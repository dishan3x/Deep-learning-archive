{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1_logestic_regression.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vqamgGLcjDJ",
        "colab_type": "text"
      },
      "source": [
        "# <i>Assignment 1</i> \n",
        "\n",
        "Problem 2\n",
        "\n",
        "This second portion is about training a  logestic regression to predic breast canser data submitted by [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html). In this example logestic regression model is created using pytorch library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNuKTrCzLsKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#<libraries>\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpB_B2VlMbe1",
        "colab_type": "text"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lSNIJalKO7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b0542674-da01-4afb-d856-9b580df6e549"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# lading data\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Data information\n",
        "print(list(data.target_names))\n",
        "print(np.array(data.data).shape)\n",
        "print(np.array(data.target).shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['malignant', 'benign']\n",
            "(569, 30)\n",
            "(569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QNw56_OLgrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "592c3b8f-3e32-4448-a964-486de180f716"
      },
      "source": [
        "# Visualize data 1\n",
        "data_b = pd.DataFrame(data.data)\n",
        "data_b.head"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         0      1       2       3   ...      26      27      28       29\n",
              "0    17.99  10.38  122.80  1001.0  ...  0.7119  0.2654  0.4601  0.11890\n",
              "1    20.57  17.77  132.90  1326.0  ...  0.2416  0.1860  0.2750  0.08902\n",
              "2    19.69  21.25  130.00  1203.0  ...  0.4504  0.2430  0.3613  0.08758\n",
              "3    11.42  20.38   77.58   386.1  ...  0.6869  0.2575  0.6638  0.17300\n",
              "4    20.29  14.34  135.10  1297.0  ...  0.4000  0.1625  0.2364  0.07678\n",
              "..     ...    ...     ...     ...  ...     ...     ...     ...      ...\n",
              "564  21.56  22.39  142.00  1479.0  ...  0.4107  0.2216  0.2060  0.07115\n",
              "565  20.13  28.25  131.20  1261.0  ...  0.3215  0.1628  0.2572  0.06637\n",
              "566  16.60  28.08  108.30   858.1  ...  0.3403  0.1418  0.2218  0.07820\n",
              "567  20.60  29.33  140.10  1265.0  ...  0.9387  0.2650  0.4087  0.12400\n",
              "568   7.76  24.54   47.92   181.0  ...  0.0000  0.0000  0.2871  0.07039\n",
              "\n",
              "[569 rows x 30 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdJPPy7iLnxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f8771365-9fe9-4ebb-87c3-6346570c7b49"
      },
      "source": [
        "# Visualize data 2\n",
        "colomns_customize = columns=np.append(data.feature_names,[\"target\"])\n",
        "colomns_customize"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension', 'target'],\n",
              "      dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpYP25dwL1Rq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "b0e9acd6-a2b4-4b05-ab66-532a7d702859"
      },
      "source": [
        "# Visualize data 3 \n",
        "colomns_customize = columns=np.append(data.feature_names,[\"target\"])\n",
        "columns=colomns_customize\n",
        "df_cancer = pd.DataFrame(data.data, data.target) \n",
        "df_cancer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0      1       2       3   ...      26      27      28       29\n",
              "0   17.99  10.38  122.80  1001.0  ...  0.7119  0.2654  0.4601  0.11890\n",
              "0   20.57  17.77  132.90  1326.0  ...  0.2416  0.1860  0.2750  0.08902\n",
              "0   19.69  21.25  130.00  1203.0  ...  0.4504  0.2430  0.3613  0.08758\n",
              "0   11.42  20.38   77.58   386.1  ...  0.6869  0.2575  0.6638  0.17300\n",
              "0   20.29  14.34  135.10  1297.0  ...  0.4000  0.1625  0.2364  0.07678\n",
              "..    ...    ...     ...     ...  ...     ...     ...     ...      ...\n",
              "0   21.56  22.39  142.00  1479.0  ...  0.4107  0.2216  0.2060  0.07115\n",
              "0   20.13  28.25  131.20  1261.0  ...  0.3215  0.1628  0.2572  0.06637\n",
              "0   16.60  28.08  108.30   858.1  ...  0.3403  0.1418  0.2218  0.07820\n",
              "0   20.60  29.33  140.10  1265.0  ...  0.9387  0.2650  0.4087  0.12400\n",
              "1    7.76  24.54   47.92   181.0  ...  0.0000  0.0000  0.2871  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMF0mm_RMsdY",
        "colab_type": "text"
      },
      "source": [
        "Process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMN0VlBfL3Wa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b39be09c-01e1-442c-fad2-e84906c7359c"
      },
      "source": [
        "# splitting the data \n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3 , random_state=5)\n",
        "\n",
        "# setting the scaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Transform train and test data according to the scaler \n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to float\n",
        "X_train = np.array(X_train, dtype=np.float32)\n",
        "X_test = np.array(X_test, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=np.float32)\n",
        "y_test = np.array(y_test, dtype=np.float32)\n",
        "\n",
        "# display infromation \n",
        "print(\"X_train shape\",X_train.shape)\n",
        "print(\"X_test shape\",X_test.shape)\n",
        "print(\"y_train shape\",y_train.shape)\n",
        "print(\"y_test shape\",y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (398, 30)\n",
            "X_test shape (171, 30)\n",
            "y_train shape (398,)\n",
            "y_test shape (171,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRtgYT0ZL6pT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fa767be2-2f56-456e-9f11-80ff9cb38edb"
      },
      "source": [
        "# Create pytorch tensors inputs\n",
        "X_train_input = Variable(torch.from_numpy(X_train))\n",
        "X_test_input = Variable(torch.from_numpy(X_test))\n",
        "\n",
        "# rearrange for one dimention\n",
        "y_train = torch.tensor(y_train, dtype=torch.float).view(-1, 1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float).view(-1, 1)\n",
        "\n",
        "# Display torch tensors\n",
        "print(\"X_train_input\",X_train_input.shape)\n",
        "print(\"X_test_input\",X_test_input.shape)\n",
        "\n",
        "print(\"y_train shape\",y_train.shape)\n",
        "print(\"y_test shape\",y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_input torch.Size([398, 30])\n",
            "X_test_input torch.Size([171, 30])\n",
            "y_train shape torch.Size([398, 1])\n",
            "y_test shape torch.Size([171, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnYtqa_yMEyZ",
        "colab_type": "text"
      },
      "source": [
        "Design Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMSw7tkPMF30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = torch.sigmoid(self.linear(x))\n",
        "        return outputs\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fZT5tKDMKZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc8eebd0-7958-4154-8e9a-4a9b347dd510"
      },
      "source": [
        "# initiate model\n",
        "input_dim = 30\n",
        "output_dim = 1\n",
        "model = LogisticRegression(input_dim, output_dim)\n",
        "\n",
        "# Store information for each epoch \n",
        "loss_arr    = [] \n",
        "val_arr     = []\n",
        "accuracy_train_arr = []\n",
        "accuracy_test_arr = []\n",
        "epoch_arr   = []\n",
        "\n",
        "# Training parameters \n",
        "num_epochs = 2000\n",
        "learningRate = 0.001\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train_input)\n",
        "    #print(y_pred)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    # Validate model\n",
        "    model.eval() # Put the model into evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # Test accuracy \n",
        "      y_train_predicted_cls = y_pred.round()\n",
        "      acc_train = y_train_predicted_cls.eq(y_train).sum() / float(y_train.shape[0])\n",
        "\n",
        "      # Validation loss \n",
        "      val_pred = model(X_test_input)\n",
        "      val_loss = criterion(val_pred, y_test) # Calculate validation loss\n",
        "\n",
        "      # Validation accuracy\n",
        "      y_test_predicted_cls = val_pred.round()\n",
        "      acc_test = y_test_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "\n",
        "\n",
        "      # store values in an array\n",
        "\n",
        "      # Keep track of epochs\n",
        "      epoch_arr.append(epoch+1)\n",
        "\n",
        "      loss_arr.append(loss.item())\n",
        "      val_arr.append(val_loss.item())\n",
        "      accuracy_train_arr.append(acc_train.item())\n",
        "      accuracy_test_arr.append(acc_test.item())\n",
        "\n",
        "      print(f\"Epoch: {epoch} learning rate: {learningRate} Training Loss: {loss.item()} Validation Loss: {val_loss.item()}  accuracy_train: {acc_train.item():.4f} accuracy_test: {acc_test.item():.4f} \")\n",
        "      #print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 learning rate: 0.001 Training Loss: 0.6705641746520996 Validation Loss: 0.6723986864089966  accuracy_train: 0.7261 accuracy_test: 0.6608 \n",
            "Epoch: 1 learning rate: 0.001 Training Loss: 0.6705343723297119 Validation Loss: 0.6723647117614746  accuracy_train: 0.7261 accuracy_test: 0.6608 \n",
            "Epoch: 2 learning rate: 0.001 Training Loss: 0.670504629611969 Validation Loss: 0.6723305583000183  accuracy_train: 0.7261 accuracy_test: 0.6608 \n",
            "Epoch: 3 learning rate: 0.001 Training Loss: 0.6704751253128052 Validation Loss: 0.6722966432571411  accuracy_train: 0.7261 accuracy_test: 0.6608 \n",
            "Epoch: 4 learning rate: 0.001 Training Loss: 0.6704452037811279 Validation Loss: 0.6722626090049744  accuracy_train: 0.7261 accuracy_test: 0.6608 \n",
            "Epoch: 5 learning rate: 0.001 Training Loss: 0.6704155206680298 Validation Loss: 0.6722286939620972  accuracy_train: 0.7286 accuracy_test: 0.6608 \n",
            "Epoch: 6 learning rate: 0.001 Training Loss: 0.6703858375549316 Validation Loss: 0.6721946001052856  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 7 learning rate: 0.001 Training Loss: 0.6703560948371887 Validation Loss: 0.6721606254577637  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 8 learning rate: 0.001 Training Loss: 0.6703266501426697 Validation Loss: 0.6721265912055969  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 9 learning rate: 0.001 Training Loss: 0.6702969074249268 Validation Loss: 0.6720925569534302  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 10 learning rate: 0.001 Training Loss: 0.6702672243118286 Validation Loss: 0.672058641910553  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 11 learning rate: 0.001 Training Loss: 0.6702374815940857 Validation Loss: 0.6720244884490967  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 12 learning rate: 0.001 Training Loss: 0.6702078580856323 Validation Loss: 0.6719906330108643  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 13 learning rate: 0.001 Training Loss: 0.6701782941818237 Validation Loss: 0.6719567179679871  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 14 learning rate: 0.001 Training Loss: 0.6701486110687256 Validation Loss: 0.6719226837158203  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 15 learning rate: 0.001 Training Loss: 0.6701189279556274 Validation Loss: 0.6718887090682983  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 16 learning rate: 0.001 Training Loss: 0.6700892448425293 Validation Loss: 0.6718547344207764  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 17 learning rate: 0.001 Training Loss: 0.6700595617294312 Validation Loss: 0.6718206405639648  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 18 learning rate: 0.001 Training Loss: 0.6700299382209778 Validation Loss: 0.6717867851257324  accuracy_train: 0.7312 accuracy_test: 0.6608 \n",
            "Epoch: 19 learning rate: 0.001 Training Loss: 0.6700004935264587 Validation Loss: 0.6717528700828552  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 20 learning rate: 0.001 Training Loss: 0.669970691204071 Validation Loss: 0.6717188954353333  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 21 learning rate: 0.001 Training Loss: 0.6699409484863281 Validation Loss: 0.671684980392456  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 22 learning rate: 0.001 Training Loss: 0.6699116230010986 Validation Loss: 0.6716510653495789  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 23 learning rate: 0.001 Training Loss: 0.6698817014694214 Validation Loss: 0.6716170310974121  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 24 learning rate: 0.001 Training Loss: 0.6698523163795471 Validation Loss: 0.6715831160545349  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 25 learning rate: 0.001 Training Loss: 0.669822633266449 Validation Loss: 0.6715491414070129  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 26 learning rate: 0.001 Training Loss: 0.6697930097579956 Validation Loss: 0.6715152859687805  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 27 learning rate: 0.001 Training Loss: 0.6697632074356079 Validation Loss: 0.6714813709259033  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 28 learning rate: 0.001 Training Loss: 0.6697337627410889 Validation Loss: 0.6714473366737366  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 29 learning rate: 0.001 Training Loss: 0.6697043180465698 Validation Loss: 0.6714136004447937  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 30 learning rate: 0.001 Training Loss: 0.6696745157241821 Validation Loss: 0.6713795065879822  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 31 learning rate: 0.001 Training Loss: 0.6696450114250183 Validation Loss: 0.6713456511497498  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 32 learning rate: 0.001 Training Loss: 0.6696153283119202 Validation Loss: 0.6713117361068726  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 33 learning rate: 0.001 Training Loss: 0.669585645198822 Validation Loss: 0.6712777614593506  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 34 learning rate: 0.001 Training Loss: 0.6695561408996582 Validation Loss: 0.6712439060211182  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 35 learning rate: 0.001 Training Loss: 0.6695265769958496 Validation Loss: 0.671209990978241  accuracy_train: 0.7337 accuracy_test: 0.6608 \n",
            "Epoch: 36 learning rate: 0.001 Training Loss: 0.6694970726966858 Validation Loss: 0.6711761951446533  accuracy_train: 0.7362 accuracy_test: 0.6608 \n",
            "Epoch: 37 learning rate: 0.001 Training Loss: 0.6694673895835876 Validation Loss: 0.6711421608924866  accuracy_train: 0.7362 accuracy_test: 0.6608 \n",
            "Epoch: 38 learning rate: 0.001 Training Loss: 0.669437825679779 Validation Loss: 0.6711084842681885  accuracy_train: 0.7362 accuracy_test: 0.6608 \n",
            "Epoch: 39 learning rate: 0.001 Training Loss: 0.6694081425666809 Validation Loss: 0.6710745096206665  accuracy_train: 0.7362 accuracy_test: 0.6608 \n",
            "Epoch: 40 learning rate: 0.001 Training Loss: 0.6693786382675171 Validation Loss: 0.6710406541824341  accuracy_train: 0.7362 accuracy_test: 0.6608 \n",
            "Epoch: 41 learning rate: 0.001 Training Loss: 0.6693490743637085 Validation Loss: 0.6710068583488464  accuracy_train: 0.7362 accuracy_test: 0.6608 \n",
            "Epoch: 42 learning rate: 0.001 Training Loss: 0.6693195104598999 Validation Loss: 0.6709728837013245  accuracy_train: 0.7362 accuracy_test: 0.6608 \n",
            "Epoch: 43 learning rate: 0.001 Training Loss: 0.6692898869514465 Validation Loss: 0.6709391474723816  accuracy_train: 0.7362 accuracy_test: 0.6667 \n",
            "Epoch: 44 learning rate: 0.001 Training Loss: 0.6692603826522827 Validation Loss: 0.6709052920341492  accuracy_train: 0.7362 accuracy_test: 0.6667 \n",
            "Epoch: 45 learning rate: 0.001 Training Loss: 0.6692308783531189 Validation Loss: 0.6708713173866272  accuracy_train: 0.7362 accuracy_test: 0.6667 \n",
            "Epoch: 46 learning rate: 0.001 Training Loss: 0.6692012548446655 Validation Loss: 0.6708375215530396  accuracy_train: 0.7362 accuracy_test: 0.6667 \n",
            "Epoch: 47 learning rate: 0.001 Training Loss: 0.6691716909408569 Validation Loss: 0.6708036661148071  accuracy_train: 0.7362 accuracy_test: 0.6667 \n",
            "Epoch: 48 learning rate: 0.001 Training Loss: 0.6691421270370483 Validation Loss: 0.6707698702812195  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 49 learning rate: 0.001 Training Loss: 0.6691125631332397 Validation Loss: 0.6707360148429871  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 50 learning rate: 0.001 Training Loss: 0.6690831780433655 Validation Loss: 0.6707022190093994  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 51 learning rate: 0.001 Training Loss: 0.6690536737442017 Validation Loss: 0.6706683039665222  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 52 learning rate: 0.001 Training Loss: 0.6690241098403931 Validation Loss: 0.6706345677375793  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 53 learning rate: 0.001 Training Loss: 0.6689945459365845 Validation Loss: 0.6706006526947021  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 54 learning rate: 0.001 Training Loss: 0.6689649224281311 Validation Loss: 0.6705668568611145  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 55 learning rate: 0.001 Training Loss: 0.6689353585243225 Validation Loss: 0.6705330610275269  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 56 learning rate: 0.001 Training Loss: 0.6689057946205139 Validation Loss: 0.670499324798584  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 57 learning rate: 0.001 Training Loss: 0.6688764691352844 Validation Loss: 0.6704655289649963  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 58 learning rate: 0.001 Training Loss: 0.668846845626831 Validation Loss: 0.6704317927360535  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 59 learning rate: 0.001 Training Loss: 0.668817400932312 Validation Loss: 0.6703978776931763  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 60 learning rate: 0.001 Training Loss: 0.6687878370285034 Validation Loss: 0.6703640818595886  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 61 learning rate: 0.001 Training Loss: 0.6687583923339844 Validation Loss: 0.6703302264213562  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 62 learning rate: 0.001 Training Loss: 0.6687287092208862 Validation Loss: 0.6702964901924133  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 63 learning rate: 0.001 Training Loss: 0.6686993837356567 Validation Loss: 0.6702627539634705  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 64 learning rate: 0.001 Training Loss: 0.6686699390411377 Validation Loss: 0.670228898525238  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 65 learning rate: 0.001 Training Loss: 0.6686403155326843 Validation Loss: 0.6701951622962952  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 66 learning rate: 0.001 Training Loss: 0.6686107516288757 Validation Loss: 0.6701613068580627  accuracy_train: 0.7362 accuracy_test: 0.6725 \n",
            "Epoch: 67 learning rate: 0.001 Training Loss: 0.6685812473297119 Validation Loss: 0.6701276302337646  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 68 learning rate: 0.001 Training Loss: 0.6685518622398376 Validation Loss: 0.6700938940048218  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 69 learning rate: 0.001 Training Loss: 0.6685223579406738 Validation Loss: 0.6700601577758789  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 70 learning rate: 0.001 Training Loss: 0.66849285364151 Validation Loss: 0.6700263619422913  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 71 learning rate: 0.001 Training Loss: 0.668463408946991 Validation Loss: 0.6699927449226379  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 72 learning rate: 0.001 Training Loss: 0.6684338450431824 Validation Loss: 0.6699588894844055  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 73 learning rate: 0.001 Training Loss: 0.6684043407440186 Validation Loss: 0.6699251532554626  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 74 learning rate: 0.001 Training Loss: 0.6683750152587891 Validation Loss: 0.6698914170265198  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 75 learning rate: 0.001 Training Loss: 0.6683456301689148 Validation Loss: 0.6698576807975769  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 76 learning rate: 0.001 Training Loss: 0.668316125869751 Validation Loss: 0.6698238849639893  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 77 learning rate: 0.001 Training Loss: 0.6682865619659424 Validation Loss: 0.6697902679443359  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 78 learning rate: 0.001 Training Loss: 0.6682571172714233 Validation Loss: 0.6697564125061035  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 79 learning rate: 0.001 Training Loss: 0.6682276725769043 Validation Loss: 0.669722855091095  accuracy_train: 0.7362 accuracy_test: 0.6784 \n",
            "Epoch: 80 learning rate: 0.001 Training Loss: 0.6681981682777405 Validation Loss: 0.6696889996528625  accuracy_train: 0.7362 accuracy_test: 0.6842 \n",
            "Epoch: 81 learning rate: 0.001 Training Loss: 0.6681687831878662 Validation Loss: 0.6696553826332092  accuracy_train: 0.7412 accuracy_test: 0.6842 \n",
            "Epoch: 82 learning rate: 0.001 Training Loss: 0.6681393384933472 Validation Loss: 0.6696215867996216  accuracy_train: 0.7412 accuracy_test: 0.6901 \n",
            "Epoch: 83 learning rate: 0.001 Training Loss: 0.6681098937988281 Validation Loss: 0.6695879697799683  accuracy_train: 0.7412 accuracy_test: 0.6901 \n",
            "Epoch: 84 learning rate: 0.001 Training Loss: 0.6680804491043091 Validation Loss: 0.6695543527603149  accuracy_train: 0.7412 accuracy_test: 0.6901 \n",
            "Epoch: 85 learning rate: 0.001 Training Loss: 0.66805100440979 Validation Loss: 0.6695205569267273  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 86 learning rate: 0.001 Training Loss: 0.6680216789245605 Validation Loss: 0.6694868206977844  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 87 learning rate: 0.001 Training Loss: 0.6679920554161072 Validation Loss: 0.6694531440734863  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 88 learning rate: 0.001 Training Loss: 0.6679626107215881 Validation Loss: 0.6694194674491882  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 89 learning rate: 0.001 Training Loss: 0.6679331660270691 Validation Loss: 0.6693857908248901  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 90 learning rate: 0.001 Training Loss: 0.6679039001464844 Validation Loss: 0.669352114200592  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 91 learning rate: 0.001 Training Loss: 0.6678743362426758 Validation Loss: 0.6693185567855835  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 92 learning rate: 0.001 Training Loss: 0.6678450703620911 Validation Loss: 0.6692848205566406  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 93 learning rate: 0.001 Training Loss: 0.667815625667572 Validation Loss: 0.6692512035369873  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 94 learning rate: 0.001 Training Loss: 0.6677863597869873 Validation Loss: 0.6692175269126892  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 95 learning rate: 0.001 Training Loss: 0.6677569150924683 Validation Loss: 0.6691838502883911  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 96 learning rate: 0.001 Training Loss: 0.6677274703979492 Validation Loss: 0.669150173664093  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 97 learning rate: 0.001 Training Loss: 0.6676980257034302 Validation Loss: 0.6691166162490845  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 98 learning rate: 0.001 Training Loss: 0.6676685810089111 Validation Loss: 0.6690828800201416  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 99 learning rate: 0.001 Training Loss: 0.6676393151283264 Validation Loss: 0.6690493822097778  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 100 learning rate: 0.001 Training Loss: 0.6676098704338074 Validation Loss: 0.669015645980835  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 101 learning rate: 0.001 Training Loss: 0.6675804853439331 Validation Loss: 0.6689821481704712  accuracy_train: 0.7412 accuracy_test: 0.6959 \n",
            "Epoch: 102 learning rate: 0.001 Training Loss: 0.6675508618354797 Validation Loss: 0.6689484119415283  accuracy_train: 0.7412 accuracy_test: 0.7018 \n",
            "Epoch: 103 learning rate: 0.001 Training Loss: 0.667521595954895 Validation Loss: 0.6689148545265198  accuracy_train: 0.7412 accuracy_test: 0.7018 \n",
            "Epoch: 104 learning rate: 0.001 Training Loss: 0.6674922704696655 Validation Loss: 0.6688811182975769  accuracy_train: 0.7412 accuracy_test: 0.7018 \n",
            "Epoch: 105 learning rate: 0.001 Training Loss: 0.6674628853797913 Validation Loss: 0.6688476800918579  accuracy_train: 0.7412 accuracy_test: 0.7018 \n",
            "Epoch: 106 learning rate: 0.001 Training Loss: 0.6674337983131409 Validation Loss: 0.6688141226768494  accuracy_train: 0.7412 accuracy_test: 0.7018 \n",
            "Epoch: 107 learning rate: 0.001 Training Loss: 0.6674042344093323 Validation Loss: 0.6687803864479065  accuracy_train: 0.7412 accuracy_test: 0.7018 \n",
            "Epoch: 108 learning rate: 0.001 Training Loss: 0.6673747897148132 Validation Loss: 0.668746829032898  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 109 learning rate: 0.001 Training Loss: 0.6673453450202942 Validation Loss: 0.6687131524085999  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 110 learning rate: 0.001 Training Loss: 0.6673159003257751 Validation Loss: 0.6686795949935913  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 111 learning rate: 0.001 Training Loss: 0.6672869324684143 Validation Loss: 0.6686460375785828  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 112 learning rate: 0.001 Training Loss: 0.6672573089599609 Validation Loss: 0.6686124205589294  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 113 learning rate: 0.001 Training Loss: 0.6672279834747314 Validation Loss: 0.6685788631439209  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 114 learning rate: 0.001 Training Loss: 0.6671987771987915 Validation Loss: 0.6685453057289124  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 115 learning rate: 0.001 Training Loss: 0.6671691536903381 Validation Loss: 0.668511688709259  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 116 learning rate: 0.001 Training Loss: 0.667140007019043 Validation Loss: 0.6684781908988953  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 117 learning rate: 0.001 Training Loss: 0.6671105623245239 Validation Loss: 0.6684445738792419  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 118 learning rate: 0.001 Training Loss: 0.667081356048584 Validation Loss: 0.6684110164642334  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 119 learning rate: 0.001 Training Loss: 0.6670519113540649 Validation Loss: 0.6683774590492249  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 120 learning rate: 0.001 Training Loss: 0.667022705078125 Validation Loss: 0.6683439016342163  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 121 learning rate: 0.001 Training Loss: 0.6669933199882507 Validation Loss: 0.6683103442192078  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 122 learning rate: 0.001 Training Loss: 0.6669639945030212 Validation Loss: 0.6682767868041992  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 123 learning rate: 0.001 Training Loss: 0.6669346690177917 Validation Loss: 0.6682433485984802  accuracy_train: 0.7412 accuracy_test: 0.7076 \n",
            "Epoch: 124 learning rate: 0.001 Training Loss: 0.666905403137207 Validation Loss: 0.6682097315788269  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 125 learning rate: 0.001 Training Loss: 0.6668760776519775 Validation Loss: 0.6681762337684631  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 126 learning rate: 0.001 Training Loss: 0.666846513748169 Validation Loss: 0.668142557144165  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 127 learning rate: 0.001 Training Loss: 0.6668175458908081 Validation Loss: 0.6681091785430908  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 128 learning rate: 0.001 Training Loss: 0.6667882204055786 Validation Loss: 0.6680756211280823  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 129 learning rate: 0.001 Training Loss: 0.6667587757110596 Validation Loss: 0.6680421233177185  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 130 learning rate: 0.001 Training Loss: 0.6667295694351196 Validation Loss: 0.66800856590271  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 131 learning rate: 0.001 Training Loss: 0.6667001247406006 Validation Loss: 0.6679750084877014  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 132 learning rate: 0.001 Training Loss: 0.6666709184646606 Validation Loss: 0.6679415702819824  accuracy_train: 0.7437 accuracy_test: 0.7076 \n",
            "Epoch: 133 learning rate: 0.001 Training Loss: 0.6666415929794312 Validation Loss: 0.6679079532623291  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 134 learning rate: 0.001 Training Loss: 0.6666123270988464 Validation Loss: 0.6678744554519653  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 135 learning rate: 0.001 Training Loss: 0.6665830612182617 Validation Loss: 0.6678410768508911  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 136 learning rate: 0.001 Training Loss: 0.6665536761283875 Validation Loss: 0.6678075790405273  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 137 learning rate: 0.001 Training Loss: 0.6665245294570923 Validation Loss: 0.6677742004394531  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 138 learning rate: 0.001 Training Loss: 0.666495144367218 Validation Loss: 0.6677405834197998  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 139 learning rate: 0.001 Training Loss: 0.6664660573005676 Validation Loss: 0.6677071452140808  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 140 learning rate: 0.001 Training Loss: 0.6664367318153381 Validation Loss: 0.6676737666130066  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 141 learning rate: 0.001 Training Loss: 0.6664074659347534 Validation Loss: 0.667640209197998  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 142 learning rate: 0.001 Training Loss: 0.6663781404495239 Validation Loss: 0.667606770992279  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 143 learning rate: 0.001 Training Loss: 0.666348934173584 Validation Loss: 0.6675731539726257  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 144 learning rate: 0.001 Training Loss: 0.6663196682929993 Validation Loss: 0.6675398349761963  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 145 learning rate: 0.001 Training Loss: 0.6662903428077698 Validation Loss: 0.6675063967704773  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 146 learning rate: 0.001 Training Loss: 0.6662610173225403 Validation Loss: 0.6674728989601135  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 147 learning rate: 0.001 Training Loss: 0.6662319302558899 Validation Loss: 0.6674394011497498  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 148 learning rate: 0.001 Training Loss: 0.6662024855613708 Validation Loss: 0.6674060821533203  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 149 learning rate: 0.001 Training Loss: 0.6661733388900757 Validation Loss: 0.6673725843429565  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 150 learning rate: 0.001 Training Loss: 0.6661439538002014 Validation Loss: 0.6673391461372375  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 151 learning rate: 0.001 Training Loss: 0.6661149263381958 Validation Loss: 0.6673057675361633  accuracy_train: 0.7437 accuracy_test: 0.7135 \n",
            "Epoch: 152 learning rate: 0.001 Training Loss: 0.6660857796669006 Validation Loss: 0.6672723293304443  accuracy_train: 0.7437 accuracy_test: 0.7193 \n",
            "Epoch: 153 learning rate: 0.001 Training Loss: 0.6660563945770264 Validation Loss: 0.6672388911247253  accuracy_train: 0.7437 accuracy_test: 0.7193 \n",
            "Epoch: 154 learning rate: 0.001 Training Loss: 0.6660274267196655 Validation Loss: 0.6672054529190063  accuracy_train: 0.7437 accuracy_test: 0.7193 \n",
            "Epoch: 155 learning rate: 0.001 Training Loss: 0.6659979820251465 Validation Loss: 0.6671720147132874  accuracy_train: 0.7437 accuracy_test: 0.7193 \n",
            "Epoch: 156 learning rate: 0.001 Training Loss: 0.6659685969352722 Validation Loss: 0.6671386361122131  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 157 learning rate: 0.001 Training Loss: 0.6659395098686218 Validation Loss: 0.6671051979064941  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 158 learning rate: 0.001 Training Loss: 0.6659102439880371 Validation Loss: 0.6670717597007751  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 159 learning rate: 0.001 Training Loss: 0.6658810377120972 Validation Loss: 0.6670383810997009  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 160 learning rate: 0.001 Training Loss: 0.665851891040802 Validation Loss: 0.6670051217079163  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 161 learning rate: 0.001 Training Loss: 0.6658226847648621 Validation Loss: 0.6669716238975525  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 162 learning rate: 0.001 Training Loss: 0.6657933592796326 Validation Loss: 0.666938304901123  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 163 learning rate: 0.001 Training Loss: 0.6657642722129822 Validation Loss: 0.666904866695404  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 164 learning rate: 0.001 Training Loss: 0.6657350659370422 Validation Loss: 0.6668714284896851  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 165 learning rate: 0.001 Training Loss: 0.6657058000564575 Validation Loss: 0.6668380498886108  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 166 learning rate: 0.001 Training Loss: 0.6656767725944519 Validation Loss: 0.6668047308921814  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 167 learning rate: 0.001 Training Loss: 0.6656474471092224 Validation Loss: 0.6667712926864624  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 168 learning rate: 0.001 Training Loss: 0.6656183004379272 Validation Loss: 0.666737973690033  accuracy_train: 0.7437 accuracy_test: 0.7251 \n",
            "Epoch: 169 learning rate: 0.001 Training Loss: 0.6655891537666321 Validation Loss: 0.6667046546936035  accuracy_train: 0.7462 accuracy_test: 0.7251 \n",
            "Epoch: 170 learning rate: 0.001 Training Loss: 0.6655598282814026 Validation Loss: 0.6666712760925293  accuracy_train: 0.7462 accuracy_test: 0.7251 \n",
            "Epoch: 171 learning rate: 0.001 Training Loss: 0.6655307412147522 Validation Loss: 0.6666379570960999  accuracy_train: 0.7462 accuracy_test: 0.7251 \n",
            "Epoch: 172 learning rate: 0.001 Training Loss: 0.665501594543457 Validation Loss: 0.6666046380996704  accuracy_train: 0.7462 accuracy_test: 0.7251 \n",
            "Epoch: 173 learning rate: 0.001 Training Loss: 0.6654725074768066 Validation Loss: 0.666571319103241  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 174 learning rate: 0.001 Training Loss: 0.6654433012008667 Validation Loss: 0.6665379405021667  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 175 learning rate: 0.001 Training Loss: 0.6654140949249268 Validation Loss: 0.6665045619010925  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 176 learning rate: 0.001 Training Loss: 0.6653848886489868 Validation Loss: 0.6664712429046631  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 177 learning rate: 0.001 Training Loss: 0.6653558015823364 Validation Loss: 0.6664379239082336  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 178 learning rate: 0.001 Training Loss: 0.6653262972831726 Validation Loss: 0.6664046049118042  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 179 learning rate: 0.001 Training Loss: 0.6652976274490356 Validation Loss: 0.6663712859153748  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 180 learning rate: 0.001 Training Loss: 0.6652682423591614 Validation Loss: 0.6663379073143005  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 181 learning rate: 0.001 Training Loss: 0.6652392148971558 Validation Loss: 0.6663047075271606  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 182 learning rate: 0.001 Training Loss: 0.6652100682258606 Validation Loss: 0.6662712693214417  accuracy_train: 0.7487 accuracy_test: 0.7251 \n",
            "Epoch: 183 learning rate: 0.001 Training Loss: 0.6651808619499207 Validation Loss: 0.6662381291389465  accuracy_train: 0.7487 accuracy_test: 0.7310 \n",
            "Epoch: 184 learning rate: 0.001 Training Loss: 0.6651517152786255 Validation Loss: 0.6662046909332275  accuracy_train: 0.7487 accuracy_test: 0.7310 \n",
            "Epoch: 185 learning rate: 0.001 Training Loss: 0.6651225090026855 Validation Loss: 0.6661714315414429  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 186 learning rate: 0.001 Training Loss: 0.6650934815406799 Validation Loss: 0.6661381125450134  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 187 learning rate: 0.001 Training Loss: 0.6650644540786743 Validation Loss: 0.666104793548584  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 188 learning rate: 0.001 Training Loss: 0.6650352478027344 Validation Loss: 0.6660716533660889  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 189 learning rate: 0.001 Training Loss: 0.6650061011314392 Validation Loss: 0.6660382747650146  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 190 learning rate: 0.001 Training Loss: 0.6649770140647888 Validation Loss: 0.66600501537323  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 191 learning rate: 0.001 Training Loss: 0.6649478077888489 Validation Loss: 0.6659716963768005  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 192 learning rate: 0.001 Training Loss: 0.6649187803268433 Validation Loss: 0.6659383773803711  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 193 learning rate: 0.001 Training Loss: 0.6648895144462585 Validation Loss: 0.6659051775932312  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 194 learning rate: 0.001 Training Loss: 0.6648606061935425 Validation Loss: 0.6658719182014465  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 195 learning rate: 0.001 Training Loss: 0.6648313403129578 Validation Loss: 0.6658387780189514  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 196 learning rate: 0.001 Training Loss: 0.6648022532463074 Validation Loss: 0.6658053994178772  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 197 learning rate: 0.001 Training Loss: 0.6647729873657227 Validation Loss: 0.6657721400260925  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 198 learning rate: 0.001 Training Loss: 0.6647441387176514 Validation Loss: 0.6657389402389526  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 199 learning rate: 0.001 Training Loss: 0.6647151112556458 Validation Loss: 0.6657055616378784  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 200 learning rate: 0.001 Training Loss: 0.6646857857704163 Validation Loss: 0.6656724214553833  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 201 learning rate: 0.001 Training Loss: 0.6646568179130554 Validation Loss: 0.6656392216682434  accuracy_train: 0.7487 accuracy_test: 0.7368 \n",
            "Epoch: 202 learning rate: 0.001 Training Loss: 0.6646277904510498 Validation Loss: 0.6656060814857483  accuracy_train: 0.7513 accuracy_test: 0.7368 \n",
            "Epoch: 203 learning rate: 0.001 Training Loss: 0.6645987033843994 Validation Loss: 0.6655728220939636  accuracy_train: 0.7513 accuracy_test: 0.7368 \n",
            "Epoch: 204 learning rate: 0.001 Training Loss: 0.6645695567131042 Validation Loss: 0.6655395030975342  accuracy_train: 0.7513 accuracy_test: 0.7368 \n",
            "Epoch: 205 learning rate: 0.001 Training Loss: 0.6645404100418091 Validation Loss: 0.6655063033103943  accuracy_train: 0.7513 accuracy_test: 0.7368 \n",
            "Epoch: 206 learning rate: 0.001 Training Loss: 0.6645113825798035 Validation Loss: 0.6654731631278992  accuracy_train: 0.7513 accuracy_test: 0.7368 \n",
            "Epoch: 207 learning rate: 0.001 Training Loss: 0.6644824743270874 Validation Loss: 0.6654398441314697  accuracy_train: 0.7513 accuracy_test: 0.7368 \n",
            "Epoch: 208 learning rate: 0.001 Training Loss: 0.6644530892372131 Validation Loss: 0.6654066443443298  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 209 learning rate: 0.001 Training Loss: 0.6644244194030762 Validation Loss: 0.6653735041618347  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 210 learning rate: 0.001 Training Loss: 0.6643953323364258 Validation Loss: 0.6653401851654053  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 211 learning rate: 0.001 Training Loss: 0.6643661260604858 Validation Loss: 0.6653071045875549  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 212 learning rate: 0.001 Training Loss: 0.664337158203125 Validation Loss: 0.665273904800415  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 213 learning rate: 0.001 Training Loss: 0.6643079519271851 Validation Loss: 0.6652407050132751  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 214 learning rate: 0.001 Training Loss: 0.6642789840698242 Validation Loss: 0.6652075052261353  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 215 learning rate: 0.001 Training Loss: 0.6642497181892395 Validation Loss: 0.6651742458343506  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 216 learning rate: 0.001 Training Loss: 0.664220929145813 Validation Loss: 0.6651411652565002  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 217 learning rate: 0.001 Training Loss: 0.6641919016838074 Validation Loss: 0.6651079058647156  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 218 learning rate: 0.001 Training Loss: 0.664162814617157 Validation Loss: 0.6650748252868652  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 219 learning rate: 0.001 Training Loss: 0.6641337871551514 Validation Loss: 0.6650416851043701  accuracy_train: 0.7538 accuracy_test: 0.7368 \n",
            "Epoch: 220 learning rate: 0.001 Training Loss: 0.6641047596931458 Validation Loss: 0.6650084853172302  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 221 learning rate: 0.001 Training Loss: 0.6640756726264954 Validation Loss: 0.6649752855300903  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 222 learning rate: 0.001 Training Loss: 0.6640467047691345 Validation Loss: 0.66494220495224  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 223 learning rate: 0.001 Training Loss: 0.6640176177024841 Validation Loss: 0.6649090647697449  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 224 learning rate: 0.001 Training Loss: 0.6639887094497681 Validation Loss: 0.6648759245872498  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 225 learning rate: 0.001 Training Loss: 0.6639596819877625 Validation Loss: 0.6648427248001099  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 226 learning rate: 0.001 Training Loss: 0.6639305949211121 Validation Loss: 0.6648095846176147  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 227 learning rate: 0.001 Training Loss: 0.6639013886451721 Validation Loss: 0.6647763848304749  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 228 learning rate: 0.001 Training Loss: 0.6638726592063904 Validation Loss: 0.6647433042526245  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 229 learning rate: 0.001 Training Loss: 0.6638436913490295 Validation Loss: 0.6647102236747742  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 230 learning rate: 0.001 Training Loss: 0.6638144254684448 Validation Loss: 0.664677083492279  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 231 learning rate: 0.001 Training Loss: 0.6637856364250183 Validation Loss: 0.6646439433097839  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 232 learning rate: 0.001 Training Loss: 0.6637564897537231 Validation Loss: 0.664610743522644  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 233 learning rate: 0.001 Training Loss: 0.6637275218963623 Validation Loss: 0.6645776629447937  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 234 learning rate: 0.001 Training Loss: 0.663698673248291 Validation Loss: 0.6645447015762329  accuracy_train: 0.7563 accuracy_test: 0.7368 \n",
            "Epoch: 235 learning rate: 0.001 Training Loss: 0.6636697053909302 Validation Loss: 0.664511501789093  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 236 learning rate: 0.001 Training Loss: 0.6636406183242798 Validation Loss: 0.6644784212112427  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 237 learning rate: 0.001 Training Loss: 0.663611650466919 Validation Loss: 0.6644452214241028  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 238 learning rate: 0.001 Training Loss: 0.6635825634002686 Validation Loss: 0.6644122004508972  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 239 learning rate: 0.001 Training Loss: 0.6635536551475525 Validation Loss: 0.6643791794776917  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 240 learning rate: 0.001 Training Loss: 0.663524866104126 Validation Loss: 0.6643459796905518  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 241 learning rate: 0.001 Training Loss: 0.6634958386421204 Validation Loss: 0.6643130779266357  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 242 learning rate: 0.001 Training Loss: 0.6634668111801147 Validation Loss: 0.6642799377441406  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 243 learning rate: 0.001 Training Loss: 0.6634377837181091 Validation Loss: 0.6642467975616455  accuracy_train: 0.7563 accuracy_test: 0.7427 \n",
            "Epoch: 244 learning rate: 0.001 Training Loss: 0.6634088158607483 Validation Loss: 0.6642137765884399  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 245 learning rate: 0.001 Training Loss: 0.663379967212677 Validation Loss: 0.6641806960105896  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 246 learning rate: 0.001 Training Loss: 0.6633509397506714 Validation Loss: 0.6641476154327393  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 247 learning rate: 0.001 Training Loss: 0.6633220314979553 Validation Loss: 0.6641145944595337  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 248 learning rate: 0.001 Training Loss: 0.6632931232452393 Validation Loss: 0.6640815734863281  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 249 learning rate: 0.001 Training Loss: 0.6632639765739441 Validation Loss: 0.6640484929084778  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 250 learning rate: 0.001 Training Loss: 0.6632351279258728 Validation Loss: 0.6640154123306274  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 251 learning rate: 0.001 Training Loss: 0.6632063388824463 Validation Loss: 0.6639823317527771  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 252 learning rate: 0.001 Training Loss: 0.6631773114204407 Validation Loss: 0.6639493703842163  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 253 learning rate: 0.001 Training Loss: 0.6631482839584351 Validation Loss: 0.6639163494110107  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 254 learning rate: 0.001 Training Loss: 0.6631194949150085 Validation Loss: 0.6638833284378052  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 255 learning rate: 0.001 Training Loss: 0.6630905270576477 Validation Loss: 0.6638503074645996  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 256 learning rate: 0.001 Training Loss: 0.6630615592002869 Validation Loss: 0.6638172268867493  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 257 learning rate: 0.001 Training Loss: 0.6630326509475708 Validation Loss: 0.6637842655181885  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 258 learning rate: 0.001 Training Loss: 0.6630037426948547 Validation Loss: 0.6637512445449829  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 259 learning rate: 0.001 Training Loss: 0.6629748344421387 Validation Loss: 0.6637181639671326  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 260 learning rate: 0.001 Training Loss: 0.6629459857940674 Validation Loss: 0.6636852025985718  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 261 learning rate: 0.001 Training Loss: 0.6629169583320618 Validation Loss: 0.6636521816253662  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 262 learning rate: 0.001 Training Loss: 0.6628881096839905 Validation Loss: 0.6636191606521606  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 263 learning rate: 0.001 Training Loss: 0.6628591418266296 Validation Loss: 0.6635861992835999  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 264 learning rate: 0.001 Training Loss: 0.6628302931785583 Validation Loss: 0.6635532379150391  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 265 learning rate: 0.001 Training Loss: 0.6628013253211975 Validation Loss: 0.6635202169418335  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 266 learning rate: 0.001 Training Loss: 0.6627724170684814 Validation Loss: 0.6634871959686279  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 267 learning rate: 0.001 Training Loss: 0.6627435088157654 Validation Loss: 0.6634543538093567  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 268 learning rate: 0.001 Training Loss: 0.6627148389816284 Validation Loss: 0.6634212136268616  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 269 learning rate: 0.001 Training Loss: 0.6626858115196228 Validation Loss: 0.663388192653656  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 270 learning rate: 0.001 Training Loss: 0.6626569032669067 Validation Loss: 0.66335529088974  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 271 learning rate: 0.001 Training Loss: 0.6626279950141907 Validation Loss: 0.663322389125824  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 272 learning rate: 0.001 Training Loss: 0.6625992059707642 Validation Loss: 0.663289487361908  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 273 learning rate: 0.001 Training Loss: 0.662570059299469 Validation Loss: 0.6632564067840576  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 274 learning rate: 0.001 Training Loss: 0.6625414490699768 Validation Loss: 0.6632234454154968  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 275 learning rate: 0.001 Training Loss: 0.6625123620033264 Validation Loss: 0.6631905436515808  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 276 learning rate: 0.001 Training Loss: 0.6624836921691895 Validation Loss: 0.6631576418876648  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 277 learning rate: 0.001 Training Loss: 0.6624547839164734 Validation Loss: 0.663124680519104  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 278 learning rate: 0.001 Training Loss: 0.6624258756637573 Validation Loss: 0.6630917191505432  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 279 learning rate: 0.001 Training Loss: 0.6623969674110413 Validation Loss: 0.6630587577819824  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 280 learning rate: 0.001 Training Loss: 0.6623682975769043 Validation Loss: 0.6630258560180664  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 281 learning rate: 0.001 Training Loss: 0.6623393297195435 Validation Loss: 0.6629928946495056  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 282 learning rate: 0.001 Training Loss: 0.6623104214668274 Validation Loss: 0.6629600524902344  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 283 learning rate: 0.001 Training Loss: 0.6622815728187561 Validation Loss: 0.6629270911216736  accuracy_train: 0.7588 accuracy_test: 0.7427 \n",
            "Epoch: 284 learning rate: 0.001 Training Loss: 0.66225266456604 Validation Loss: 0.6628942489624023  accuracy_train: 0.7588 accuracy_test: 0.7485 \n",
            "Epoch: 285 learning rate: 0.001 Training Loss: 0.6622241139411926 Validation Loss: 0.6628612279891968  accuracy_train: 0.7588 accuracy_test: 0.7485 \n",
            "Epoch: 286 learning rate: 0.001 Training Loss: 0.6621952652931213 Validation Loss: 0.6628283858299255  accuracy_train: 0.7588 accuracy_test: 0.7485 \n",
            "Epoch: 287 learning rate: 0.001 Training Loss: 0.6621661186218262 Validation Loss: 0.6627954840660095  accuracy_train: 0.7588 accuracy_test: 0.7485 \n",
            "Epoch: 288 learning rate: 0.001 Training Loss: 0.6621374487876892 Validation Loss: 0.6627625823020935  accuracy_train: 0.7588 accuracy_test: 0.7485 \n",
            "Epoch: 289 learning rate: 0.001 Training Loss: 0.6621086001396179 Validation Loss: 0.6627295613288879  accuracy_train: 0.7588 accuracy_test: 0.7485 \n",
            "Epoch: 290 learning rate: 0.001 Training Loss: 0.6620798707008362 Validation Loss: 0.6626967191696167  accuracy_train: 0.7588 accuracy_test: 0.7485 \n",
            "Epoch: 291 learning rate: 0.001 Training Loss: 0.6620509624481201 Validation Loss: 0.6626638174057007  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 292 learning rate: 0.001 Training Loss: 0.6620221138000488 Validation Loss: 0.6626309156417847  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 293 learning rate: 0.001 Training Loss: 0.6619933843612671 Validation Loss: 0.6625981330871582  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 294 learning rate: 0.001 Training Loss: 0.6619647145271301 Validation Loss: 0.6625651717185974  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 295 learning rate: 0.001 Training Loss: 0.6619358658790588 Validation Loss: 0.662532389163971  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 296 learning rate: 0.001 Training Loss: 0.6619070172309875 Validation Loss: 0.6624995470046997  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 297 learning rate: 0.001 Training Loss: 0.6618781685829163 Validation Loss: 0.6624666452407837  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 298 learning rate: 0.001 Training Loss: 0.6618492603302002 Validation Loss: 0.6624336838722229  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 299 learning rate: 0.001 Training Loss: 0.6618203520774841 Validation Loss: 0.6624008417129517  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 300 learning rate: 0.001 Training Loss: 0.6617916822433472 Validation Loss: 0.6623680591583252  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 301 learning rate: 0.001 Training Loss: 0.6617628931999207 Validation Loss: 0.6623352766036987  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 302 learning rate: 0.001 Training Loss: 0.6617341041564941 Validation Loss: 0.6623023152351379  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 303 learning rate: 0.001 Training Loss: 0.6617053747177124 Validation Loss: 0.6622694730758667  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 304 learning rate: 0.001 Training Loss: 0.6616767048835754 Validation Loss: 0.6622366905212402  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 305 learning rate: 0.001 Training Loss: 0.6616476774215698 Validation Loss: 0.662203848361969  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 306 learning rate: 0.001 Training Loss: 0.6616190075874329 Validation Loss: 0.6621708869934082  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 307 learning rate: 0.001 Training Loss: 0.6615902781486511 Validation Loss: 0.6621381640434265  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 308 learning rate: 0.001 Training Loss: 0.6615614891052246 Validation Loss: 0.6621053814888  accuracy_train: 0.7613 accuracy_test: 0.7485 \n",
            "Epoch: 309 learning rate: 0.001 Training Loss: 0.6615328192710876 Validation Loss: 0.6620725393295288  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 310 learning rate: 0.001 Training Loss: 0.6615038514137268 Validation Loss: 0.6620396971702576  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 311 learning rate: 0.001 Training Loss: 0.6614751815795898 Validation Loss: 0.6620069742202759  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 312 learning rate: 0.001 Training Loss: 0.6614463329315186 Validation Loss: 0.6619741320610046  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 313 learning rate: 0.001 Training Loss: 0.6614176630973816 Validation Loss: 0.6619412899017334  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 314 learning rate: 0.001 Training Loss: 0.6613889336585999 Validation Loss: 0.6619085073471069  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 315 learning rate: 0.001 Training Loss: 0.6613602638244629 Validation Loss: 0.6618756651878357  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 316 learning rate: 0.001 Training Loss: 0.6613314747810364 Validation Loss: 0.661842942237854  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 317 learning rate: 0.001 Training Loss: 0.6613026261329651 Validation Loss: 0.661810040473938  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 318 learning rate: 0.001 Training Loss: 0.6612738966941833 Validation Loss: 0.6617773175239563  accuracy_train: 0.7613 accuracy_test: 0.7544 \n",
            "Epoch: 319 learning rate: 0.001 Training Loss: 0.6612452268600464 Validation Loss: 0.6617445349693298  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 320 learning rate: 0.001 Training Loss: 0.6612163186073303 Validation Loss: 0.6617117524147034  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 321 learning rate: 0.001 Training Loss: 0.6611875891685486 Validation Loss: 0.6616790294647217  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 322 learning rate: 0.001 Training Loss: 0.6611589789390564 Validation Loss: 0.6616461873054504  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 323 learning rate: 0.001 Training Loss: 0.661130428314209 Validation Loss: 0.6616135239601135  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 324 learning rate: 0.001 Training Loss: 0.6611014008522034 Validation Loss: 0.6615806818008423  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 325 learning rate: 0.001 Training Loss: 0.6610727906227112 Validation Loss: 0.6615478992462158  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 326 learning rate: 0.001 Training Loss: 0.6610439419746399 Validation Loss: 0.6615151762962341  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 327 learning rate: 0.001 Training Loss: 0.6610153913497925 Validation Loss: 0.6614823937416077  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 328 learning rate: 0.001 Training Loss: 0.6609866619110107 Validation Loss: 0.661449670791626  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 329 learning rate: 0.001 Training Loss: 0.6609578132629395 Validation Loss: 0.6614169478416443  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 330 learning rate: 0.001 Training Loss: 0.6609290838241577 Validation Loss: 0.6613841652870178  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 331 learning rate: 0.001 Training Loss: 0.6609004139900208 Validation Loss: 0.6613514423370361  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 332 learning rate: 0.001 Training Loss: 0.6608717441558838 Validation Loss: 0.6613186597824097  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 333 learning rate: 0.001 Training Loss: 0.6608431339263916 Validation Loss: 0.6612859964370728  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 334 learning rate: 0.001 Training Loss: 0.6608144640922546 Validation Loss: 0.6612531542778015  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 335 learning rate: 0.001 Training Loss: 0.6607856750488281 Validation Loss: 0.6612204909324646  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 336 learning rate: 0.001 Training Loss: 0.6607569456100464 Validation Loss: 0.6611878275871277  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 337 learning rate: 0.001 Training Loss: 0.6607282757759094 Validation Loss: 0.661155104637146  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 338 learning rate: 0.001 Training Loss: 0.6606996059417725 Validation Loss: 0.6611224412918091  accuracy_train: 0.7638 accuracy_test: 0.7544 \n",
            "Epoch: 339 learning rate: 0.001 Training Loss: 0.6606709361076355 Validation Loss: 0.6610895991325378  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 340 learning rate: 0.001 Training Loss: 0.6606422066688538 Validation Loss: 0.6610570549964905  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 341 learning rate: 0.001 Training Loss: 0.6606135368347168 Validation Loss: 0.6610243320465088  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 342 learning rate: 0.001 Training Loss: 0.6605848073959351 Validation Loss: 0.6609916687011719  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 343 learning rate: 0.001 Training Loss: 0.6605563759803772 Validation Loss: 0.6609588265419006  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 344 learning rate: 0.001 Training Loss: 0.6605275273323059 Validation Loss: 0.6609262228012085  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 345 learning rate: 0.001 Training Loss: 0.6604989171028137 Validation Loss: 0.6608935594558716  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 346 learning rate: 0.001 Training Loss: 0.6604700684547424 Validation Loss: 0.6608608365058899  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 347 learning rate: 0.001 Training Loss: 0.6604415774345398 Validation Loss: 0.6608281135559082  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 348 learning rate: 0.001 Training Loss: 0.6604129076004028 Validation Loss: 0.6607955098152161  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 349 learning rate: 0.001 Training Loss: 0.6603841185569763 Validation Loss: 0.6607628464698792  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 350 learning rate: 0.001 Training Loss: 0.6603556871414185 Validation Loss: 0.6607301235198975  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 351 learning rate: 0.001 Training Loss: 0.6603268384933472 Validation Loss: 0.6606974601745605  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 352 learning rate: 0.001 Training Loss: 0.660298228263855 Validation Loss: 0.6606647968292236  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 353 learning rate: 0.001 Training Loss: 0.6602697372436523 Validation Loss: 0.6606321930885315  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 354 learning rate: 0.001 Training Loss: 0.6602410078048706 Validation Loss: 0.6605995297431946  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 355 learning rate: 0.001 Training Loss: 0.6602122783660889 Validation Loss: 0.6605669260025024  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 356 learning rate: 0.001 Training Loss: 0.660183846950531 Validation Loss: 0.6605342626571655  accuracy_train: 0.7663 accuracy_test: 0.7544 \n",
            "Epoch: 357 learning rate: 0.001 Training Loss: 0.6601552367210388 Validation Loss: 0.6605015993118286  accuracy_train: 0.7663 accuracy_test: 0.7602 \n",
            "Epoch: 358 learning rate: 0.001 Training Loss: 0.6601265072822571 Validation Loss: 0.6604689955711365  accuracy_train: 0.7663 accuracy_test: 0.7602 \n",
            "Epoch: 359 learning rate: 0.001 Training Loss: 0.6600978970527649 Validation Loss: 0.6604363918304443  accuracy_train: 0.7663 accuracy_test: 0.7602 \n",
            "Epoch: 360 learning rate: 0.001 Training Loss: 0.6600692272186279 Validation Loss: 0.6604037880897522  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 361 learning rate: 0.001 Training Loss: 0.660040557384491 Validation Loss: 0.6603710055351257  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 362 learning rate: 0.001 Training Loss: 0.6600120067596436 Validation Loss: 0.6603384613990784  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 363 learning rate: 0.001 Training Loss: 0.6599833965301514 Validation Loss: 0.6603058576583862  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 364 learning rate: 0.001 Training Loss: 0.659954845905304 Validation Loss: 0.6602732539176941  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 365 learning rate: 0.001 Training Loss: 0.6599262356758118 Validation Loss: 0.6602405309677124  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 366 learning rate: 0.001 Training Loss: 0.6598974466323853 Validation Loss: 0.660207986831665  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 367 learning rate: 0.001 Training Loss: 0.6598690152168274 Validation Loss: 0.6601755023002625  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 368 learning rate: 0.001 Training Loss: 0.6598404049873352 Validation Loss: 0.6601427793502808  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 369 learning rate: 0.001 Training Loss: 0.6598117351531982 Validation Loss: 0.6601102352142334  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 370 learning rate: 0.001 Training Loss: 0.6597832441329956 Validation Loss: 0.6600776314735413  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 371 learning rate: 0.001 Training Loss: 0.6597545146942139 Validation Loss: 0.6600450277328491  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 372 learning rate: 0.001 Training Loss: 0.6597259640693665 Validation Loss: 0.6600124835968018  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 373 learning rate: 0.001 Training Loss: 0.6596973538398743 Validation Loss: 0.6599799990653992  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 374 learning rate: 0.001 Training Loss: 0.6596688032150269 Validation Loss: 0.6599473357200623  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 375 learning rate: 0.001 Training Loss: 0.6596401333808899 Validation Loss: 0.6599146723747253  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 376 learning rate: 0.001 Training Loss: 0.6596115231513977 Validation Loss: 0.659882128238678  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 377 learning rate: 0.001 Training Loss: 0.6595830321311951 Validation Loss: 0.6598495841026306  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 378 learning rate: 0.001 Training Loss: 0.659554660320282 Validation Loss: 0.659817099571228  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 379 learning rate: 0.001 Training Loss: 0.659525990486145 Validation Loss: 0.6597845554351807  accuracy_train: 0.7688 accuracy_test: 0.7602 \n",
            "Epoch: 380 learning rate: 0.001 Training Loss: 0.6594973802566528 Validation Loss: 0.6597520112991333  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 381 learning rate: 0.001 Training Loss: 0.6594688296318054 Validation Loss: 0.6597194671630859  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 382 learning rate: 0.001 Training Loss: 0.6594401597976685 Validation Loss: 0.6596868634223938  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 383 learning rate: 0.001 Training Loss: 0.659411609172821 Validation Loss: 0.6596543192863464  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 384 learning rate: 0.001 Training Loss: 0.6593831181526184 Validation Loss: 0.6596217751502991  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 385 learning rate: 0.001 Training Loss: 0.6593546867370605 Validation Loss: 0.6595892310142517  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 386 learning rate: 0.001 Training Loss: 0.659325897693634 Validation Loss: 0.6595568060874939  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 387 learning rate: 0.001 Training Loss: 0.6592974662780762 Validation Loss: 0.659524142742157  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 388 learning rate: 0.001 Training Loss: 0.6592690348625183 Validation Loss: 0.6594915986061096  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 389 learning rate: 0.001 Training Loss: 0.6592404842376709 Validation Loss: 0.6594591736793518  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 390 learning rate: 0.001 Training Loss: 0.6592118740081787 Validation Loss: 0.6594266295433044  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 391 learning rate: 0.001 Training Loss: 0.6591834425926208 Validation Loss: 0.6593941450119019  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 392 learning rate: 0.001 Training Loss: 0.6591548323631287 Validation Loss: 0.6593616604804993  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 393 learning rate: 0.001 Training Loss: 0.6591261625289917 Validation Loss: 0.6593291759490967  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 394 learning rate: 0.001 Training Loss: 0.6590977311134338 Validation Loss: 0.6592966914176941  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 395 learning rate: 0.001 Training Loss: 0.6590691804885864 Validation Loss: 0.6592641472816467  accuracy_train: 0.7688 accuracy_test: 0.7661 \n",
            "Epoch: 396 learning rate: 0.001 Training Loss: 0.6590406894683838 Validation Loss: 0.6592316627502441  accuracy_train: 0.7688 accuracy_test: 0.7719 \n",
            "Epoch: 397 learning rate: 0.001 Training Loss: 0.6590120792388916 Validation Loss: 0.6591991186141968  accuracy_train: 0.7688 accuracy_test: 0.7719 \n",
            "Epoch: 398 learning rate: 0.001 Training Loss: 0.6589837074279785 Validation Loss: 0.6591666340827942  accuracy_train: 0.7688 accuracy_test: 0.7719 \n",
            "Epoch: 399 learning rate: 0.001 Training Loss: 0.6589551568031311 Validation Loss: 0.6591342687606812  accuracy_train: 0.7688 accuracy_test: 0.7719 \n",
            "Epoch: 400 learning rate: 0.001 Training Loss: 0.6589266657829285 Validation Loss: 0.659101665019989  accuracy_train: 0.7688 accuracy_test: 0.7719 \n",
            "Epoch: 401 learning rate: 0.001 Training Loss: 0.6588982939720154 Validation Loss: 0.6590692400932312  accuracy_train: 0.7688 accuracy_test: 0.7719 \n",
            "Epoch: 402 learning rate: 0.001 Training Loss: 0.6588696241378784 Validation Loss: 0.6590367555618286  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 403 learning rate: 0.001 Training Loss: 0.6588411331176758 Validation Loss: 0.659004271030426  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 404 learning rate: 0.001 Training Loss: 0.6588127613067627 Validation Loss: 0.6589717864990234  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 405 learning rate: 0.001 Training Loss: 0.6587842702865601 Validation Loss: 0.6589394211769104  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 406 learning rate: 0.001 Training Loss: 0.6587556600570679 Validation Loss: 0.658906877040863  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 407 learning rate: 0.001 Training Loss: 0.6587271094322205 Validation Loss: 0.65887451171875  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 408 learning rate: 0.001 Training Loss: 0.6586986184120178 Validation Loss: 0.6588420867919922  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 409 learning rate: 0.001 Training Loss: 0.6586700677871704 Validation Loss: 0.6588096022605896  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 410 learning rate: 0.001 Training Loss: 0.6586416363716125 Validation Loss: 0.6587770581245422  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 411 learning rate: 0.001 Training Loss: 0.6586133241653442 Validation Loss: 0.658744752407074  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 412 learning rate: 0.001 Training Loss: 0.6585848927497864 Validation Loss: 0.6587123274803162  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 413 learning rate: 0.001 Training Loss: 0.6585562229156494 Validation Loss: 0.6586796641349792  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 414 learning rate: 0.001 Training Loss: 0.6585278511047363 Validation Loss: 0.658647358417511  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 415 learning rate: 0.001 Training Loss: 0.6584992408752441 Validation Loss: 0.658614993095398  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 416 learning rate: 0.001 Training Loss: 0.6584709882736206 Validation Loss: 0.6585824489593506  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 417 learning rate: 0.001 Training Loss: 0.658442497253418 Validation Loss: 0.6585502028465271  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 418 learning rate: 0.001 Training Loss: 0.6584140658378601 Validation Loss: 0.6585177183151245  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 419 learning rate: 0.001 Training Loss: 0.6583854556083679 Validation Loss: 0.6584851741790771  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 420 learning rate: 0.001 Training Loss: 0.6583570241928101 Validation Loss: 0.6584529280662537  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 421 learning rate: 0.001 Training Loss: 0.6583284735679626 Validation Loss: 0.6584205031394958  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 422 learning rate: 0.001 Training Loss: 0.6583002209663391 Validation Loss: 0.6583880186080933  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 423 learning rate: 0.001 Training Loss: 0.6582717299461365 Validation Loss: 0.658355712890625  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 424 learning rate: 0.001 Training Loss: 0.6582434773445129 Validation Loss: 0.6583232879638672  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 425 learning rate: 0.001 Training Loss: 0.6582148671150208 Validation Loss: 0.6582910418510437  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 426 learning rate: 0.001 Training Loss: 0.6581864356994629 Validation Loss: 0.6582585573196411  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 427 learning rate: 0.001 Training Loss: 0.6581579446792603 Validation Loss: 0.6582260727882385  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 428 learning rate: 0.001 Training Loss: 0.6581295132637024 Validation Loss: 0.658193826675415  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 429 learning rate: 0.001 Training Loss: 0.6581011414527893 Validation Loss: 0.6581614017486572  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 430 learning rate: 0.001 Training Loss: 0.6580727100372314 Validation Loss: 0.6581290364265442  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 431 learning rate: 0.001 Training Loss: 0.6580442786216736 Validation Loss: 0.6580967903137207  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 432 learning rate: 0.001 Training Loss: 0.6580159068107605 Validation Loss: 0.6580644249916077  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 433 learning rate: 0.001 Training Loss: 0.6579874157905579 Validation Loss: 0.6580320000648499  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 434 learning rate: 0.001 Training Loss: 0.6579589247703552 Validation Loss: 0.6579996347427368  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 435 learning rate: 0.001 Training Loss: 0.6579307913780212 Validation Loss: 0.6579673290252686  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 436 learning rate: 0.001 Training Loss: 0.6579023003578186 Validation Loss: 0.6579349637031555  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 437 learning rate: 0.001 Training Loss: 0.657873809337616 Validation Loss: 0.657902717590332  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 438 learning rate: 0.001 Training Loss: 0.6578454375267029 Validation Loss: 0.657870352268219  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 439 learning rate: 0.001 Training Loss: 0.6578171253204346 Validation Loss: 0.6578380465507507  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 440 learning rate: 0.001 Training Loss: 0.6577886343002319 Validation Loss: 0.6578057408332825  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 441 learning rate: 0.001 Training Loss: 0.6577602624893188 Validation Loss: 0.6577733159065247  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 442 learning rate: 0.001 Training Loss: 0.6577319502830505 Validation Loss: 0.6577410101890564  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 443 learning rate: 0.001 Training Loss: 0.6577035188674927 Validation Loss: 0.6577085852622986  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 444 learning rate: 0.001 Training Loss: 0.6576752066612244 Validation Loss: 0.6576763391494751  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 445 learning rate: 0.001 Training Loss: 0.6576467752456665 Validation Loss: 0.6576439738273621  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 446 learning rate: 0.001 Training Loss: 0.6576184034347534 Validation Loss: 0.6576116681098938  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 447 learning rate: 0.001 Training Loss: 0.6575899124145508 Validation Loss: 0.6575794816017151  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 448 learning rate: 0.001 Training Loss: 0.6575615406036377 Validation Loss: 0.6575470566749573  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 449 learning rate: 0.001 Training Loss: 0.6575332880020142 Validation Loss: 0.657514750957489  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 450 learning rate: 0.001 Training Loss: 0.6575049757957458 Validation Loss: 0.6574825644493103  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 451 learning rate: 0.001 Training Loss: 0.657476544380188 Validation Loss: 0.6574501991271973  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 452 learning rate: 0.001 Training Loss: 0.6574481725692749 Validation Loss: 0.657417893409729  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 453 learning rate: 0.001 Training Loss: 0.6574198007583618 Validation Loss: 0.6573857665061951  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 454 learning rate: 0.001 Training Loss: 0.6573914885520935 Validation Loss: 0.6573533415794373  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 455 learning rate: 0.001 Training Loss: 0.6573631167411804 Validation Loss: 0.6573212146759033  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 456 learning rate: 0.001 Training Loss: 0.6573348045349121 Validation Loss: 0.6572889089584351  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 457 learning rate: 0.001 Training Loss: 0.6573063135147095 Validation Loss: 0.657256543636322  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 458 learning rate: 0.001 Training Loss: 0.6572780013084412 Validation Loss: 0.6572242975234985  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 459 learning rate: 0.001 Training Loss: 0.6572498679161072 Validation Loss: 0.6571919918060303  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 460 learning rate: 0.001 Training Loss: 0.6572213768959045 Validation Loss: 0.6571597456932068  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 461 learning rate: 0.001 Training Loss: 0.6571930646896362 Validation Loss: 0.6571276187896729  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 462 learning rate: 0.001 Training Loss: 0.6571646928787231 Validation Loss: 0.6570952534675598  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 463 learning rate: 0.001 Training Loss: 0.6571363806724548 Validation Loss: 0.6570632457733154  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 464 learning rate: 0.001 Training Loss: 0.6571080684661865 Validation Loss: 0.6570308208465576  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 465 learning rate: 0.001 Training Loss: 0.6570796966552734 Validation Loss: 0.6569986343383789  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 466 learning rate: 0.001 Training Loss: 0.6570514440536499 Validation Loss: 0.6569664478302002  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 467 learning rate: 0.001 Training Loss: 0.6570231318473816 Validation Loss: 0.6569341421127319  accuracy_train: 0.7714 accuracy_test: 0.7719 \n",
            "Epoch: 468 learning rate: 0.001 Training Loss: 0.6569947600364685 Validation Loss: 0.6569018959999084  accuracy_train: 0.7714 accuracy_test: 0.7778 \n",
            "Epoch: 469 learning rate: 0.001 Training Loss: 0.6569665670394897 Validation Loss: 0.6568697094917297  accuracy_train: 0.7714 accuracy_test: 0.7778 \n",
            "Epoch: 470 learning rate: 0.001 Training Loss: 0.6569380760192871 Validation Loss: 0.6568374037742615  accuracy_train: 0.7714 accuracy_test: 0.7778 \n",
            "Epoch: 471 learning rate: 0.001 Training Loss: 0.656909704208374 Validation Loss: 0.6568050980567932  accuracy_train: 0.7714 accuracy_test: 0.7778 \n",
            "Epoch: 472 learning rate: 0.001 Training Loss: 0.6568814516067505 Validation Loss: 0.656773030757904  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 473 learning rate: 0.001 Training Loss: 0.6568533182144165 Validation Loss: 0.6567407250404358  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 474 learning rate: 0.001 Training Loss: 0.6568248271942139 Validation Loss: 0.6567085385322571  accuracy_train: 0.7739 accuracy_test: 0.7836 \n",
            "Epoch: 475 learning rate: 0.001 Training Loss: 0.6567965745925903 Validation Loss: 0.6566763520240784  accuracy_train: 0.7739 accuracy_test: 0.7836 \n",
            "Epoch: 476 learning rate: 0.001 Training Loss: 0.656768262386322 Validation Loss: 0.6566442251205444  accuracy_train: 0.7739 accuracy_test: 0.7836 \n",
            "Epoch: 477 learning rate: 0.001 Training Loss: 0.656740128993988 Validation Loss: 0.6566120386123657  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 478 learning rate: 0.001 Training Loss: 0.6567118167877197 Validation Loss: 0.6565799117088318  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 479 learning rate: 0.001 Training Loss: 0.6566834449768066 Validation Loss: 0.6565476059913635  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 480 learning rate: 0.001 Training Loss: 0.6566552519798279 Validation Loss: 0.6565155386924744  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 481 learning rate: 0.001 Training Loss: 0.6566269397735596 Validation Loss: 0.6564832925796509  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 482 learning rate: 0.001 Training Loss: 0.6565986275672913 Validation Loss: 0.6564509868621826  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 483 learning rate: 0.001 Training Loss: 0.6565703749656677 Validation Loss: 0.6564189195632935  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 484 learning rate: 0.001 Training Loss: 0.6565420627593994 Validation Loss: 0.6563867330551147  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 485 learning rate: 0.001 Training Loss: 0.6565137505531311 Validation Loss: 0.6563546061515808  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 486 learning rate: 0.001 Training Loss: 0.6564855575561523 Validation Loss: 0.6563224792480469  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 487 learning rate: 0.001 Training Loss: 0.6564573645591736 Validation Loss: 0.6562901735305786  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 488 learning rate: 0.001 Training Loss: 0.6564289927482605 Validation Loss: 0.6562581658363342  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 489 learning rate: 0.001 Training Loss: 0.656400740146637 Validation Loss: 0.6562260389328003  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 490 learning rate: 0.001 Training Loss: 0.656372606754303 Validation Loss: 0.6561939120292664  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 491 learning rate: 0.001 Training Loss: 0.656344473361969 Validation Loss: 0.6561617255210876  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 492 learning rate: 0.001 Training Loss: 0.6563160419464111 Validation Loss: 0.6561296582221985  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 493 learning rate: 0.001 Training Loss: 0.6562877297401428 Validation Loss: 0.656097412109375  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 494 learning rate: 0.001 Training Loss: 0.6562596559524536 Validation Loss: 0.6560652256011963  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 495 learning rate: 0.001 Training Loss: 0.6562312841415405 Validation Loss: 0.6560332179069519  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 496 learning rate: 0.001 Training Loss: 0.6562031507492065 Validation Loss: 0.6560009121894836  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 497 learning rate: 0.001 Training Loss: 0.6561748385429382 Validation Loss: 0.6559688448905945  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 498 learning rate: 0.001 Training Loss: 0.6561466455459595 Validation Loss: 0.6559367179870605  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 499 learning rate: 0.001 Training Loss: 0.6561183333396912 Validation Loss: 0.6559046506881714  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 500 learning rate: 0.001 Training Loss: 0.6560901403427124 Validation Loss: 0.6558725833892822  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 501 learning rate: 0.001 Training Loss: 0.6560618281364441 Validation Loss: 0.6558405160903931  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 502 learning rate: 0.001 Training Loss: 0.6560337543487549 Validation Loss: 0.6558084487915039  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 503 learning rate: 0.001 Training Loss: 0.6560055017471313 Validation Loss: 0.6557762622833252  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 504 learning rate: 0.001 Training Loss: 0.6559772491455078 Validation Loss: 0.6557442545890808  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 505 learning rate: 0.001 Training Loss: 0.6559491753578186 Validation Loss: 0.6557121872901917  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 506 learning rate: 0.001 Training Loss: 0.6559208035469055 Validation Loss: 0.6556800603866577  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 507 learning rate: 0.001 Training Loss: 0.6558926701545715 Validation Loss: 0.655647873878479  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 508 learning rate: 0.001 Training Loss: 0.6558644771575928 Validation Loss: 0.6556159257888794  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 509 learning rate: 0.001 Training Loss: 0.6558363437652588 Validation Loss: 0.6555837988853455  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 510 learning rate: 0.001 Training Loss: 0.6558080315589905 Validation Loss: 0.6555517315864563  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 511 learning rate: 0.001 Training Loss: 0.655780017375946 Validation Loss: 0.6555196046829224  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 512 learning rate: 0.001 Training Loss: 0.6557517647743225 Validation Loss: 0.6554874777793884  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 513 learning rate: 0.001 Training Loss: 0.6557236313819885 Validation Loss: 0.6554555296897888  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 514 learning rate: 0.001 Training Loss: 0.6556953191757202 Validation Loss: 0.6554234027862549  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 515 learning rate: 0.001 Training Loss: 0.6556671261787415 Validation Loss: 0.6553913354873657  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 516 learning rate: 0.001 Training Loss: 0.6556389331817627 Validation Loss: 0.6553593277931213  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 517 learning rate: 0.001 Training Loss: 0.6556107997894287 Validation Loss: 0.6553272604942322  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 518 learning rate: 0.001 Training Loss: 0.65558260679245 Validation Loss: 0.6552953124046326  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 519 learning rate: 0.001 Training Loss: 0.6555543541908264 Validation Loss: 0.6552631855010986  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 520 learning rate: 0.001 Training Loss: 0.6555262207984924 Validation Loss: 0.655231237411499  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 521 learning rate: 0.001 Training Loss: 0.6554980874061584 Validation Loss: 0.6551991701126099  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 522 learning rate: 0.001 Training Loss: 0.6554698944091797 Validation Loss: 0.6551671028137207  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 523 learning rate: 0.001 Training Loss: 0.6554418802261353 Validation Loss: 0.6551350951194763  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 524 learning rate: 0.001 Training Loss: 0.6554136276245117 Validation Loss: 0.6551030278205872  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 525 learning rate: 0.001 Training Loss: 0.655385434627533 Validation Loss: 0.6550710797309875  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 526 learning rate: 0.001 Training Loss: 0.6553572416305542 Validation Loss: 0.6550390124320984  accuracy_train: 0.7688 accuracy_test: 0.7836 \n",
            "Epoch: 527 learning rate: 0.001 Training Loss: 0.655329167842865 Validation Loss: 0.655007004737854  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 528 learning rate: 0.001 Training Loss: 0.6553009152412415 Validation Loss: 0.6549749374389648  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 529 learning rate: 0.001 Training Loss: 0.655272901058197 Validation Loss: 0.6549429893493652  accuracy_train: 0.7714 accuracy_test: 0.7836 \n",
            "Epoch: 530 learning rate: 0.001 Training Loss: 0.655244767665863 Validation Loss: 0.6549109220504761  accuracy_train: 0.7714 accuracy_test: 0.7895 \n",
            "Epoch: 531 learning rate: 0.001 Training Loss: 0.6552166938781738 Validation Loss: 0.654879093170166  accuracy_train: 0.7714 accuracy_test: 0.7895 \n",
            "Epoch: 532 learning rate: 0.001 Training Loss: 0.6551883220672607 Validation Loss: 0.6548471450805664  accuracy_train: 0.7714 accuracy_test: 0.7895 \n",
            "Epoch: 533 learning rate: 0.001 Training Loss: 0.6551601886749268 Validation Loss: 0.6548150777816772  accuracy_train: 0.7714 accuracy_test: 0.7895 \n",
            "Epoch: 534 learning rate: 0.001 Training Loss: 0.6551321744918823 Validation Loss: 0.6547830700874329  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 535 learning rate: 0.001 Training Loss: 0.6551040410995483 Validation Loss: 0.6547511219978333  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 536 learning rate: 0.001 Training Loss: 0.6550759077072144 Validation Loss: 0.6547191739082336  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 537 learning rate: 0.001 Training Loss: 0.6550477147102356 Validation Loss: 0.6546871066093445  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 538 learning rate: 0.001 Training Loss: 0.6550197005271912 Validation Loss: 0.6546552181243896  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 539 learning rate: 0.001 Training Loss: 0.6549915671348572 Validation Loss: 0.6546231508255005  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 540 learning rate: 0.001 Training Loss: 0.6549633741378784 Validation Loss: 0.6545913219451904  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 541 learning rate: 0.001 Training Loss: 0.654935359954834 Validation Loss: 0.6545591950416565  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 542 learning rate: 0.001 Training Loss: 0.6549074053764343 Validation Loss: 0.6545273661613464  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 543 learning rate: 0.001 Training Loss: 0.6548791527748108 Validation Loss: 0.654495358467102  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 544 learning rate: 0.001 Training Loss: 0.6548510789871216 Validation Loss: 0.654463529586792  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 545 learning rate: 0.001 Training Loss: 0.6548229455947876 Validation Loss: 0.6544315218925476  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 546 learning rate: 0.001 Training Loss: 0.6547948122024536 Validation Loss: 0.654399573802948  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 547 learning rate: 0.001 Training Loss: 0.654766857624054 Validation Loss: 0.6543675661087036  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 548 learning rate: 0.001 Training Loss: 0.6547385454177856 Validation Loss: 0.6543356776237488  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 549 learning rate: 0.001 Training Loss: 0.6547107100486755 Validation Loss: 0.6543037295341492  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 550 learning rate: 0.001 Training Loss: 0.654682457447052 Validation Loss: 0.6542718410491943  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 551 learning rate: 0.001 Training Loss: 0.6546544432640076 Validation Loss: 0.65423983335495  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 552 learning rate: 0.001 Training Loss: 0.6546263694763184 Validation Loss: 0.6542078852653503  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 553 learning rate: 0.001 Training Loss: 0.6545981168746948 Validation Loss: 0.6541759371757507  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 554 learning rate: 0.001 Training Loss: 0.6545701622962952 Validation Loss: 0.6541441082954407  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 555 learning rate: 0.001 Training Loss: 0.654542088508606 Validation Loss: 0.6541122198104858  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 556 learning rate: 0.001 Training Loss: 0.6545140147209167 Validation Loss: 0.654080331325531  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 557 learning rate: 0.001 Training Loss: 0.6544858813285828 Validation Loss: 0.6540483832359314  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 558 learning rate: 0.001 Training Loss: 0.6544581055641174 Validation Loss: 0.6540164947509766  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 559 learning rate: 0.001 Training Loss: 0.6544298529624939 Validation Loss: 0.6539847254753113  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 560 learning rate: 0.001 Training Loss: 0.6544018983840942 Validation Loss: 0.6539527773857117  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 561 learning rate: 0.001 Training Loss: 0.6543737053871155 Validation Loss: 0.6539208292961121  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 562 learning rate: 0.001 Training Loss: 0.6543458104133606 Validation Loss: 0.6538889408111572  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 563 learning rate: 0.001 Training Loss: 0.6543176770210266 Validation Loss: 0.6538571119308472  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 564 learning rate: 0.001 Training Loss: 0.6542896032333374 Validation Loss: 0.6538251638412476  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 565 learning rate: 0.001 Training Loss: 0.6542617082595825 Validation Loss: 0.6537933349609375  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 566 learning rate: 0.001 Training Loss: 0.6542335152626038 Validation Loss: 0.6537613868713379  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 567 learning rate: 0.001 Training Loss: 0.6542055606842041 Validation Loss: 0.6537295579910278  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 568 learning rate: 0.001 Training Loss: 0.6541774868965149 Validation Loss: 0.6536977291107178  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 569 learning rate: 0.001 Training Loss: 0.6541493535041809 Validation Loss: 0.6536659002304077  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 570 learning rate: 0.001 Training Loss: 0.654121458530426 Validation Loss: 0.6536340117454529  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 571 learning rate: 0.001 Training Loss: 0.654093325138092 Validation Loss: 0.6536021828651428  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 572 learning rate: 0.001 Training Loss: 0.6540654897689819 Validation Loss: 0.6535704135894775  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 573 learning rate: 0.001 Training Loss: 0.6540371775627136 Validation Loss: 0.6535384654998779  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 574 learning rate: 0.001 Training Loss: 0.6540094017982483 Validation Loss: 0.6535066366195679  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 575 learning rate: 0.001 Training Loss: 0.6539812684059143 Validation Loss: 0.6534748077392578  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 576 learning rate: 0.001 Training Loss: 0.6539532542228699 Validation Loss: 0.653442919254303  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 577 learning rate: 0.001 Training Loss: 0.6539252996444702 Validation Loss: 0.6534112691879272  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 578 learning rate: 0.001 Training Loss: 0.6538972854614258 Validation Loss: 0.6533792614936829  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 579 learning rate: 0.001 Training Loss: 0.6538693308830261 Validation Loss: 0.6533474922180176  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 580 learning rate: 0.001 Training Loss: 0.6538413166999817 Validation Loss: 0.6533156633377075  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 581 learning rate: 0.001 Training Loss: 0.6538131833076477 Validation Loss: 0.6532838344573975  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 582 learning rate: 0.001 Training Loss: 0.6537854075431824 Validation Loss: 0.6532519459724426  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 583 learning rate: 0.001 Training Loss: 0.6537572741508484 Validation Loss: 0.6532202959060669  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 584 learning rate: 0.001 Training Loss: 0.6537293791770935 Validation Loss: 0.6531884074211121  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 585 learning rate: 0.001 Training Loss: 0.6537011861801147 Validation Loss: 0.6531566381454468  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 586 learning rate: 0.001 Training Loss: 0.6536734104156494 Validation Loss: 0.6531247496604919  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 587 learning rate: 0.001 Training Loss: 0.6536453366279602 Validation Loss: 0.6530930399894714  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 588 learning rate: 0.001 Training Loss: 0.6536173820495605 Validation Loss: 0.6530612707138062  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 589 learning rate: 0.001 Training Loss: 0.6535893082618713 Validation Loss: 0.6530295014381409  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 590 learning rate: 0.001 Training Loss: 0.653561532497406 Validation Loss: 0.6529976725578308  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 591 learning rate: 0.001 Training Loss: 0.6535333395004272 Validation Loss: 0.6529659032821655  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 592 learning rate: 0.001 Training Loss: 0.6535055041313171 Validation Loss: 0.6529341340065002  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 593 learning rate: 0.001 Training Loss: 0.6534774303436279 Validation Loss: 0.652902364730835  accuracy_train: 0.7714 accuracy_test: 0.7953 \n",
            "Epoch: 594 learning rate: 0.001 Training Loss: 0.6534495949745178 Validation Loss: 0.6528705954551697  accuracy_train: 0.7739 accuracy_test: 0.7953 \n",
            "Epoch: 595 learning rate: 0.001 Training Loss: 0.6534215211868286 Validation Loss: 0.6528388261795044  accuracy_train: 0.7739 accuracy_test: 0.7953 \n",
            "Epoch: 596 learning rate: 0.001 Training Loss: 0.6533936262130737 Validation Loss: 0.6528071165084839  accuracy_train: 0.7739 accuracy_test: 0.7953 \n",
            "Epoch: 597 learning rate: 0.001 Training Loss: 0.6533656120300293 Validation Loss: 0.6527753472328186  accuracy_train: 0.7739 accuracy_test: 0.7953 \n",
            "Epoch: 598 learning rate: 0.001 Training Loss: 0.6533377766609192 Validation Loss: 0.6527435779571533  accuracy_train: 0.7739 accuracy_test: 0.7953 \n",
            "Epoch: 599 learning rate: 0.001 Training Loss: 0.6533098220825195 Validation Loss: 0.6527116894721985  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 600 learning rate: 0.001 Training Loss: 0.6532818078994751 Validation Loss: 0.652679979801178  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 601 learning rate: 0.001 Training Loss: 0.6532539129257202 Validation Loss: 0.6526483297348022  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 602 learning rate: 0.001 Training Loss: 0.6532260179519653 Validation Loss: 0.652616560459137  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 603 learning rate: 0.001 Training Loss: 0.6531980037689209 Validation Loss: 0.6525847911834717  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 604 learning rate: 0.001 Training Loss: 0.6531701683998108 Validation Loss: 0.6525530219078064  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 605 learning rate: 0.001 Training Loss: 0.6531420946121216 Validation Loss: 0.6525213718414307  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 606 learning rate: 0.001 Training Loss: 0.6531142592430115 Validation Loss: 0.6524895429611206  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 607 learning rate: 0.001 Training Loss: 0.653086245059967 Validation Loss: 0.6524578928947449  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 608 learning rate: 0.001 Training Loss: 0.6530582904815674 Validation Loss: 0.6524262428283691  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 609 learning rate: 0.001 Training Loss: 0.6530303955078125 Validation Loss: 0.6523945331573486  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 610 learning rate: 0.001 Training Loss: 0.6530025601387024 Validation Loss: 0.6523628234863281  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 611 learning rate: 0.001 Training Loss: 0.652974545955658 Validation Loss: 0.6523310542106628  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 612 learning rate: 0.001 Training Loss: 0.6529465913772583 Validation Loss: 0.6522993445396423  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 613 learning rate: 0.001 Training Loss: 0.652918815612793 Validation Loss: 0.6522676348686218  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 614 learning rate: 0.001 Training Loss: 0.6528907418251038 Validation Loss: 0.6522359848022461  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 615 learning rate: 0.001 Training Loss: 0.6528628468513489 Validation Loss: 0.6522043347358704  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 616 learning rate: 0.001 Training Loss: 0.652834951877594 Validation Loss: 0.6521725654602051  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 617 learning rate: 0.001 Training Loss: 0.6528071165084839 Validation Loss: 0.6521407961845398  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 618 learning rate: 0.001 Training Loss: 0.6527792811393738 Validation Loss: 0.6521091461181641  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 619 learning rate: 0.001 Training Loss: 0.6527512073516846 Validation Loss: 0.6520774960517883  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 620 learning rate: 0.001 Training Loss: 0.6527235507965088 Validation Loss: 0.6520457863807678  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 621 learning rate: 0.001 Training Loss: 0.6526955962181091 Validation Loss: 0.6520140767097473  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 622 learning rate: 0.001 Training Loss: 0.6526676416397095 Validation Loss: 0.6519825458526611  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 623 learning rate: 0.001 Training Loss: 0.6526398062705994 Validation Loss: 0.6519507765769958  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 624 learning rate: 0.001 Training Loss: 0.6526119112968445 Validation Loss: 0.6519191861152649  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 625 learning rate: 0.001 Training Loss: 0.6525840759277344 Validation Loss: 0.6518875360488892  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 626 learning rate: 0.001 Training Loss: 0.6525561213493347 Validation Loss: 0.6518558859825134  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 627 learning rate: 0.001 Training Loss: 0.6525282859802246 Validation Loss: 0.6518242359161377  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 628 learning rate: 0.001 Training Loss: 0.6525003910064697 Validation Loss: 0.6517927050590515  accuracy_train: 0.7764 accuracy_test: 0.8012 \n",
            "Epoch: 629 learning rate: 0.001 Training Loss: 0.6524724960327148 Validation Loss: 0.651760995388031  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 630 learning rate: 0.001 Training Loss: 0.65244460105896 Validation Loss: 0.6517292261123657  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 631 learning rate: 0.001 Training Loss: 0.6524168848991394 Validation Loss: 0.65169757604599  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 632 learning rate: 0.001 Training Loss: 0.6523890495300293 Validation Loss: 0.6516660451889038  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 633 learning rate: 0.001 Training Loss: 0.6523611545562744 Validation Loss: 0.6516342759132385  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 634 learning rate: 0.001 Training Loss: 0.65233314037323 Validation Loss: 0.6516028046607971  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 635 learning rate: 0.001 Training Loss: 0.6523054838180542 Validation Loss: 0.6515711545944214  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 636 learning rate: 0.001 Training Loss: 0.6522775292396545 Validation Loss: 0.6515395641326904  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 637 learning rate: 0.001 Training Loss: 0.652249813079834 Validation Loss: 0.6515079736709595  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 638 learning rate: 0.001 Training Loss: 0.6522217392921448 Validation Loss: 0.6514763236045837  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 639 learning rate: 0.001 Training Loss: 0.6521941423416138 Validation Loss: 0.6514446139335632  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 640 learning rate: 0.001 Training Loss: 0.6521660685539246 Validation Loss: 0.6514130234718323  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 641 learning rate: 0.001 Training Loss: 0.6521384716033936 Validation Loss: 0.6513814926147461  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 642 learning rate: 0.001 Training Loss: 0.6521105766296387 Validation Loss: 0.6513499021530151  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 643 learning rate: 0.001 Training Loss: 0.6520827412605286 Validation Loss: 0.6513183116912842  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 644 learning rate: 0.001 Training Loss: 0.6520548462867737 Validation Loss: 0.6512867212295532  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 645 learning rate: 0.001 Training Loss: 0.6520270109176636 Validation Loss: 0.6512551307678223  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 646 learning rate: 0.001 Training Loss: 0.651999294757843 Validation Loss: 0.6512235403060913  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 647 learning rate: 0.001 Training Loss: 0.6519714593887329 Validation Loss: 0.6511919498443604  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 648 learning rate: 0.001 Training Loss: 0.651943564414978 Validation Loss: 0.6511602997779846  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 649 learning rate: 0.001 Training Loss: 0.6519159078598022 Validation Loss: 0.6511288285255432  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 650 learning rate: 0.001 Training Loss: 0.6518880724906921 Validation Loss: 0.6510971188545227  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 651 learning rate: 0.001 Training Loss: 0.651860237121582 Validation Loss: 0.6510655879974365  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 652 learning rate: 0.001 Training Loss: 0.6518322825431824 Validation Loss: 0.6510340571403503  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 653 learning rate: 0.001 Training Loss: 0.6518046855926514 Validation Loss: 0.6510025262832642  accuracy_train: 0.7739 accuracy_test: 0.8012 \n",
            "Epoch: 654 learning rate: 0.001 Training Loss: 0.6517767906188965 Validation Loss: 0.6509709358215332  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 655 learning rate: 0.001 Training Loss: 0.6517491340637207 Validation Loss: 0.6509395241737366  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 656 learning rate: 0.001 Training Loss: 0.6517211198806763 Validation Loss: 0.6509078145027161  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 657 learning rate: 0.001 Training Loss: 0.6516934633255005 Validation Loss: 0.6508763432502747  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 658 learning rate: 0.001 Training Loss: 0.6516656875610352 Validation Loss: 0.6508448123931885  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 659 learning rate: 0.001 Training Loss: 0.6516377925872803 Validation Loss: 0.6508132219314575  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 660 learning rate: 0.001 Training Loss: 0.6516100764274597 Validation Loss: 0.6507817506790161  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 661 learning rate: 0.001 Training Loss: 0.6515821814537048 Validation Loss: 0.6507502198219299  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 662 learning rate: 0.001 Training Loss: 0.6515544056892395 Validation Loss: 0.6507187485694885  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 663 learning rate: 0.001 Training Loss: 0.6515267491340637 Validation Loss: 0.6506870985031128  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 664 learning rate: 0.001 Training Loss: 0.6514989137649536 Validation Loss: 0.6506556868553162  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 665 learning rate: 0.001 Training Loss: 0.6514710783958435 Validation Loss: 0.6506240367889404  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 666 learning rate: 0.001 Training Loss: 0.6514434218406677 Validation Loss: 0.6505926251411438  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 667 learning rate: 0.001 Training Loss: 0.6514157056808472 Validation Loss: 0.6505610942840576  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 668 learning rate: 0.001 Training Loss: 0.6513879895210266 Validation Loss: 0.6505296230316162  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 669 learning rate: 0.001 Training Loss: 0.651360034942627 Validation Loss: 0.65049809217453  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 670 learning rate: 0.001 Training Loss: 0.651332437992096 Validation Loss: 0.6504666805267334  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 671 learning rate: 0.001 Training Loss: 0.6513046026229858 Validation Loss: 0.6504351496696472  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 672 learning rate: 0.001 Training Loss: 0.6512770056724548 Validation Loss: 0.6504036784172058  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 673 learning rate: 0.001 Training Loss: 0.6512491106987 Validation Loss: 0.6503720879554749  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 674 learning rate: 0.001 Training Loss: 0.651221513748169 Validation Loss: 0.650340735912323  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 675 learning rate: 0.001 Training Loss: 0.6511937975883484 Validation Loss: 0.650309145450592  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 676 learning rate: 0.001 Training Loss: 0.6511659622192383 Validation Loss: 0.6502776741981506  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 677 learning rate: 0.001 Training Loss: 0.6511381268501282 Validation Loss: 0.650246262550354  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 678 learning rate: 0.001 Training Loss: 0.6511104702949524 Validation Loss: 0.6502147316932678  accuracy_train: 0.7739 accuracy_test: 0.8070 \n",
            "Epoch: 679 learning rate: 0.001 Training Loss: 0.6510828137397766 Validation Loss: 0.6501832604408264  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 680 learning rate: 0.001 Training Loss: 0.6510550379753113 Validation Loss: 0.6501518487930298  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 681 learning rate: 0.001 Training Loss: 0.6510272026062012 Validation Loss: 0.6501203775405884  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 682 learning rate: 0.001 Training Loss: 0.6509995460510254 Validation Loss: 0.650088906288147  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 683 learning rate: 0.001 Training Loss: 0.6509718298912048 Validation Loss: 0.6500574350357056  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 684 learning rate: 0.001 Training Loss: 0.650944173336029 Validation Loss: 0.6500260829925537  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 685 learning rate: 0.001 Training Loss: 0.6509164571762085 Validation Loss: 0.6499944925308228  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 686 learning rate: 0.001 Training Loss: 0.6508886218070984 Validation Loss: 0.6499631404876709  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 687 learning rate: 0.001 Training Loss: 0.6508611440658569 Validation Loss: 0.6499317288398743  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 688 learning rate: 0.001 Training Loss: 0.6508331298828125 Validation Loss: 0.6499003767967224  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 689 learning rate: 0.001 Training Loss: 0.6508055925369263 Validation Loss: 0.649868905544281  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 690 learning rate: 0.001 Training Loss: 0.6507778167724609 Validation Loss: 0.64983731508255  accuracy_train: 0.7764 accuracy_test: 0.8070 \n",
            "Epoch: 691 learning rate: 0.001 Training Loss: 0.6507501602172852 Validation Loss: 0.6498059034347534  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 692 learning rate: 0.001 Training Loss: 0.6507225632667542 Validation Loss: 0.6497746109962463  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 693 learning rate: 0.001 Training Loss: 0.650694727897644 Validation Loss: 0.6497430801391602  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 694 learning rate: 0.001 Training Loss: 0.650667130947113 Validation Loss: 0.6497116684913635  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 695 learning rate: 0.001 Training Loss: 0.650639533996582 Validation Loss: 0.6496803760528564  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 696 learning rate: 0.001 Training Loss: 0.6506118178367615 Validation Loss: 0.649648904800415  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 697 learning rate: 0.001 Training Loss: 0.6505841016769409 Validation Loss: 0.649617612361908  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 698 learning rate: 0.001 Training Loss: 0.6505565047264099 Validation Loss: 0.6495860815048218  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 699 learning rate: 0.001 Training Loss: 0.6505287885665894 Validation Loss: 0.6495547890663147  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 700 learning rate: 0.001 Training Loss: 0.6505009531974792 Validation Loss: 0.6495233178138733  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 701 learning rate: 0.001 Training Loss: 0.6504735350608826 Validation Loss: 0.6494919657707214  accuracy_train: 0.7764 accuracy_test: 0.8129 \n",
            "Epoch: 702 learning rate: 0.001 Training Loss: 0.6504457592964172 Validation Loss: 0.64946049451828  accuracy_train: 0.7764 accuracy_test: 0.8187 \n",
            "Epoch: 703 learning rate: 0.001 Training Loss: 0.650418221950531 Validation Loss: 0.6494291424751282  accuracy_train: 0.7764 accuracy_test: 0.8187 \n",
            "Epoch: 704 learning rate: 0.001 Training Loss: 0.6503903865814209 Validation Loss: 0.6493978500366211  accuracy_train: 0.7764 accuracy_test: 0.8187 \n",
            "Epoch: 705 learning rate: 0.001 Training Loss: 0.6503627896308899 Validation Loss: 0.6493664383888245  accuracy_train: 0.7764 accuracy_test: 0.8187 \n",
            "Epoch: 706 learning rate: 0.001 Training Loss: 0.6503351330757141 Validation Loss: 0.6493350267410278  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 707 learning rate: 0.001 Training Loss: 0.6503075361251831 Validation Loss: 0.6493037343025208  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 708 learning rate: 0.001 Training Loss: 0.6502797603607178 Validation Loss: 0.6492722630500793  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 709 learning rate: 0.001 Training Loss: 0.6502521634101868 Validation Loss: 0.6492409110069275  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 710 learning rate: 0.001 Training Loss: 0.6502246260643005 Validation Loss: 0.6492096185684204  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 711 learning rate: 0.001 Training Loss: 0.6501967906951904 Validation Loss: 0.649178147315979  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 712 learning rate: 0.001 Training Loss: 0.6501692533493042 Validation Loss: 0.6491468548774719  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 713 learning rate: 0.001 Training Loss: 0.6501415967941284 Validation Loss: 0.6491155624389648  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 714 learning rate: 0.001 Training Loss: 0.6501139998435974 Validation Loss: 0.6490841507911682  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 715 learning rate: 0.001 Training Loss: 0.6500862240791321 Validation Loss: 0.6490529179573059  accuracy_train: 0.7764 accuracy_test: 0.8246 \n",
            "Epoch: 716 learning rate: 0.001 Training Loss: 0.6500587463378906 Validation Loss: 0.649021565914154  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 717 learning rate: 0.001 Training Loss: 0.6500310301780701 Validation Loss: 0.6489901542663574  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 718 learning rate: 0.001 Training Loss: 0.6500034332275391 Validation Loss: 0.6489588618278503  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 719 learning rate: 0.001 Training Loss: 0.6499757766723633 Validation Loss: 0.6489274501800537  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 720 learning rate: 0.001 Training Loss: 0.6499481797218323 Validation Loss: 0.6488962173461914  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 721 learning rate: 0.001 Training Loss: 0.6499205231666565 Validation Loss: 0.6488648653030396  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 722 learning rate: 0.001 Training Loss: 0.6498929858207703 Validation Loss: 0.648833692073822  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 723 learning rate: 0.001 Training Loss: 0.6498653888702393 Validation Loss: 0.6488023996353149  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 724 learning rate: 0.001 Training Loss: 0.6498377323150635 Validation Loss: 0.6487708687782288  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 725 learning rate: 0.001 Training Loss: 0.6498101949691772 Validation Loss: 0.6487396359443665  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 726 learning rate: 0.001 Training Loss: 0.6497824788093567 Validation Loss: 0.6487083435058594  accuracy_train: 0.7789 accuracy_test: 0.8304 \n",
            "Epoch: 727 learning rate: 0.001 Training Loss: 0.64975506067276 Validation Loss: 0.6486771106719971  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 728 learning rate: 0.001 Training Loss: 0.6497272849082947 Validation Loss: 0.64864581823349  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 729 learning rate: 0.001 Training Loss: 0.6496997475624084 Validation Loss: 0.6486145257949829  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 730 learning rate: 0.001 Training Loss: 0.6496721506118774 Validation Loss: 0.648583173751831  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 731 learning rate: 0.001 Training Loss: 0.6496445536613464 Validation Loss: 0.648551881313324  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 732 learning rate: 0.001 Training Loss: 0.649617075920105 Validation Loss: 0.6485206484794617  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 733 learning rate: 0.001 Training Loss: 0.649589478969574 Validation Loss: 0.6484893560409546  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 734 learning rate: 0.001 Training Loss: 0.6495618224143982 Validation Loss: 0.6484581828117371  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 735 learning rate: 0.001 Training Loss: 0.649534285068512 Validation Loss: 0.64842689037323  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 736 learning rate: 0.001 Training Loss: 0.649506688117981 Validation Loss: 0.6483955979347229  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 737 learning rate: 0.001 Training Loss: 0.64947909116745 Validation Loss: 0.6483643054962158  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 738 learning rate: 0.001 Training Loss: 0.6494515538215637 Validation Loss: 0.648332953453064  accuracy_train: 0.7814 accuracy_test: 0.8304 \n",
            "Epoch: 739 learning rate: 0.001 Training Loss: 0.6494240164756775 Validation Loss: 0.6483017206192017  accuracy_train: 0.7839 accuracy_test: 0.8304 \n",
            "Epoch: 740 learning rate: 0.001 Training Loss: 0.6493963599205017 Validation Loss: 0.6482706069946289  accuracy_train: 0.7839 accuracy_test: 0.8304 \n",
            "Epoch: 741 learning rate: 0.001 Training Loss: 0.6493687629699707 Validation Loss: 0.6482393145561218  accuracy_train: 0.7839 accuracy_test: 0.8304 \n",
            "Epoch: 742 learning rate: 0.001 Training Loss: 0.649341344833374 Validation Loss: 0.6482080817222595  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 743 learning rate: 0.001 Training Loss: 0.6493136882781982 Validation Loss: 0.6481767892837524  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 744 learning rate: 0.001 Training Loss: 0.649286150932312 Validation Loss: 0.6481455564498901  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 745 learning rate: 0.001 Training Loss: 0.6492584943771362 Validation Loss: 0.6481143236160278  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 746 learning rate: 0.001 Training Loss: 0.6492310166358948 Validation Loss: 0.6480830311775208  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 747 learning rate: 0.001 Training Loss: 0.6492035984992981 Validation Loss: 0.648051917552948  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 748 learning rate: 0.001 Training Loss: 0.6491760015487671 Validation Loss: 0.6480206251144409  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 749 learning rate: 0.001 Training Loss: 0.6491485238075256 Validation Loss: 0.6479894518852234  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 750 learning rate: 0.001 Training Loss: 0.6491209268569946 Validation Loss: 0.6479581594467163  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 751 learning rate: 0.001 Training Loss: 0.6490933299064636 Validation Loss: 0.6479269862174988  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 752 learning rate: 0.001 Training Loss: 0.6490658521652222 Validation Loss: 0.6478958129882812  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 753 learning rate: 0.001 Training Loss: 0.6490382552146912 Validation Loss: 0.6478646397590637  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 754 learning rate: 0.001 Training Loss: 0.6490108966827393 Validation Loss: 0.6478334069252014  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 755 learning rate: 0.001 Training Loss: 0.6489832997322083 Validation Loss: 0.6478021144866943  accuracy_train: 0.7864 accuracy_test: 0.8304 \n",
            "Epoch: 756 learning rate: 0.001 Training Loss: 0.648955762386322 Validation Loss: 0.6477709412574768  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 757 learning rate: 0.001 Training Loss: 0.648928165435791 Validation Loss: 0.647739827632904  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 758 learning rate: 0.001 Training Loss: 0.6489008069038391 Validation Loss: 0.6477086544036865  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 759 learning rate: 0.001 Training Loss: 0.6488732099533081 Validation Loss: 0.6476774215698242  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 760 learning rate: 0.001 Training Loss: 0.6488455533981323 Validation Loss: 0.6476462483406067  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 761 learning rate: 0.001 Training Loss: 0.6488181352615356 Validation Loss: 0.6476150155067444  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 762 learning rate: 0.001 Training Loss: 0.6487905979156494 Validation Loss: 0.6475837826728821  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 763 learning rate: 0.001 Training Loss: 0.6487632989883423 Validation Loss: 0.6475527286529541  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 764 learning rate: 0.001 Training Loss: 0.6487356424331665 Validation Loss: 0.6475215554237366  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 765 learning rate: 0.001 Training Loss: 0.6487083435058594 Validation Loss: 0.6474904417991638  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 766 learning rate: 0.001 Training Loss: 0.6486807465553284 Validation Loss: 0.6474591493606567  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 767 learning rate: 0.001 Training Loss: 0.6486532688140869 Validation Loss: 0.647428035736084  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 768 learning rate: 0.001 Training Loss: 0.6486256718635559 Validation Loss: 0.6473968029022217  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 769 learning rate: 0.001 Training Loss: 0.648598313331604 Validation Loss: 0.6473658084869385  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 770 learning rate: 0.001 Training Loss: 0.6485707759857178 Validation Loss: 0.647334635257721  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 771 learning rate: 0.001 Training Loss: 0.6485432982444763 Validation Loss: 0.6473034620285034  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 772 learning rate: 0.001 Training Loss: 0.6485158801078796 Validation Loss: 0.6472723484039307  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 773 learning rate: 0.001 Training Loss: 0.6484883427619934 Validation Loss: 0.6472411155700684  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 774 learning rate: 0.001 Training Loss: 0.648460865020752 Validation Loss: 0.6472101807594299  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 775 learning rate: 0.001 Training Loss: 0.6484334468841553 Validation Loss: 0.6471790075302124  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 776 learning rate: 0.001 Training Loss: 0.648405909538269 Validation Loss: 0.6471477746963501  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 777 learning rate: 0.001 Training Loss: 0.6483785510063171 Validation Loss: 0.6471166610717773  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 778 learning rate: 0.001 Training Loss: 0.6483510732650757 Validation Loss: 0.6470855474472046  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 779 learning rate: 0.001 Training Loss: 0.648323655128479 Validation Loss: 0.6470544338226318  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 780 learning rate: 0.001 Training Loss: 0.6482961177825928 Validation Loss: 0.6470233201980591  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 781 learning rate: 0.001 Training Loss: 0.6482685804367065 Validation Loss: 0.6469923257827759  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 782 learning rate: 0.001 Training Loss: 0.6482412219047546 Validation Loss: 0.6469610929489136  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 783 learning rate: 0.001 Training Loss: 0.6482136249542236 Validation Loss: 0.6469299793243408  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 784 learning rate: 0.001 Training Loss: 0.6481863856315613 Validation Loss: 0.6468989849090576  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 785 learning rate: 0.001 Training Loss: 0.648158848285675 Validation Loss: 0.6468678116798401  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 786 learning rate: 0.001 Training Loss: 0.6481314301490784 Validation Loss: 0.6468368172645569  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 787 learning rate: 0.001 Training Loss: 0.6481039524078369 Validation Loss: 0.6468056440353394  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 788 learning rate: 0.001 Training Loss: 0.6480764746665955 Validation Loss: 0.6467745304107666  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 789 learning rate: 0.001 Training Loss: 0.6480490565299988 Validation Loss: 0.6467434763908386  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 790 learning rate: 0.001 Training Loss: 0.6480216979980469 Validation Loss: 0.6467124223709106  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 791 learning rate: 0.001 Training Loss: 0.6479942202568054 Validation Loss: 0.6466814279556274  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 792 learning rate: 0.001 Training Loss: 0.6479668021202087 Validation Loss: 0.6466503739356995  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 793 learning rate: 0.001 Training Loss: 0.6479395031929016 Validation Loss: 0.6466192007064819  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 794 learning rate: 0.001 Training Loss: 0.6479119658470154 Validation Loss: 0.646588146686554  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 795 learning rate: 0.001 Training Loss: 0.6478846669197083 Validation Loss: 0.6465570330619812  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 796 learning rate: 0.001 Training Loss: 0.6478571891784668 Validation Loss: 0.6465259790420532  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 797 learning rate: 0.001 Training Loss: 0.6478298306465149 Validation Loss: 0.6464949250221252  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 798 learning rate: 0.001 Training Loss: 0.6478022933006287 Validation Loss: 0.6464638710021973  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 799 learning rate: 0.001 Training Loss: 0.6477747559547424 Validation Loss: 0.6464329361915588  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 800 learning rate: 0.001 Training Loss: 0.6477474570274353 Validation Loss: 0.6464017629623413  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 801 learning rate: 0.001 Training Loss: 0.6477200984954834 Validation Loss: 0.6463708877563477  accuracy_train: 0.7889 accuracy_test: 0.8304 \n",
            "Epoch: 802 learning rate: 0.001 Training Loss: 0.6476927399635315 Validation Loss: 0.6463396549224854  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 803 learning rate: 0.001 Training Loss: 0.6476654410362244 Validation Loss: 0.6463087797164917  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 804 learning rate: 0.001 Training Loss: 0.6476379632949829 Validation Loss: 0.6462777256965637  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 805 learning rate: 0.001 Training Loss: 0.6476104855537415 Validation Loss: 0.6462466716766357  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 806 learning rate: 0.001 Training Loss: 0.6475831866264343 Validation Loss: 0.6462156772613525  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 807 learning rate: 0.001 Training Loss: 0.6475557684898376 Validation Loss: 0.6461846232414246  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 808 learning rate: 0.001 Training Loss: 0.6475284695625305 Validation Loss: 0.6461536884307861  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 809 learning rate: 0.001 Training Loss: 0.6475010514259338 Validation Loss: 0.6461225152015686  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 810 learning rate: 0.001 Training Loss: 0.6474737524986267 Validation Loss: 0.6460915207862854  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 811 learning rate: 0.001 Training Loss: 0.6474463939666748 Validation Loss: 0.646060585975647  accuracy_train: 0.7915 accuracy_test: 0.8304 \n",
            "Epoch: 812 learning rate: 0.001 Training Loss: 0.6474189162254333 Validation Loss: 0.646029531955719  accuracy_train: 0.7940 accuracy_test: 0.8304 \n",
            "Epoch: 813 learning rate: 0.001 Training Loss: 0.6473916172981262 Validation Loss: 0.6459985971450806  accuracy_train: 0.7940 accuracy_test: 0.8304 \n",
            "Epoch: 814 learning rate: 0.001 Training Loss: 0.6473641991615295 Validation Loss: 0.6459676027297974  accuracy_train: 0.7965 accuracy_test: 0.8304 \n",
            "Epoch: 815 learning rate: 0.001 Training Loss: 0.6473369002342224 Validation Loss: 0.6459365487098694  accuracy_train: 0.7965 accuracy_test: 0.8363 \n",
            "Epoch: 816 learning rate: 0.001 Training Loss: 0.6473094820976257 Validation Loss: 0.645905613899231  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 817 learning rate: 0.001 Training Loss: 0.6472821235656738 Validation Loss: 0.6458746194839478  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 818 learning rate: 0.001 Training Loss: 0.6472547650337219 Validation Loss: 0.6458437442779541  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 819 learning rate: 0.001 Training Loss: 0.64722740650177 Validation Loss: 0.6458126902580261  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 820 learning rate: 0.001 Training Loss: 0.6471999287605286 Validation Loss: 0.6457817554473877  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 821 learning rate: 0.001 Training Loss: 0.6471728086471558 Validation Loss: 0.6457508206367493  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 822 learning rate: 0.001 Training Loss: 0.6471453905105591 Validation Loss: 0.6457197666168213  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 823 learning rate: 0.001 Training Loss: 0.6471180319786072 Validation Loss: 0.6456888914108276  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 824 learning rate: 0.001 Training Loss: 0.6470907926559448 Validation Loss: 0.6456577777862549  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 825 learning rate: 0.001 Training Loss: 0.6470633745193481 Validation Loss: 0.6456269025802612  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 826 learning rate: 0.001 Training Loss: 0.6470360159873962 Validation Loss: 0.645595908164978  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 827 learning rate: 0.001 Training Loss: 0.6470087766647339 Validation Loss: 0.6455650329589844  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 828 learning rate: 0.001 Training Loss: 0.646981418132782 Validation Loss: 0.6455340385437012  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 829 learning rate: 0.001 Training Loss: 0.6469539403915405 Validation Loss: 0.6455031037330627  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 830 learning rate: 0.001 Training Loss: 0.6469267010688782 Validation Loss: 0.6454721689224243  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 831 learning rate: 0.001 Training Loss: 0.6468995213508606 Validation Loss: 0.6454412341117859  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 832 learning rate: 0.001 Training Loss: 0.6468721032142639 Validation Loss: 0.6454102396965027  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 833 learning rate: 0.001 Training Loss: 0.646844744682312 Validation Loss: 0.645379364490509  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 834 learning rate: 0.001 Training Loss: 0.6468174457550049 Validation Loss: 0.6453484892845154  accuracy_train: 0.7990 accuracy_test: 0.8363 \n",
            "Epoch: 835 learning rate: 0.001 Training Loss: 0.6467901468276978 Validation Loss: 0.6453174948692322  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 836 learning rate: 0.001 Training Loss: 0.6467628479003906 Validation Loss: 0.6452866196632385  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 837 learning rate: 0.001 Training Loss: 0.6467355489730835 Validation Loss: 0.6452556252479553  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 838 learning rate: 0.001 Training Loss: 0.6467083692550659 Validation Loss: 0.6452248096466064  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 839 learning rate: 0.001 Training Loss: 0.6466809511184692 Validation Loss: 0.645193874835968  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 840 learning rate: 0.001 Training Loss: 0.6466535925865173 Validation Loss: 0.6451629400253296  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 841 learning rate: 0.001 Training Loss: 0.646626353263855 Validation Loss: 0.6451320648193359  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 842 learning rate: 0.001 Training Loss: 0.6465991139411926 Validation Loss: 0.6451010704040527  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 843 learning rate: 0.001 Training Loss: 0.6465718746185303 Validation Loss: 0.6450702548027039  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 844 learning rate: 0.001 Training Loss: 0.6465445756912231 Validation Loss: 0.6450393795967102  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 845 learning rate: 0.001 Training Loss: 0.6465173363685608 Validation Loss: 0.6450085639953613  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 846 learning rate: 0.001 Training Loss: 0.6464899778366089 Validation Loss: 0.6449776291847229  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 847 learning rate: 0.001 Training Loss: 0.6464626789093018 Validation Loss: 0.6449466943740845  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 848 learning rate: 0.001 Training Loss: 0.646435558795929 Validation Loss: 0.6449158191680908  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 849 learning rate: 0.001 Training Loss: 0.6464081406593323 Validation Loss: 0.6448850035667419  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 850 learning rate: 0.001 Training Loss: 0.6463808417320251 Validation Loss: 0.6448540687561035  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 851 learning rate: 0.001 Training Loss: 0.6463536620140076 Validation Loss: 0.6448232531547546  accuracy_train: 0.7990 accuracy_test: 0.8421 \n",
            "Epoch: 852 learning rate: 0.001 Training Loss: 0.6463264226913452 Validation Loss: 0.6447924971580505  accuracy_train: 0.8015 accuracy_test: 0.8421 \n",
            "Epoch: 853 learning rate: 0.001 Training Loss: 0.6462989449501038 Validation Loss: 0.6447615027427673  accuracy_train: 0.8040 accuracy_test: 0.8421 \n",
            "Epoch: 854 learning rate: 0.001 Training Loss: 0.6462720036506653 Validation Loss: 0.6447306275367737  accuracy_train: 0.8040 accuracy_test: 0.8421 \n",
            "Epoch: 855 learning rate: 0.001 Training Loss: 0.6462447047233582 Validation Loss: 0.64469975233078  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 856 learning rate: 0.001 Training Loss: 0.6462172269821167 Validation Loss: 0.6446689367294312  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 857 learning rate: 0.001 Training Loss: 0.6461901068687439 Validation Loss: 0.6446381211280823  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 858 learning rate: 0.001 Training Loss: 0.6461628675460815 Validation Loss: 0.6446072459220886  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 859 learning rate: 0.001 Training Loss: 0.6461355686187744 Validation Loss: 0.644576370716095  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 860 learning rate: 0.001 Training Loss: 0.6461082696914673 Validation Loss: 0.6445455551147461  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 861 learning rate: 0.001 Training Loss: 0.6460812091827393 Validation Loss: 0.6445148587226868  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 862 learning rate: 0.001 Training Loss: 0.6460539102554321 Validation Loss: 0.6444839835166931  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 863 learning rate: 0.001 Training Loss: 0.646026611328125 Validation Loss: 0.6444531083106995  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 864 learning rate: 0.001 Training Loss: 0.6459994912147522 Validation Loss: 0.6444222331047058  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 865 learning rate: 0.001 Training Loss: 0.6459721922874451 Validation Loss: 0.6443915367126465  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 866 learning rate: 0.001 Training Loss: 0.6459449529647827 Validation Loss: 0.6443606615066528  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 867 learning rate: 0.001 Training Loss: 0.6459177136421204 Validation Loss: 0.6443299055099487  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 868 learning rate: 0.001 Training Loss: 0.6458905339241028 Validation Loss: 0.6442990899085999  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 869 learning rate: 0.001 Training Loss: 0.6458633542060852 Validation Loss: 0.6442682147026062  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 870 learning rate: 0.001 Training Loss: 0.6458360552787781 Validation Loss: 0.6442374587059021  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 871 learning rate: 0.001 Training Loss: 0.6458088755607605 Validation Loss: 0.6442065238952637  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 872 learning rate: 0.001 Training Loss: 0.6457816958427429 Validation Loss: 0.6441759467124939  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 873 learning rate: 0.001 Training Loss: 0.6457544565200806 Validation Loss: 0.6441450715065002  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 874 learning rate: 0.001 Training Loss: 0.6457273364067078 Validation Loss: 0.6441141963005066  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 875 learning rate: 0.001 Training Loss: 0.6456999778747559 Validation Loss: 0.6440833806991577  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 876 learning rate: 0.001 Training Loss: 0.6456726789474487 Validation Loss: 0.6440526843070984  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 877 learning rate: 0.001 Training Loss: 0.6456456780433655 Validation Loss: 0.6440219283103943  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 878 learning rate: 0.001 Training Loss: 0.6456183791160583 Validation Loss: 0.6439911127090454  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 879 learning rate: 0.001 Training Loss: 0.6455912590026855 Validation Loss: 0.6439603567123413  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 880 learning rate: 0.001 Training Loss: 0.645564079284668 Validation Loss: 0.643929660320282  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 881 learning rate: 0.001 Training Loss: 0.6455369591712952 Validation Loss: 0.6438988447189331  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 882 learning rate: 0.001 Training Loss: 0.6455097198486328 Validation Loss: 0.6438680291175842  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 883 learning rate: 0.001 Training Loss: 0.6454824805259705 Validation Loss: 0.6438372731208801  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 884 learning rate: 0.001 Training Loss: 0.6454553008079529 Validation Loss: 0.6438065767288208  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 885 learning rate: 0.001 Training Loss: 0.6454281210899353 Validation Loss: 0.6437758803367615  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 886 learning rate: 0.001 Training Loss: 0.6454010009765625 Validation Loss: 0.6437451839447021  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 887 learning rate: 0.001 Training Loss: 0.6453737616539001 Validation Loss: 0.6437143087387085  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 888 learning rate: 0.001 Training Loss: 0.6453466415405273 Validation Loss: 0.6436836123466492  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 889 learning rate: 0.001 Training Loss: 0.6453195810317993 Validation Loss: 0.6436529159545898  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 890 learning rate: 0.001 Training Loss: 0.6452924013137817 Validation Loss: 0.643622100353241  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 891 learning rate: 0.001 Training Loss: 0.6452651023864746 Validation Loss: 0.6435913443565369  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 892 learning rate: 0.001 Training Loss: 0.6452381610870361 Validation Loss: 0.6435606479644775  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 893 learning rate: 0.001 Training Loss: 0.6452109217643738 Validation Loss: 0.6435298919677734  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 894 learning rate: 0.001 Training Loss: 0.6451836824417114 Validation Loss: 0.6434992551803589  accuracy_train: 0.8040 accuracy_test: 0.8480 \n",
            "Epoch: 895 learning rate: 0.001 Training Loss: 0.6451566219329834 Validation Loss: 0.64346843957901  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 896 learning rate: 0.001 Training Loss: 0.645129382610321 Validation Loss: 0.6434378027915955  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 897 learning rate: 0.001 Training Loss: 0.645102322101593 Validation Loss: 0.6434070467948914  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 898 learning rate: 0.001 Training Loss: 0.6450751423835754 Validation Loss: 0.643376350402832  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 899 learning rate: 0.001 Training Loss: 0.6450480818748474 Validation Loss: 0.6433455944061279  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 900 learning rate: 0.001 Training Loss: 0.6450209021568298 Validation Loss: 0.6433149576187134  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 901 learning rate: 0.001 Training Loss: 0.6449936628341675 Validation Loss: 0.6432843208312988  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 902 learning rate: 0.001 Training Loss: 0.6449666023254395 Validation Loss: 0.64325350522995  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 903 learning rate: 0.001 Training Loss: 0.6449395418167114 Validation Loss: 0.6432229280471802  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 904 learning rate: 0.001 Training Loss: 0.6449123620986938 Validation Loss: 0.6431921124458313  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 905 learning rate: 0.001 Training Loss: 0.6448851823806763 Validation Loss: 0.6431615948677063  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 906 learning rate: 0.001 Training Loss: 0.6448581218719482 Validation Loss: 0.643130898475647  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 907 learning rate: 0.001 Training Loss: 0.6448310017585754 Validation Loss: 0.6431001424789429  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 908 learning rate: 0.001 Training Loss: 0.6448038220405579 Validation Loss: 0.6430695056915283  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 909 learning rate: 0.001 Training Loss: 0.6447767615318298 Validation Loss: 0.643038809299469  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 910 learning rate: 0.001 Training Loss: 0.6447497010231018 Validation Loss: 0.6430081725120544  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 911 learning rate: 0.001 Training Loss: 0.644722580909729 Validation Loss: 0.6429775953292847  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 912 learning rate: 0.001 Training Loss: 0.6446954011917114 Validation Loss: 0.6429468393325806  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 913 learning rate: 0.001 Training Loss: 0.6446683406829834 Validation Loss: 0.6429160833358765  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 914 learning rate: 0.001 Training Loss: 0.6446413397789001 Validation Loss: 0.6428854465484619  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 915 learning rate: 0.001 Training Loss: 0.6446141600608826 Validation Loss: 0.6428549289703369  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 916 learning rate: 0.001 Training Loss: 0.644586980342865 Validation Loss: 0.6428242325782776  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 917 learning rate: 0.001 Training Loss: 0.6445599794387817 Validation Loss: 0.642793595790863  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 918 learning rate: 0.001 Training Loss: 0.6445328593254089 Validation Loss: 0.6427628993988037  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 919 learning rate: 0.001 Training Loss: 0.6445057392120361 Validation Loss: 0.6427322030067444  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 920 learning rate: 0.001 Training Loss: 0.6444787383079529 Validation Loss: 0.6427016854286194  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 921 learning rate: 0.001 Training Loss: 0.6444516777992249 Validation Loss: 0.6426711082458496  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 922 learning rate: 0.001 Training Loss: 0.6444246172904968 Validation Loss: 0.6426404118537903  accuracy_train: 0.8065 accuracy_test: 0.8480 \n",
            "Epoch: 923 learning rate: 0.001 Training Loss: 0.644397497177124 Validation Loss: 0.6426097750663757  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 924 learning rate: 0.001 Training Loss: 0.6443703770637512 Validation Loss: 0.6425792574882507  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 925 learning rate: 0.001 Training Loss: 0.6443433165550232 Validation Loss: 0.6425486207008362  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 926 learning rate: 0.001 Training Loss: 0.6443161964416504 Validation Loss: 0.6425180435180664  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 927 learning rate: 0.001 Training Loss: 0.6442890763282776 Validation Loss: 0.6424872279167175  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 928 learning rate: 0.001 Training Loss: 0.6442621946334839 Validation Loss: 0.6424566507339478  accuracy_train: 0.8090 accuracy_test: 0.8538 \n",
            "Epoch: 929 learning rate: 0.001 Training Loss: 0.6442350745201111 Validation Loss: 0.6424261331558228  accuracy_train: 0.8090 accuracy_test: 0.8538 \n",
            "Epoch: 930 learning rate: 0.001 Training Loss: 0.6442080736160278 Validation Loss: 0.6423956155776978  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 931 learning rate: 0.001 Training Loss: 0.6441810131072998 Validation Loss: 0.6423649787902832  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 932 learning rate: 0.001 Training Loss: 0.644153892993927 Validation Loss: 0.6423344016075134  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 933 learning rate: 0.001 Training Loss: 0.6441269516944885 Validation Loss: 0.6423038840293884  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 934 learning rate: 0.001 Training Loss: 0.6440997123718262 Validation Loss: 0.6422731280326843  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 935 learning rate: 0.001 Training Loss: 0.6440727114677429 Validation Loss: 0.6422427296638489  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 936 learning rate: 0.001 Training Loss: 0.6440457105636597 Validation Loss: 0.6422120928764343  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 937 learning rate: 0.001 Training Loss: 0.6440187096595764 Validation Loss: 0.642181396484375  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 938 learning rate: 0.001 Training Loss: 0.6439916491508484 Validation Loss: 0.6421509385108948  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 939 learning rate: 0.001 Training Loss: 0.6439645290374756 Validation Loss: 0.6421203017234802  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 940 learning rate: 0.001 Training Loss: 0.6439375877380371 Validation Loss: 0.6420897841453552  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 941 learning rate: 0.001 Training Loss: 0.6439106464385986 Validation Loss: 0.6420592665672302  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 942 learning rate: 0.001 Training Loss: 0.6438835859298706 Validation Loss: 0.6420286893844604  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 943 learning rate: 0.001 Training Loss: 0.6438565850257874 Validation Loss: 0.6419981122016907  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 944 learning rate: 0.001 Training Loss: 0.6438295841217041 Validation Loss: 0.6419675946235657  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 945 learning rate: 0.001 Training Loss: 0.6438025236129761 Validation Loss: 0.6419370174407959  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 946 learning rate: 0.001 Training Loss: 0.6437755227088928 Validation Loss: 0.6419064998626709  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 947 learning rate: 0.001 Training Loss: 0.6437485218048096 Validation Loss: 0.6418758630752563  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 948 learning rate: 0.001 Training Loss: 0.6437214612960815 Validation Loss: 0.6418453454971313  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 949 learning rate: 0.001 Training Loss: 0.6436945199966431 Validation Loss: 0.6418148279190063  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 950 learning rate: 0.001 Training Loss: 0.643667459487915 Validation Loss: 0.6417844295501709  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 951 learning rate: 0.001 Training Loss: 0.643640398979187 Validation Loss: 0.6417537927627563  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 952 learning rate: 0.001 Training Loss: 0.6436135172843933 Validation Loss: 0.6417232155799866  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 953 learning rate: 0.001 Training Loss: 0.6435865163803101 Validation Loss: 0.6416927576065063  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 954 learning rate: 0.001 Training Loss: 0.6435595154762268 Validation Loss: 0.6416621804237366  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 955 learning rate: 0.001 Training Loss: 0.6435325145721436 Validation Loss: 0.6416317224502563  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 956 learning rate: 0.001 Training Loss: 0.6435054540634155 Validation Loss: 0.6416013240814209  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 957 learning rate: 0.001 Training Loss: 0.6434785723686218 Validation Loss: 0.6415706276893616  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 958 learning rate: 0.001 Training Loss: 0.643451452255249 Validation Loss: 0.6415402889251709  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 959 learning rate: 0.001 Training Loss: 0.6434245705604553 Validation Loss: 0.6415096521377563  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 960 learning rate: 0.001 Training Loss: 0.6433975696563721 Validation Loss: 0.6414791345596313  accuracy_train: 0.8065 accuracy_test: 0.8538 \n",
            "Epoch: 961 learning rate: 0.001 Training Loss: 0.6433705687522888 Validation Loss: 0.6414487361907959  accuracy_train: 0.8065 accuracy_test: 0.8596 \n",
            "Epoch: 962 learning rate: 0.001 Training Loss: 0.6433435082435608 Validation Loss: 0.6414182186126709  accuracy_train: 0.8065 accuracy_test: 0.8596 \n",
            "Epoch: 963 learning rate: 0.001 Training Loss: 0.6433166861534119 Validation Loss: 0.6413877606391907  accuracy_train: 0.8065 accuracy_test: 0.8596 \n",
            "Epoch: 964 learning rate: 0.001 Training Loss: 0.6432897448539734 Validation Loss: 0.6413571834564209  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 965 learning rate: 0.001 Training Loss: 0.6432626843452454 Validation Loss: 0.6413267254829407  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 966 learning rate: 0.001 Training Loss: 0.6432356834411621 Validation Loss: 0.6412962675094604  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 967 learning rate: 0.001 Training Loss: 0.6432088017463684 Validation Loss: 0.6412658095359802  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 968 learning rate: 0.001 Training Loss: 0.6431818008422852 Validation Loss: 0.6412354111671448  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 969 learning rate: 0.001 Training Loss: 0.6431548595428467 Validation Loss: 0.6412048935890198  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 970 learning rate: 0.001 Training Loss: 0.6431279182434082 Validation Loss: 0.6411743760108948  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 971 learning rate: 0.001 Training Loss: 0.6431009769439697 Validation Loss: 0.6411439776420593  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 972 learning rate: 0.001 Training Loss: 0.643074095249176 Validation Loss: 0.6411135792732239  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 973 learning rate: 0.001 Training Loss: 0.6430470943450928 Validation Loss: 0.6410830616950989  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 974 learning rate: 0.001 Training Loss: 0.6430202126502991 Validation Loss: 0.6410525441169739  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 975 learning rate: 0.001 Training Loss: 0.642993152141571 Validation Loss: 0.6410220861434937  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 976 learning rate: 0.001 Training Loss: 0.6429662704467773 Validation Loss: 0.640991747379303  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 977 learning rate: 0.001 Training Loss: 0.6429394483566284 Validation Loss: 0.6409612894058228  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 978 learning rate: 0.001 Training Loss: 0.6429124474525452 Validation Loss: 0.6409308314323425  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 979 learning rate: 0.001 Training Loss: 0.6428854465484619 Validation Loss: 0.6409004330635071  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 980 learning rate: 0.001 Training Loss: 0.6428585052490234 Validation Loss: 0.6408700346946716  accuracy_train: 0.8065 accuracy_test: 0.8655 \n",
            "Epoch: 981 learning rate: 0.001 Training Loss: 0.6428316831588745 Validation Loss: 0.6408395171165466  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 982 learning rate: 0.001 Training Loss: 0.6428046822547913 Validation Loss: 0.6408091187477112  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 983 learning rate: 0.001 Training Loss: 0.6427778601646423 Validation Loss: 0.6407787799835205  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 984 learning rate: 0.001 Training Loss: 0.6427508592605591 Validation Loss: 0.6407483220100403  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 985 learning rate: 0.001 Training Loss: 0.6427240967750549 Validation Loss: 0.6407179236412048  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 986 learning rate: 0.001 Training Loss: 0.6426970958709717 Validation Loss: 0.6406874656677246  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 987 learning rate: 0.001 Training Loss: 0.642670214176178 Validation Loss: 0.6406570076942444  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 988 learning rate: 0.001 Training Loss: 0.6426432728767395 Validation Loss: 0.6406266689300537  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 989 learning rate: 0.001 Training Loss: 0.6426163911819458 Validation Loss: 0.6405962109565735  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 990 learning rate: 0.001 Training Loss: 0.6425894498825073 Validation Loss: 0.6405658721923828  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 991 learning rate: 0.001 Training Loss: 0.6425625681877136 Validation Loss: 0.6405355334281921  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 992 learning rate: 0.001 Training Loss: 0.6425356268882751 Validation Loss: 0.6405050754547119  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 993 learning rate: 0.001 Training Loss: 0.6425087451934814 Validation Loss: 0.6404747366905212  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 994 learning rate: 0.001 Training Loss: 0.6424819231033325 Validation Loss: 0.640444278717041  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 995 learning rate: 0.001 Training Loss: 0.6424549221992493 Validation Loss: 0.6404139399528503  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 996 learning rate: 0.001 Training Loss: 0.6424281597137451 Validation Loss: 0.6403835415840149  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 997 learning rate: 0.001 Training Loss: 0.6424012184143066 Validation Loss: 0.6403531432151794  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 998 learning rate: 0.001 Training Loss: 0.6423743367195129 Validation Loss: 0.6403228640556335  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 999 learning rate: 0.001 Training Loss: 0.6423474550247192 Validation Loss: 0.6402924656867981  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 1000 learning rate: 0.001 Training Loss: 0.6423206925392151 Validation Loss: 0.6402621269226074  accuracy_train: 0.8065 accuracy_test: 0.8713 \n",
            "Epoch: 1001 learning rate: 0.001 Training Loss: 0.6422937512397766 Validation Loss: 0.640231728553772  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1002 learning rate: 0.001 Training Loss: 0.6422668695449829 Validation Loss: 0.6402013897895813  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1003 learning rate: 0.001 Training Loss: 0.6422401070594788 Validation Loss: 0.6401710510253906  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1004 learning rate: 0.001 Training Loss: 0.6422131657600403 Validation Loss: 0.6401407122612  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1005 learning rate: 0.001 Training Loss: 0.6421863436698914 Validation Loss: 0.6401103138923645  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1006 learning rate: 0.001 Training Loss: 0.6421594023704529 Validation Loss: 0.6400800347328186  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1007 learning rate: 0.001 Training Loss: 0.6421326398849487 Validation Loss: 0.6400496959686279  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1008 learning rate: 0.001 Training Loss: 0.6421058177947998 Validation Loss: 0.6400192975997925  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1009 learning rate: 0.001 Training Loss: 0.6420788764953613 Validation Loss: 0.6399890780448914  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1010 learning rate: 0.001 Training Loss: 0.6420520544052124 Validation Loss: 0.6399586796760559  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1011 learning rate: 0.001 Training Loss: 0.6420252323150635 Validation Loss: 0.6399283409118652  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1012 learning rate: 0.001 Training Loss: 0.6419983506202698 Validation Loss: 0.6398979425430298  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1013 learning rate: 0.001 Training Loss: 0.6419714689254761 Validation Loss: 0.6398677229881287  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1014 learning rate: 0.001 Training Loss: 0.6419446468353271 Validation Loss: 0.6398375034332275  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1015 learning rate: 0.001 Training Loss: 0.6419179439544678 Validation Loss: 0.6398069858551025  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1016 learning rate: 0.001 Training Loss: 0.6418909430503845 Validation Loss: 0.6397767663002014  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1017 learning rate: 0.001 Training Loss: 0.6418640613555908 Validation Loss: 0.6397464871406555  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1018 learning rate: 0.001 Training Loss: 0.6418374180793762 Validation Loss: 0.6397160887718201  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1019 learning rate: 0.001 Training Loss: 0.6418105363845825 Validation Loss: 0.639685869216919  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1020 learning rate: 0.001 Training Loss: 0.6417837738990784 Validation Loss: 0.639655590057373  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1021 learning rate: 0.001 Training Loss: 0.6417568922042847 Validation Loss: 0.6396253108978271  accuracy_train: 0.8090 accuracy_test: 0.8713 \n",
            "Epoch: 1022 learning rate: 0.001 Training Loss: 0.641730010509491 Validation Loss: 0.6395950317382812  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1023 learning rate: 0.001 Training Loss: 0.6417033076286316 Validation Loss: 0.6395647525787354  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1024 learning rate: 0.001 Training Loss: 0.6416764259338379 Validation Loss: 0.6395344734191895  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1025 learning rate: 0.001 Training Loss: 0.6416495442390442 Validation Loss: 0.6395041346549988  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1026 learning rate: 0.001 Training Loss: 0.6416229009628296 Validation Loss: 0.6394739151000977  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1027 learning rate: 0.001 Training Loss: 0.6415960192680359 Validation Loss: 0.639443576335907  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1028 learning rate: 0.001 Training Loss: 0.6415692567825317 Validation Loss: 0.6394134163856506  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1029 learning rate: 0.001 Training Loss: 0.6415424942970276 Validation Loss: 0.6393830180168152  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1030 learning rate: 0.001 Training Loss: 0.6415157318115234 Validation Loss: 0.6393528580665588  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1031 learning rate: 0.001 Training Loss: 0.641488790512085 Validation Loss: 0.6393225789070129  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1032 learning rate: 0.001 Training Loss: 0.6414620280265808 Validation Loss: 0.6392923593521118  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1033 learning rate: 0.001 Training Loss: 0.6414353251457214 Validation Loss: 0.6392620801925659  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1034 learning rate: 0.001 Training Loss: 0.6414085030555725 Validation Loss: 0.6392317414283752  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1035 learning rate: 0.001 Training Loss: 0.6413817405700684 Validation Loss: 0.6392015814781189  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1036 learning rate: 0.001 Training Loss: 0.6413549780845642 Validation Loss: 0.6391712427139282  accuracy_train: 0.8116 accuracy_test: 0.8713 \n",
            "Epoch: 1037 learning rate: 0.001 Training Loss: 0.6413282155990601 Validation Loss: 0.6391411423683167  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1038 learning rate: 0.001 Training Loss: 0.6413013935089111 Validation Loss: 0.639110803604126  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1039 learning rate: 0.001 Training Loss: 0.641274631023407 Validation Loss: 0.6390805840492249  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1040 learning rate: 0.001 Training Loss: 0.6412478089332581 Validation Loss: 0.6390503644943237  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1041 learning rate: 0.001 Training Loss: 0.6412211656570435 Validation Loss: 0.6390202045440674  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1042 learning rate: 0.001 Training Loss: 0.6411943435668945 Validation Loss: 0.6389899253845215  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1043 learning rate: 0.001 Training Loss: 0.6411675810813904 Validation Loss: 0.6389595866203308  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1044 learning rate: 0.001 Training Loss: 0.6411407589912415 Validation Loss: 0.6389294266700745  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1045 learning rate: 0.001 Training Loss: 0.6411140561103821 Validation Loss: 0.6388992667198181  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1046 learning rate: 0.001 Training Loss: 0.6410873532295227 Validation Loss: 0.6388691067695618  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1047 learning rate: 0.001 Training Loss: 0.6410605311393738 Validation Loss: 0.6388389468193054  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1048 learning rate: 0.001 Training Loss: 0.6410338878631592 Validation Loss: 0.6388087272644043  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1049 learning rate: 0.001 Training Loss: 0.6410070657730103 Validation Loss: 0.638778567314148  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1050 learning rate: 0.001 Training Loss: 0.6409803032875061 Validation Loss: 0.6387482285499573  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1051 learning rate: 0.001 Training Loss: 0.6409536600112915 Validation Loss: 0.6387181282043457  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1052 learning rate: 0.001 Training Loss: 0.6409267783164978 Validation Loss: 0.6386878490447998  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1053 learning rate: 0.001 Training Loss: 0.6409000754356384 Validation Loss: 0.6386577486991882  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1054 learning rate: 0.001 Training Loss: 0.6408733129501343 Validation Loss: 0.6386275291442871  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1055 learning rate: 0.001 Training Loss: 0.6408466100692749 Validation Loss: 0.6385973691940308  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1056 learning rate: 0.001 Training Loss: 0.6408199667930603 Validation Loss: 0.6385671496391296  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1057 learning rate: 0.001 Training Loss: 0.6407931447029114 Validation Loss: 0.6385369896888733  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1058 learning rate: 0.001 Training Loss: 0.6407663822174072 Validation Loss: 0.6385068297386169  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1059 learning rate: 0.001 Training Loss: 0.6407396793365479 Validation Loss: 0.6384767889976501  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1060 learning rate: 0.001 Training Loss: 0.6407129764556885 Validation Loss: 0.6384464502334595  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1061 learning rate: 0.001 Training Loss: 0.6406863331794739 Validation Loss: 0.6384162902832031  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1062 learning rate: 0.001 Training Loss: 0.6406595706939697 Validation Loss: 0.6383861303329468  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1063 learning rate: 0.001 Training Loss: 0.6406328082084656 Validation Loss: 0.6383561491966248  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1064 learning rate: 0.001 Training Loss: 0.640606164932251 Validation Loss: 0.6383259296417236  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1065 learning rate: 0.001 Training Loss: 0.6405794024467468 Validation Loss: 0.6382957100868225  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1066 learning rate: 0.001 Training Loss: 0.6405527591705322 Validation Loss: 0.6382655501365662  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1067 learning rate: 0.001 Training Loss: 0.6405261158943176 Validation Loss: 0.6382355690002441  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1068 learning rate: 0.001 Training Loss: 0.6404992938041687 Validation Loss: 0.638205349445343  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1069 learning rate: 0.001 Training Loss: 0.6404727101325989 Validation Loss: 0.6381752490997314  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1070 learning rate: 0.001 Training Loss: 0.6404460668563843 Validation Loss: 0.6381450891494751  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1071 learning rate: 0.001 Training Loss: 0.6404193043708801 Validation Loss: 0.638114869594574  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1072 learning rate: 0.001 Training Loss: 0.640392541885376 Validation Loss: 0.6380847692489624  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1073 learning rate: 0.001 Training Loss: 0.6403658986091614 Validation Loss: 0.6380548477172852  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1074 learning rate: 0.001 Training Loss: 0.6403393149375916 Validation Loss: 0.6380245089530945  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1075 learning rate: 0.001 Training Loss: 0.6403125524520874 Validation Loss: 0.6379944682121277  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1076 learning rate: 0.001 Training Loss: 0.6402859091758728 Validation Loss: 0.6379643678665161  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1077 learning rate: 0.001 Training Loss: 0.6402592658996582 Validation Loss: 0.6379343271255493  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1078 learning rate: 0.001 Training Loss: 0.6402326226234436 Validation Loss: 0.6379042267799377  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1079 learning rate: 0.001 Training Loss: 0.6402058601379395 Validation Loss: 0.6378740072250366  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1080 learning rate: 0.001 Training Loss: 0.6401792168617249 Validation Loss: 0.6378439664840698  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1081 learning rate: 0.001 Training Loss: 0.640152633190155 Validation Loss: 0.6378138661384583  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1082 learning rate: 0.001 Training Loss: 0.6401258707046509 Validation Loss: 0.6377837657928467  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1083 learning rate: 0.001 Training Loss: 0.6400992274284363 Validation Loss: 0.6377537250518799  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1084 learning rate: 0.001 Training Loss: 0.6400726437568665 Validation Loss: 0.6377236247062683  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1085 learning rate: 0.001 Training Loss: 0.6400458812713623 Validation Loss: 0.6376935839653015  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1086 learning rate: 0.001 Training Loss: 0.6400192379951477 Validation Loss: 0.6376634836196899  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1087 learning rate: 0.001 Training Loss: 0.6399926543235779 Validation Loss: 0.6376334428787231  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1088 learning rate: 0.001 Training Loss: 0.6399660110473633 Validation Loss: 0.6376033425331116  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1089 learning rate: 0.001 Training Loss: 0.6399393677711487 Validation Loss: 0.6375731825828552  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1090 learning rate: 0.001 Training Loss: 0.6399127244949341 Validation Loss: 0.6375431418418884  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1091 learning rate: 0.001 Training Loss: 0.6398860216140747 Validation Loss: 0.6375131607055664  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1092 learning rate: 0.001 Training Loss: 0.6398594975471497 Validation Loss: 0.6374830603599548  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1093 learning rate: 0.001 Training Loss: 0.6398327946662903 Validation Loss: 0.6374529600143433  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1094 learning rate: 0.001 Training Loss: 0.6398061513900757 Validation Loss: 0.6374229788780212  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1095 learning rate: 0.001 Training Loss: 0.6397795677185059 Validation Loss: 0.6373929977416992  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1096 learning rate: 0.001 Training Loss: 0.639752984046936 Validation Loss: 0.6373628973960876  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1097 learning rate: 0.001 Training Loss: 0.6397262811660767 Validation Loss: 0.6373329162597656  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1098 learning rate: 0.001 Training Loss: 0.6396996974945068 Validation Loss: 0.6373028755187988  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1099 learning rate: 0.001 Training Loss: 0.6396731734275818 Validation Loss: 0.637272834777832  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1100 learning rate: 0.001 Training Loss: 0.6396465301513672 Validation Loss: 0.6372427940368652  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1101 learning rate: 0.001 Training Loss: 0.6396200060844421 Validation Loss: 0.6372126936912537  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1102 learning rate: 0.001 Training Loss: 0.6395931243896484 Validation Loss: 0.6371826529502869  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1103 learning rate: 0.001 Training Loss: 0.6395666003227234 Validation Loss: 0.6371526718139648  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1104 learning rate: 0.001 Training Loss: 0.6395400166511536 Validation Loss: 0.6371226906776428  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1105 learning rate: 0.001 Training Loss: 0.6395134925842285 Validation Loss: 0.6370925903320312  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1106 learning rate: 0.001 Training Loss: 0.6394868493080139 Validation Loss: 0.637062668800354  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1107 learning rate: 0.001 Training Loss: 0.6394602060317993 Validation Loss: 0.637032687664032  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1108 learning rate: 0.001 Training Loss: 0.639433741569519 Validation Loss: 0.6370026469230652  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1109 learning rate: 0.001 Training Loss: 0.6394070386886597 Validation Loss: 0.6369727253913879  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1110 learning rate: 0.001 Training Loss: 0.6393805146217346 Validation Loss: 0.6369426250457764  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1111 learning rate: 0.001 Training Loss: 0.63935387134552 Validation Loss: 0.6369125843048096  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1112 learning rate: 0.001 Training Loss: 0.6393272876739502 Validation Loss: 0.6368827223777771  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1113 learning rate: 0.001 Training Loss: 0.6393007636070251 Validation Loss: 0.6368526220321655  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1114 learning rate: 0.001 Training Loss: 0.6392741203308105 Validation Loss: 0.6368225812911987  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1115 learning rate: 0.001 Training Loss: 0.6392475366592407 Validation Loss: 0.6367927193641663  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1116 learning rate: 0.001 Training Loss: 0.6392209529876709 Validation Loss: 0.6367626786231995  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1117 learning rate: 0.001 Training Loss: 0.6391944289207458 Validation Loss: 0.6367327570915222  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1118 learning rate: 0.001 Training Loss: 0.6391677856445312 Validation Loss: 0.6367028951644897  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1119 learning rate: 0.001 Training Loss: 0.639141321182251 Validation Loss: 0.6366727948188782  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1120 learning rate: 0.001 Training Loss: 0.6391147375106812 Validation Loss: 0.6366428732872009  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1121 learning rate: 0.001 Training Loss: 0.6390882134437561 Validation Loss: 0.6366128921508789  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1122 learning rate: 0.001 Training Loss: 0.639061689376831 Validation Loss: 0.6365829706192017  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1123 learning rate: 0.001 Training Loss: 0.6390350461006165 Validation Loss: 0.6365529298782349  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1124 learning rate: 0.001 Training Loss: 0.6390084624290466 Validation Loss: 0.6365230679512024  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1125 learning rate: 0.001 Training Loss: 0.6389819383621216 Validation Loss: 0.6364929676055908  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1126 learning rate: 0.001 Training Loss: 0.6389554142951965 Validation Loss: 0.6364631056785583  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1127 learning rate: 0.001 Training Loss: 0.6389287710189819 Validation Loss: 0.6364331841468811  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1128 learning rate: 0.001 Training Loss: 0.6389023065567017 Validation Loss: 0.6364032030105591  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1129 learning rate: 0.001 Training Loss: 0.6388758420944214 Validation Loss: 0.6363733410835266  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1130 learning rate: 0.001 Training Loss: 0.6388493180274963 Validation Loss: 0.6363433599472046  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1131 learning rate: 0.001 Training Loss: 0.6388227343559265 Validation Loss: 0.6363135576248169  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1132 learning rate: 0.001 Training Loss: 0.6387962102890015 Validation Loss: 0.6362834572792053  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1133 learning rate: 0.001 Training Loss: 0.6387696266174316 Validation Loss: 0.6362537145614624  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1134 learning rate: 0.001 Training Loss: 0.6387431621551514 Validation Loss: 0.6362236142158508  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1135 learning rate: 0.001 Training Loss: 0.6387166380882263 Validation Loss: 0.6361938118934631  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1136 learning rate: 0.001 Training Loss: 0.6386900544166565 Validation Loss: 0.6361640095710754  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1137 learning rate: 0.001 Training Loss: 0.6386635899543762 Validation Loss: 0.6361340284347534  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1138 learning rate: 0.001 Training Loss: 0.6386370062828064 Validation Loss: 0.6361040472984314  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1139 learning rate: 0.001 Training Loss: 0.6386104822158813 Validation Loss: 0.6360741257667542  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1140 learning rate: 0.001 Training Loss: 0.6385841369628906 Validation Loss: 0.6360443830490112  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1141 learning rate: 0.001 Training Loss: 0.638557493686676 Validation Loss: 0.6360143423080444  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1142 learning rate: 0.001 Training Loss: 0.6385309100151062 Validation Loss: 0.635984480381012  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1143 learning rate: 0.001 Training Loss: 0.6385045051574707 Validation Loss: 0.6359544992446899  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1144 learning rate: 0.001 Training Loss: 0.6384779810905457 Validation Loss: 0.6359246969223022  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1145 learning rate: 0.001 Training Loss: 0.6384515166282654 Validation Loss: 0.6358948349952698  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1146 learning rate: 0.001 Training Loss: 0.6384250521659851 Validation Loss: 0.6358649730682373  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1147 learning rate: 0.001 Training Loss: 0.6383985877037048 Validation Loss: 0.6358351111412048  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1148 learning rate: 0.001 Training Loss: 0.6383720636367798 Validation Loss: 0.6358052492141724  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1149 learning rate: 0.001 Training Loss: 0.63834547996521 Validation Loss: 0.6357753872871399  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1150 learning rate: 0.001 Training Loss: 0.6383190751075745 Validation Loss: 0.6357454061508179  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1151 learning rate: 0.001 Training Loss: 0.6382925510406494 Validation Loss: 0.6357154846191406  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1152 learning rate: 0.001 Training Loss: 0.6382661461830139 Validation Loss: 0.6356856822967529  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1153 learning rate: 0.001 Training Loss: 0.6382395625114441 Validation Loss: 0.6356558799743652  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1154 learning rate: 0.001 Training Loss: 0.6382132172584534 Validation Loss: 0.6356260180473328  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1155 learning rate: 0.001 Training Loss: 0.6381866931915283 Validation Loss: 0.6355960965156555  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1156 learning rate: 0.001 Training Loss: 0.6381602883338928 Validation Loss: 0.6355662941932678  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1157 learning rate: 0.001 Training Loss: 0.6381337642669678 Validation Loss: 0.6355364918708801  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1158 learning rate: 0.001 Training Loss: 0.6381072402000427 Validation Loss: 0.6355066895484924  accuracy_train: 0.8141 accuracy_test: 0.8713 \n",
            "Epoch: 1159 learning rate: 0.001 Training Loss: 0.6380809545516968 Validation Loss: 0.63547682762146  accuracy_train: 0.8141 accuracy_test: 0.8772 \n",
            "Epoch: 1160 learning rate: 0.001 Training Loss: 0.638054370880127 Validation Loss: 0.6354469656944275  accuracy_train: 0.8141 accuracy_test: 0.8772 \n",
            "Epoch: 1161 learning rate: 0.001 Training Loss: 0.6380279064178467 Validation Loss: 0.6354172229766846  accuracy_train: 0.8141 accuracy_test: 0.8772 \n",
            "Epoch: 1162 learning rate: 0.001 Training Loss: 0.6380014419555664 Validation Loss: 0.6353874206542969  accuracy_train: 0.8141 accuracy_test: 0.8772 \n",
            "Epoch: 1163 learning rate: 0.001 Training Loss: 0.6379750370979309 Validation Loss: 0.6353574395179749  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1164 learning rate: 0.001 Training Loss: 0.6379486322402954 Validation Loss: 0.6353276371955872  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1165 learning rate: 0.001 Training Loss: 0.6379221677780151 Validation Loss: 0.6352978348731995  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1166 learning rate: 0.001 Training Loss: 0.6378956437110901 Validation Loss: 0.6352680325508118  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1167 learning rate: 0.001 Training Loss: 0.6378692388534546 Validation Loss: 0.6352382302284241  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1168 learning rate: 0.001 Training Loss: 0.6378427743911743 Validation Loss: 0.6352084875106812  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1169 learning rate: 0.001 Training Loss: 0.6378163695335388 Validation Loss: 0.6351786255836487  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1170 learning rate: 0.001 Training Loss: 0.6377899646759033 Validation Loss: 0.6351489424705505  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1171 learning rate: 0.001 Training Loss: 0.637763500213623 Validation Loss: 0.6351190805435181  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1172 learning rate: 0.001 Training Loss: 0.6377370357513428 Validation Loss: 0.6350892186164856  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1173 learning rate: 0.001 Training Loss: 0.6377106308937073 Validation Loss: 0.6350594758987427  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1174 learning rate: 0.001 Training Loss: 0.6376841068267822 Validation Loss: 0.635029673576355  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1175 learning rate: 0.001 Training Loss: 0.6376578211784363 Validation Loss: 0.6349999308586121  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1176 learning rate: 0.001 Training Loss: 0.6376312971115112 Validation Loss: 0.6349702477455139  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1177 learning rate: 0.001 Training Loss: 0.6376049518585205 Validation Loss: 0.6349403262138367  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1178 learning rate: 0.001 Training Loss: 0.637578547000885 Validation Loss: 0.6349105834960938  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1179 learning rate: 0.001 Training Loss: 0.6375521421432495 Validation Loss: 0.6348807215690613  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1180 learning rate: 0.001 Training Loss: 0.6375256180763245 Validation Loss: 0.6348510384559631  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1181 learning rate: 0.001 Training Loss: 0.6374993324279785 Validation Loss: 0.6348212361335754  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1182 learning rate: 0.001 Training Loss: 0.637472927570343 Validation Loss: 0.6347914338111877  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1183 learning rate: 0.001 Training Loss: 0.6374465823173523 Validation Loss: 0.6347618103027344  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1184 learning rate: 0.001 Training Loss: 0.6374200582504272 Validation Loss: 0.6347320079803467  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1185 learning rate: 0.001 Training Loss: 0.6373936533927917 Validation Loss: 0.6347022652626038  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1186 learning rate: 0.001 Training Loss: 0.637367308139801 Validation Loss: 0.6346725225448608  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1187 learning rate: 0.001 Training Loss: 0.6373409032821655 Validation Loss: 0.6346427798271179  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1188 learning rate: 0.001 Training Loss: 0.6373144388198853 Validation Loss: 0.634613037109375  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1189 learning rate: 0.001 Training Loss: 0.6372880935668945 Validation Loss: 0.6345832943916321  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1190 learning rate: 0.001 Training Loss: 0.6372618079185486 Validation Loss: 0.6345534920692444  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1191 learning rate: 0.001 Training Loss: 0.6372354030609131 Validation Loss: 0.634523868560791  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1192 learning rate: 0.001 Training Loss: 0.6372089982032776 Validation Loss: 0.6344941258430481  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1193 learning rate: 0.001 Training Loss: 0.6371827125549316 Validation Loss: 0.6344643831253052  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1194 learning rate: 0.001 Training Loss: 0.6371563076972961 Validation Loss: 0.6344346404075623  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1195 learning rate: 0.001 Training Loss: 0.6371299028396606 Validation Loss: 0.6344048380851746  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1196 learning rate: 0.001 Training Loss: 0.6371034383773804 Validation Loss: 0.6343751549720764  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1197 learning rate: 0.001 Training Loss: 0.6370771527290344 Validation Loss: 0.6343454122543335  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1198 learning rate: 0.001 Training Loss: 0.6370508670806885 Validation Loss: 0.6343157887458801  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1199 learning rate: 0.001 Training Loss: 0.6370245218276978 Validation Loss: 0.6342859864234924  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1200 learning rate: 0.001 Training Loss: 0.6369980573654175 Validation Loss: 0.6342562437057495  accuracy_train: 0.8166 accuracy_test: 0.8772 \n",
            "Epoch: 1201 learning rate: 0.001 Training Loss: 0.6369717717170715 Validation Loss: 0.6342266798019409  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1202 learning rate: 0.001 Training Loss: 0.636945366859436 Validation Loss: 0.6341969966888428  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1203 learning rate: 0.001 Training Loss: 0.6369190216064453 Validation Loss: 0.6341671943664551  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1204 learning rate: 0.001 Training Loss: 0.6368926763534546 Validation Loss: 0.6341375112533569  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1205 learning rate: 0.001 Training Loss: 0.6368663311004639 Validation Loss: 0.6341078877449036  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1206 learning rate: 0.001 Training Loss: 0.6368399858474731 Validation Loss: 0.6340781450271606  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1207 learning rate: 0.001 Training Loss: 0.6368135809898376 Validation Loss: 0.6340484619140625  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1208 learning rate: 0.001 Training Loss: 0.6367872357368469 Validation Loss: 0.6340187788009644  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1209 learning rate: 0.001 Training Loss: 0.6367610096931458 Validation Loss: 0.6339892148971558  accuracy_train: 0.8191 accuracy_test: 0.8772 \n",
            "Epoch: 1210 learning rate: 0.001 Training Loss: 0.636734664440155 Validation Loss: 0.6339594721794128  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1211 learning rate: 0.001 Training Loss: 0.6367082595825195 Validation Loss: 0.6339299082756042  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1212 learning rate: 0.001 Training Loss: 0.6366819739341736 Validation Loss: 0.6339001655578613  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1213 learning rate: 0.001 Training Loss: 0.6366556882858276 Validation Loss: 0.6338704824447632  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1214 learning rate: 0.001 Training Loss: 0.6366294026374817 Validation Loss: 0.6338408589363098  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1215 learning rate: 0.001 Training Loss: 0.636603057384491 Validation Loss: 0.6338112354278564  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1216 learning rate: 0.001 Training Loss: 0.636576771736145 Validation Loss: 0.6337815523147583  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1217 learning rate: 0.001 Training Loss: 0.6365503668785095 Validation Loss: 0.6337519884109497  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1218 learning rate: 0.001 Training Loss: 0.6365241408348083 Validation Loss: 0.6337222456932068  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1219 learning rate: 0.001 Training Loss: 0.6364977955818176 Validation Loss: 0.6336926221847534  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1220 learning rate: 0.001 Training Loss: 0.6364714503288269 Validation Loss: 0.6336629390716553  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1221 learning rate: 0.001 Training Loss: 0.6364452242851257 Validation Loss: 0.6336333155632019  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1222 learning rate: 0.001 Training Loss: 0.6364187598228455 Validation Loss: 0.6336036324501038  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1223 learning rate: 0.001 Training Loss: 0.6363925337791443 Validation Loss: 0.6335740685462952  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1224 learning rate: 0.001 Training Loss: 0.6363662481307983 Validation Loss: 0.6335445046424866  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1225 learning rate: 0.001 Training Loss: 0.6363400220870972 Validation Loss: 0.6335148811340332  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1226 learning rate: 0.001 Training Loss: 0.6363136768341064 Validation Loss: 0.6334851980209351  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1227 learning rate: 0.001 Training Loss: 0.6362873315811157 Validation Loss: 0.6334556341171265  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1228 learning rate: 0.001 Training Loss: 0.6362610459327698 Validation Loss: 0.6334259510040283  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1229 learning rate: 0.001 Training Loss: 0.6362348794937134 Validation Loss: 0.633396327495575  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1230 learning rate: 0.001 Training Loss: 0.6362084746360779 Validation Loss: 0.6333668231964111  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1231 learning rate: 0.001 Training Loss: 0.6361822485923767 Validation Loss: 0.633337140083313  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1232 learning rate: 0.001 Training Loss: 0.6361559629440308 Validation Loss: 0.6333075165748596  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1233 learning rate: 0.001 Training Loss: 0.6361297369003296 Validation Loss: 0.633277952671051  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1234 learning rate: 0.001 Training Loss: 0.6361033916473389 Validation Loss: 0.6332483887672424  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1235 learning rate: 0.001 Training Loss: 0.6360771656036377 Validation Loss: 0.6332187652587891  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1236 learning rate: 0.001 Training Loss: 0.6360508799552917 Validation Loss: 0.6331892013549805  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1237 learning rate: 0.001 Training Loss: 0.636024534702301 Validation Loss: 0.6331595778465271  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1238 learning rate: 0.001 Training Loss: 0.6359983086585999 Validation Loss: 0.6331300735473633  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1239 learning rate: 0.001 Training Loss: 0.6359720230102539 Validation Loss: 0.6331004500389099  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1240 learning rate: 0.001 Training Loss: 0.6359457969665527 Validation Loss: 0.6330708861351013  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1241 learning rate: 0.001 Training Loss: 0.6359195113182068 Validation Loss: 0.6330413222312927  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1242 learning rate: 0.001 Training Loss: 0.6358933448791504 Validation Loss: 0.6330118179321289  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1243 learning rate: 0.001 Training Loss: 0.6358669996261597 Validation Loss: 0.6329821944236755  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1244 learning rate: 0.001 Training Loss: 0.6358408331871033 Validation Loss: 0.6329525709152222  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1245 learning rate: 0.001 Training Loss: 0.6358146071434021 Validation Loss: 0.6329230070114136  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1246 learning rate: 0.001 Training Loss: 0.6357884407043457 Validation Loss: 0.6328935027122498  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1247 learning rate: 0.001 Training Loss: 0.635762095451355 Validation Loss: 0.6328639984130859  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1248 learning rate: 0.001 Training Loss: 0.6357359290122986 Validation Loss: 0.6328343749046326  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1249 learning rate: 0.001 Training Loss: 0.6357095837593079 Validation Loss: 0.632804811000824  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1250 learning rate: 0.001 Training Loss: 0.6356834173202515 Validation Loss: 0.6327753067016602  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1251 learning rate: 0.001 Training Loss: 0.6356571316719055 Validation Loss: 0.6327456831932068  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1252 learning rate: 0.001 Training Loss: 0.6356310248374939 Validation Loss: 0.6327162384986877  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1253 learning rate: 0.001 Training Loss: 0.6356046795845032 Validation Loss: 0.6326866149902344  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1254 learning rate: 0.001 Training Loss: 0.635578453540802 Validation Loss: 0.6326571702957153  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1255 learning rate: 0.001 Training Loss: 0.6355522871017456 Validation Loss: 0.6326277256011963  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1256 learning rate: 0.001 Training Loss: 0.6355261206626892 Validation Loss: 0.6325982213020325  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1257 learning rate: 0.001 Training Loss: 0.6354999542236328 Validation Loss: 0.6325685977935791  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1258 learning rate: 0.001 Training Loss: 0.6354736685752869 Validation Loss: 0.6325390934944153  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1259 learning rate: 0.001 Training Loss: 0.6354475021362305 Validation Loss: 0.6325095295906067  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1260 learning rate: 0.001 Training Loss: 0.6354212164878845 Validation Loss: 0.6324800848960876  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1261 learning rate: 0.001 Training Loss: 0.6353951096534729 Validation Loss: 0.6324506998062134  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1262 learning rate: 0.001 Training Loss: 0.6353689432144165 Validation Loss: 0.6324211955070496  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1263 learning rate: 0.001 Training Loss: 0.6353425979614258 Validation Loss: 0.6323915719985962  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1264 learning rate: 0.001 Training Loss: 0.6353163719177246 Validation Loss: 0.6323620676994324  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1265 learning rate: 0.001 Training Loss: 0.635290265083313 Validation Loss: 0.6323326230049133  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1266 learning rate: 0.001 Training Loss: 0.6352640390396118 Validation Loss: 0.6323031187057495  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1267 learning rate: 0.001 Training Loss: 0.6352378129959106 Validation Loss: 0.6322736144065857  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1268 learning rate: 0.001 Training Loss: 0.6352116465568542 Validation Loss: 0.6322441697120667  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1269 learning rate: 0.001 Training Loss: 0.6351855397224426 Validation Loss: 0.6322146654129028  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1270 learning rate: 0.001 Training Loss: 0.6351593732833862 Validation Loss: 0.6321852207183838  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1271 learning rate: 0.001 Training Loss: 0.6351331472396851 Validation Loss: 0.6321557760238647  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1272 learning rate: 0.001 Training Loss: 0.6351069211959839 Validation Loss: 0.6321262717247009  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1273 learning rate: 0.001 Training Loss: 0.635080873966217 Validation Loss: 0.6320967078208923  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1274 learning rate: 0.001 Training Loss: 0.6350545287132263 Validation Loss: 0.6320673823356628  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1275 learning rate: 0.001 Training Loss: 0.6350284218788147 Validation Loss: 0.6320378184318542  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1276 learning rate: 0.001 Training Loss: 0.6350023150444031 Validation Loss: 0.6320083737373352  accuracy_train: 0.8191 accuracy_test: 0.8830 \n",
            "Epoch: 1277 learning rate: 0.001 Training Loss: 0.6349760890007019 Validation Loss: 0.6319790482521057  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1278 learning rate: 0.001 Training Loss: 0.6349499821662903 Validation Loss: 0.6319495439529419  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1279 learning rate: 0.001 Training Loss: 0.6349238753318787 Validation Loss: 0.6319199800491333  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1280 learning rate: 0.001 Training Loss: 0.6348976492881775 Validation Loss: 0.6318906545639038  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1281 learning rate: 0.001 Training Loss: 0.6348715424537659 Validation Loss: 0.6318610906600952  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1282 learning rate: 0.001 Training Loss: 0.6348454356193542 Validation Loss: 0.6318318247795105  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1283 learning rate: 0.001 Training Loss: 0.6348192691802979 Validation Loss: 0.6318023204803467  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1284 learning rate: 0.001 Training Loss: 0.6347930431365967 Validation Loss: 0.6317728161811829  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1285 learning rate: 0.001 Training Loss: 0.6347668766975403 Validation Loss: 0.6317433714866638  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1286 learning rate: 0.001 Training Loss: 0.6347407698631287 Validation Loss: 0.6317139267921448  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1287 learning rate: 0.001 Training Loss: 0.6347146034240723 Validation Loss: 0.6316844820976257  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1288 learning rate: 0.001 Training Loss: 0.6346884965896606 Validation Loss: 0.631655216217041  accuracy_train: 0.8216 accuracy_test: 0.8830 \n",
            "Epoch: 1289 learning rate: 0.001 Training Loss: 0.634662389755249 Validation Loss: 0.6316257119178772  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1290 learning rate: 0.001 Training Loss: 0.6346362233161926 Validation Loss: 0.6315963268280029  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1291 learning rate: 0.001 Training Loss: 0.634610116481781 Validation Loss: 0.6315668821334839  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1292 learning rate: 0.001 Training Loss: 0.6345840096473694 Validation Loss: 0.6315375566482544  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1293 learning rate: 0.001 Training Loss: 0.6345579624176025 Validation Loss: 0.6315081715583801  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1294 learning rate: 0.001 Training Loss: 0.6345317363739014 Validation Loss: 0.6314786672592163  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1295 learning rate: 0.001 Training Loss: 0.6345056295394897 Validation Loss: 0.631449282169342  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1296 learning rate: 0.001 Training Loss: 0.6344794631004333 Validation Loss: 0.6314199566841125  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1297 learning rate: 0.001 Training Loss: 0.6344534158706665 Validation Loss: 0.6313904523849487  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1298 learning rate: 0.001 Training Loss: 0.6344273090362549 Validation Loss: 0.631361186504364  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1299 learning rate: 0.001 Training Loss: 0.6344010829925537 Validation Loss: 0.631331741809845  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1300 learning rate: 0.001 Training Loss: 0.6343750953674316 Validation Loss: 0.6313024163246155  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1301 learning rate: 0.001 Training Loss: 0.6343489289283752 Validation Loss: 0.6312730312347412  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1302 learning rate: 0.001 Training Loss: 0.6343229413032532 Validation Loss: 0.6312436461448669  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1303 learning rate: 0.001 Training Loss: 0.6342967748641968 Validation Loss: 0.6312142610549927  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1304 learning rate: 0.001 Training Loss: 0.6342706084251404 Validation Loss: 0.6311848759651184  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1305 learning rate: 0.001 Training Loss: 0.6342445611953735 Validation Loss: 0.6311554908752441  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1306 learning rate: 0.001 Training Loss: 0.6342184543609619 Validation Loss: 0.6311261653900146  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1307 learning rate: 0.001 Training Loss: 0.6341922879219055 Validation Loss: 0.6310967206954956  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1308 learning rate: 0.001 Training Loss: 0.6341663002967834 Validation Loss: 0.6310673952102661  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1309 learning rate: 0.001 Training Loss: 0.6341401934623718 Validation Loss: 0.6310381293296814  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1310 learning rate: 0.001 Training Loss: 0.634114146232605 Validation Loss: 0.6310087442398071  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1311 learning rate: 0.001 Training Loss: 0.6340879797935486 Validation Loss: 0.6309794187545776  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1312 learning rate: 0.001 Training Loss: 0.6340620517730713 Validation Loss: 0.6309500336647034  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1313 learning rate: 0.001 Training Loss: 0.6340358257293701 Validation Loss: 0.6309206485748291  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1314 learning rate: 0.001 Training Loss: 0.634009838104248 Validation Loss: 0.6308913230895996  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1315 learning rate: 0.001 Training Loss: 0.633983850479126 Validation Loss: 0.6308621168136597  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1316 learning rate: 0.001 Training Loss: 0.6339577436447144 Validation Loss: 0.630832850933075  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1317 learning rate: 0.001 Training Loss: 0.6339316964149475 Validation Loss: 0.6308034062385559  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1318 learning rate: 0.001 Training Loss: 0.6339057087898254 Validation Loss: 0.6307739615440369  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1319 learning rate: 0.001 Training Loss: 0.633879542350769 Validation Loss: 0.6307446956634521  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1320 learning rate: 0.001 Training Loss: 0.6338534951210022 Validation Loss: 0.6307153701782227  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1321 learning rate: 0.001 Training Loss: 0.6338274478912354 Validation Loss: 0.6306860446929932  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1322 learning rate: 0.001 Training Loss: 0.6338014006614685 Validation Loss: 0.6306568384170532  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1323 learning rate: 0.001 Training Loss: 0.6337753534317017 Validation Loss: 0.6306275129318237  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1324 learning rate: 0.001 Training Loss: 0.63374924659729 Validation Loss: 0.6305981278419495  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1325 learning rate: 0.001 Training Loss: 0.6337231993675232 Validation Loss: 0.6305688619613647  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1326 learning rate: 0.001 Training Loss: 0.6336973309516907 Validation Loss: 0.6305395364761353  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1327 learning rate: 0.001 Training Loss: 0.633671224117279 Validation Loss: 0.6305102109909058  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1328 learning rate: 0.001 Training Loss: 0.6336451768875122 Validation Loss: 0.6304810643196106  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1329 learning rate: 0.001 Training Loss: 0.6336190104484558 Validation Loss: 0.6304517388343811  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1330 learning rate: 0.001 Training Loss: 0.633592963218689 Validation Loss: 0.6304223537445068  accuracy_train: 0.8216 accuracy_test: 0.8889 \n",
            "Epoch: 1331 learning rate: 0.001 Training Loss: 0.6335669755935669 Validation Loss: 0.6303931474685669  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1332 learning rate: 0.001 Training Loss: 0.6335409283638 Validation Loss: 0.6303638815879822  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1333 learning rate: 0.001 Training Loss: 0.633514940738678 Validation Loss: 0.630334734916687  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1334 learning rate: 0.001 Training Loss: 0.6334888935089111 Validation Loss: 0.6303053498268127  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1335 learning rate: 0.001 Training Loss: 0.6334629654884338 Validation Loss: 0.630276083946228  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1336 learning rate: 0.001 Training Loss: 0.6334369778633118 Validation Loss: 0.6302467584609985  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1337 learning rate: 0.001 Training Loss: 0.6334109306335449 Validation Loss: 0.6302174925804138  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1338 learning rate: 0.001 Training Loss: 0.6333848834037781 Validation Loss: 0.6301883459091187  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1339 learning rate: 0.001 Training Loss: 0.6333589553833008 Validation Loss: 0.6301590204238892  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1340 learning rate: 0.001 Training Loss: 0.6333329677581787 Validation Loss: 0.6301297545433044  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1341 learning rate: 0.001 Training Loss: 0.6333069205284119 Validation Loss: 0.630100429058075  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1342 learning rate: 0.001 Training Loss: 0.633280873298645 Validation Loss: 0.6300713419914246  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1343 learning rate: 0.001 Training Loss: 0.6332549452781677 Validation Loss: 0.6300419569015503  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1344 learning rate: 0.001 Training Loss: 0.6332288384437561 Validation Loss: 0.6300127506256104  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1345 learning rate: 0.001 Training Loss: 0.6332029700279236 Validation Loss: 0.6299834847450256  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1346 learning rate: 0.001 Training Loss: 0.6331769227981567 Validation Loss: 0.6299543380737305  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1347 learning rate: 0.001 Training Loss: 0.6331509351730347 Validation Loss: 0.6299251317977905  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1348 learning rate: 0.001 Training Loss: 0.6331249475479126 Validation Loss: 0.6298959851264954  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1349 learning rate: 0.001 Training Loss: 0.6330990195274353 Validation Loss: 0.6298665404319763  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1350 learning rate: 0.001 Training Loss: 0.6330729722976685 Validation Loss: 0.6298373937606812  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1351 learning rate: 0.001 Training Loss: 0.6330470442771912 Validation Loss: 0.629808247089386  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1352 learning rate: 0.001 Training Loss: 0.6330211162567139 Validation Loss: 0.6297789216041565  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1353 learning rate: 0.001 Training Loss: 0.6329951286315918 Validation Loss: 0.6297498345375061  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1354 learning rate: 0.001 Training Loss: 0.6329691410064697 Validation Loss: 0.6297205686569214  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1355 learning rate: 0.001 Training Loss: 0.6329432129859924 Validation Loss: 0.6296913027763367  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1356 learning rate: 0.001 Training Loss: 0.6329172253608704 Validation Loss: 0.6296620965003967  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1357 learning rate: 0.001 Training Loss: 0.6328912377357483 Validation Loss: 0.6296328902244568  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1358 learning rate: 0.001 Training Loss: 0.632865309715271 Validation Loss: 0.6296037435531616  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1359 learning rate: 0.001 Training Loss: 0.6328392624855042 Validation Loss: 0.6295745372772217  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1360 learning rate: 0.001 Training Loss: 0.6328133344650269 Validation Loss: 0.6295453906059265  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1361 learning rate: 0.001 Training Loss: 0.6327874064445496 Validation Loss: 0.6295161843299866  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1362 learning rate: 0.001 Training Loss: 0.6327614188194275 Validation Loss: 0.6294869780540466  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1363 learning rate: 0.001 Training Loss: 0.6327354311943054 Validation Loss: 0.6294577717781067  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1364 learning rate: 0.001 Training Loss: 0.6327095031738281 Validation Loss: 0.6294285655021667  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1365 learning rate: 0.001 Training Loss: 0.632683515548706 Validation Loss: 0.6293994188308716  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1366 learning rate: 0.001 Training Loss: 0.6326576471328735 Validation Loss: 0.6293702721595764  accuracy_train: 0.8241 accuracy_test: 0.8889 \n",
            "Epoch: 1367 learning rate: 0.001 Training Loss: 0.6326317191123962 Validation Loss: 0.629341185092926  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1368 learning rate: 0.001 Training Loss: 0.6326057314872742 Validation Loss: 0.6293119192123413  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1369 learning rate: 0.001 Training Loss: 0.6325798034667969 Validation Loss: 0.6292827725410461  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1370 learning rate: 0.001 Training Loss: 0.6325539946556091 Validation Loss: 0.629253625869751  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1371 learning rate: 0.001 Training Loss: 0.6325280070304871 Validation Loss: 0.6292244791984558  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1372 learning rate: 0.001 Training Loss: 0.632502019405365 Validation Loss: 0.6291953921318054  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1373 learning rate: 0.001 Training Loss: 0.6324760913848877 Validation Loss: 0.6291661858558655  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1374 learning rate: 0.001 Training Loss: 0.6324502229690552 Validation Loss: 0.6291370987892151  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1375 learning rate: 0.001 Training Loss: 0.6324242949485779 Validation Loss: 0.6291078925132751  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1376 learning rate: 0.001 Training Loss: 0.6323984265327454 Validation Loss: 0.6290786862373352  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1377 learning rate: 0.001 Training Loss: 0.6323724389076233 Validation Loss: 0.6290497183799744  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1378 learning rate: 0.001 Training Loss: 0.6323465704917908 Validation Loss: 0.6290204524993896  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1379 learning rate: 0.001 Training Loss: 0.6323207020759583 Validation Loss: 0.628991425037384  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1380 learning rate: 0.001 Training Loss: 0.6322947144508362 Validation Loss: 0.6289622187614441  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1381 learning rate: 0.001 Training Loss: 0.6322687864303589 Validation Loss: 0.6289331316947937  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1382 learning rate: 0.001 Training Loss: 0.6322429776191711 Validation Loss: 0.628903865814209  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1383 learning rate: 0.001 Training Loss: 0.6322170495986938 Validation Loss: 0.6288748979568481  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1384 learning rate: 0.001 Training Loss: 0.6321911215782166 Validation Loss: 0.628845751285553  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1385 learning rate: 0.001 Training Loss: 0.6321651935577393 Validation Loss: 0.6288167238235474  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1386 learning rate: 0.001 Training Loss: 0.6321393251419067 Validation Loss: 0.6287875771522522  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1387 learning rate: 0.001 Training Loss: 0.6321134567260742 Validation Loss: 0.628758430480957  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1388 learning rate: 0.001 Training Loss: 0.6320875883102417 Validation Loss: 0.6287292838096619  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1389 learning rate: 0.001 Training Loss: 0.632061779499054 Validation Loss: 0.6287001967430115  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1390 learning rate: 0.001 Training Loss: 0.6320357918739319 Validation Loss: 0.6286710500717163  accuracy_train: 0.8266 accuracy_test: 0.8889 \n",
            "Epoch: 1391 learning rate: 0.001 Training Loss: 0.6320099234580994 Validation Loss: 0.6286420822143555  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1392 learning rate: 0.001 Training Loss: 0.6319840550422668 Validation Loss: 0.6286128759384155  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1393 learning rate: 0.001 Training Loss: 0.6319582462310791 Validation Loss: 0.6285837888717651  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1394 learning rate: 0.001 Training Loss: 0.631932258605957 Validation Loss: 0.6285548806190491  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1395 learning rate: 0.001 Training Loss: 0.6319064497947693 Validation Loss: 0.6285257339477539  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1396 learning rate: 0.001 Training Loss: 0.6318805813789368 Validation Loss: 0.6284966468811035  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1397 learning rate: 0.001 Training Loss: 0.6318547129631042 Validation Loss: 0.6284675002098083  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1398 learning rate: 0.001 Training Loss: 0.6318289041519165 Validation Loss: 0.6284384727478027  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1399 learning rate: 0.001 Training Loss: 0.6318029761314392 Validation Loss: 0.6284094452857971  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1400 learning rate: 0.001 Training Loss: 0.6317771673202515 Validation Loss: 0.6283803582191467  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1401 learning rate: 0.001 Training Loss: 0.6317511796951294 Validation Loss: 0.6283512711524963  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1402 learning rate: 0.001 Training Loss: 0.631725549697876 Validation Loss: 0.6283222436904907  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1403 learning rate: 0.001 Training Loss: 0.6316996216773987 Validation Loss: 0.6282930970191956  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1404 learning rate: 0.001 Training Loss: 0.6316738128662109 Validation Loss: 0.6282640695571899  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1405 learning rate: 0.001 Training Loss: 0.6316478848457336 Validation Loss: 0.6282351016998291  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1406 learning rate: 0.001 Training Loss: 0.6316221356391907 Validation Loss: 0.6282060146331787  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1407 learning rate: 0.001 Training Loss: 0.6315962672233582 Validation Loss: 0.6281769275665283  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1408 learning rate: 0.001 Training Loss: 0.6315704584121704 Validation Loss: 0.6281478404998779  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1409 learning rate: 0.001 Training Loss: 0.6315445303916931 Validation Loss: 0.6281189322471619  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1410 learning rate: 0.001 Training Loss: 0.6315187215805054 Validation Loss: 0.6280897855758667  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1411 learning rate: 0.001 Training Loss: 0.6314929723739624 Validation Loss: 0.6280606985092163  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1412 learning rate: 0.001 Training Loss: 0.6314670443534851 Validation Loss: 0.6280317902565002  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1413 learning rate: 0.001 Training Loss: 0.6314412355422974 Validation Loss: 0.6280028223991394  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1414 learning rate: 0.001 Training Loss: 0.6314154267311096 Validation Loss: 0.627973735332489  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1415 learning rate: 0.001 Training Loss: 0.6313897371292114 Validation Loss: 0.6279448866844177  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1416 learning rate: 0.001 Training Loss: 0.6313638091087341 Validation Loss: 0.6279157400131226  accuracy_train: 0.8266 accuracy_test: 0.8947 \n",
            "Epoch: 1417 learning rate: 0.001 Training Loss: 0.6313379406929016 Validation Loss: 0.6278868317604065  accuracy_train: 0.8291 accuracy_test: 0.8947 \n",
            "Epoch: 1418 learning rate: 0.001 Training Loss: 0.6313121914863586 Validation Loss: 0.6278576850891113  accuracy_train: 0.8291 accuracy_test: 0.8947 \n",
            "Epoch: 1419 learning rate: 0.001 Training Loss: 0.6312863826751709 Validation Loss: 0.6278286576271057  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1420 learning rate: 0.001 Training Loss: 0.6312605142593384 Validation Loss: 0.6277997493743896  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1421 learning rate: 0.001 Training Loss: 0.6312347650527954 Validation Loss: 0.6277706027030945  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1422 learning rate: 0.001 Training Loss: 0.6312089562416077 Validation Loss: 0.627741813659668  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1423 learning rate: 0.001 Training Loss: 0.6311830878257751 Validation Loss: 0.6277127861976624  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1424 learning rate: 0.001 Training Loss: 0.6311572790145874 Validation Loss: 0.6276837587356567  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1425 learning rate: 0.001 Training Loss: 0.6311315298080444 Validation Loss: 0.6276547908782959  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1426 learning rate: 0.001 Training Loss: 0.6311057209968567 Validation Loss: 0.6276257634162903  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1427 learning rate: 0.001 Training Loss: 0.6310800313949585 Validation Loss: 0.6275967359542847  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1428 learning rate: 0.001 Training Loss: 0.6310542225837708 Validation Loss: 0.6275678277015686  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1429 learning rate: 0.001 Training Loss: 0.631028413772583 Validation Loss: 0.627538800239563  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1430 learning rate: 0.001 Training Loss: 0.63100266456604 Validation Loss: 0.6275098323822021  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1431 learning rate: 0.001 Training Loss: 0.6309768557548523 Validation Loss: 0.6274809837341309  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1432 learning rate: 0.001 Training Loss: 0.6309511065483093 Validation Loss: 0.6274519562721252  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1433 learning rate: 0.001 Training Loss: 0.630925178527832 Validation Loss: 0.6274229884147644  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1434 learning rate: 0.001 Training Loss: 0.6308996081352234 Validation Loss: 0.6273940801620483  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1435 learning rate: 0.001 Training Loss: 0.6308736801147461 Validation Loss: 0.6273651719093323  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1436 learning rate: 0.001 Training Loss: 0.6308479309082031 Validation Loss: 0.6273361444473267  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1437 learning rate: 0.001 Training Loss: 0.6308221817016602 Validation Loss: 0.627307116985321  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1438 learning rate: 0.001 Training Loss: 0.630796492099762 Validation Loss: 0.6272782683372498  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1439 learning rate: 0.001 Training Loss: 0.6307706832885742 Validation Loss: 0.6272493600845337  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1440 learning rate: 0.001 Training Loss: 0.6307450532913208 Validation Loss: 0.6272203922271729  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1441 learning rate: 0.001 Training Loss: 0.6307191848754883 Validation Loss: 0.627191424369812  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1442 learning rate: 0.001 Training Loss: 0.6306934952735901 Validation Loss: 0.6271625757217407  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1443 learning rate: 0.001 Training Loss: 0.6306677460670471 Validation Loss: 0.6271334886550903  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1444 learning rate: 0.001 Training Loss: 0.6306419372558594 Validation Loss: 0.6271046996116638  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1445 learning rate: 0.001 Training Loss: 0.6306161284446716 Validation Loss: 0.627075731754303  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1446 learning rate: 0.001 Training Loss: 0.6305903792381287 Validation Loss: 0.6270468235015869  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1447 learning rate: 0.001 Training Loss: 0.6305647492408752 Validation Loss: 0.6270179748535156  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1448 learning rate: 0.001 Training Loss: 0.6305388808250427 Validation Loss: 0.62698894739151  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1449 learning rate: 0.001 Training Loss: 0.6305132508277893 Validation Loss: 0.626960039138794  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1450 learning rate: 0.001 Training Loss: 0.6304875612258911 Validation Loss: 0.6269311904907227  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1451 learning rate: 0.001 Training Loss: 0.6304617524147034 Validation Loss: 0.6269022822380066  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1452 learning rate: 0.001 Training Loss: 0.6304360628128052 Validation Loss: 0.6268733739852905  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1453 learning rate: 0.001 Training Loss: 0.630410373210907 Validation Loss: 0.6268444657325745  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1454 learning rate: 0.001 Training Loss: 0.6303847432136536 Validation Loss: 0.6268155574798584  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1455 learning rate: 0.001 Training Loss: 0.630358874797821 Validation Loss: 0.6267866492271423  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1456 learning rate: 0.001 Training Loss: 0.6303331255912781 Validation Loss: 0.6267578601837158  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1457 learning rate: 0.001 Training Loss: 0.6303074359893799 Validation Loss: 0.626728892326355  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1458 learning rate: 0.001 Training Loss: 0.6302816867828369 Validation Loss: 0.6266998648643494  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1459 learning rate: 0.001 Training Loss: 0.6302560567855835 Validation Loss: 0.6266711354255676  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1460 learning rate: 0.001 Training Loss: 0.6302303671836853 Validation Loss: 0.6266422867774963  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1461 learning rate: 0.001 Training Loss: 0.6302046179771423 Validation Loss: 0.6266133189201355  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1462 learning rate: 0.001 Training Loss: 0.6301789283752441 Validation Loss: 0.6265844702720642  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1463 learning rate: 0.001 Training Loss: 0.630153238773346 Validation Loss: 0.6265556216239929  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1464 learning rate: 0.001 Training Loss: 0.6301276087760925 Validation Loss: 0.6265267729759216  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1465 learning rate: 0.001 Training Loss: 0.6301018595695496 Validation Loss: 0.6264979243278503  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1466 learning rate: 0.001 Training Loss: 0.6300760507583618 Validation Loss: 0.6264690160751343  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1467 learning rate: 0.001 Training Loss: 0.6300504207611084 Validation Loss: 0.6264402270317078  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1468 learning rate: 0.001 Training Loss: 0.6300247311592102 Validation Loss: 0.6264113187789917  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1469 learning rate: 0.001 Training Loss: 0.629999041557312 Validation Loss: 0.6263825297355652  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1470 learning rate: 0.001 Training Loss: 0.6299733519554138 Validation Loss: 0.6263536810874939  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1471 learning rate: 0.001 Training Loss: 0.6299476027488708 Validation Loss: 0.6263248324394226  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1472 learning rate: 0.001 Training Loss: 0.6299220323562622 Validation Loss: 0.6262959837913513  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1473 learning rate: 0.001 Training Loss: 0.629896342754364 Validation Loss: 0.6262671947479248  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1474 learning rate: 0.001 Training Loss: 0.629870593547821 Validation Loss: 0.6262382864952087  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1475 learning rate: 0.001 Training Loss: 0.6298450231552124 Validation Loss: 0.6262094974517822  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1476 learning rate: 0.001 Training Loss: 0.629819393157959 Validation Loss: 0.6261807084083557  accuracy_train: 0.8317 accuracy_test: 0.8947 \n",
            "Epoch: 1477 learning rate: 0.001 Training Loss: 0.629793643951416 Validation Loss: 0.6261518001556396  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1478 learning rate: 0.001 Training Loss: 0.6297679543495178 Validation Loss: 0.6261230111122131  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1479 learning rate: 0.001 Training Loss: 0.6297422647476196 Validation Loss: 0.6260941624641418  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1480 learning rate: 0.001 Training Loss: 0.629716694355011 Validation Loss: 0.6260653138160706  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1481 learning rate: 0.001 Training Loss: 0.6296910643577576 Validation Loss: 0.626036524772644  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1482 learning rate: 0.001 Training Loss: 0.6296653747558594 Validation Loss: 0.6260077953338623  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1483 learning rate: 0.001 Training Loss: 0.629639744758606 Validation Loss: 0.625978946685791  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1484 learning rate: 0.001 Training Loss: 0.6296141147613525 Validation Loss: 0.6259501576423645  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1485 learning rate: 0.001 Training Loss: 0.6295884251594543 Validation Loss: 0.6259213089942932  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1486 learning rate: 0.001 Training Loss: 0.6295627355575562 Validation Loss: 0.6258925795555115  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1487 learning rate: 0.001 Training Loss: 0.6295371055603027 Validation Loss: 0.6258637309074402  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1488 learning rate: 0.001 Training Loss: 0.6295114755630493 Validation Loss: 0.6258350610733032  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1489 learning rate: 0.001 Training Loss: 0.6294858455657959 Validation Loss: 0.6258062124252319  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1490 learning rate: 0.001 Training Loss: 0.6294602155685425 Validation Loss: 0.6257774829864502  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1491 learning rate: 0.001 Training Loss: 0.6294347047805786 Validation Loss: 0.6257486343383789  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1492 learning rate: 0.001 Training Loss: 0.6294088959693909 Validation Loss: 0.6257198452949524  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1493 learning rate: 0.001 Training Loss: 0.6293833255767822 Validation Loss: 0.6256910562515259  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1494 learning rate: 0.001 Training Loss: 0.6293577551841736 Validation Loss: 0.6256622672080994  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1495 learning rate: 0.001 Training Loss: 0.6293320655822754 Validation Loss: 0.6256335377693176  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1496 learning rate: 0.001 Training Loss: 0.6293063759803772 Validation Loss: 0.6256049275398254  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1497 learning rate: 0.001 Training Loss: 0.6292808651924133 Validation Loss: 0.6255759596824646  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1498 learning rate: 0.001 Training Loss: 0.6292552351951599 Validation Loss: 0.6255471706390381  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1499 learning rate: 0.001 Training Loss: 0.6292295455932617 Validation Loss: 0.6255185008049011  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1500 learning rate: 0.001 Training Loss: 0.6292040348052979 Validation Loss: 0.6254897117614746  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1501 learning rate: 0.001 Training Loss: 0.6291784048080444 Validation Loss: 0.6254609823226929  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1502 learning rate: 0.001 Training Loss: 0.629152774810791 Validation Loss: 0.6254323124885559  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1503 learning rate: 0.001 Training Loss: 0.6291272640228271 Validation Loss: 0.6254035830497742  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1504 learning rate: 0.001 Training Loss: 0.6291016340255737 Validation Loss: 0.6253747940063477  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1505 learning rate: 0.001 Training Loss: 0.6290760040283203 Validation Loss: 0.6253460645675659  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1506 learning rate: 0.001 Training Loss: 0.6290503144264221 Validation Loss: 0.6253173351287842  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1507 learning rate: 0.001 Training Loss: 0.629024863243103 Validation Loss: 0.6252886056900024  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1508 learning rate: 0.001 Training Loss: 0.6289992332458496 Validation Loss: 0.6252598762512207  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1509 learning rate: 0.001 Training Loss: 0.628973662853241 Validation Loss: 0.6252312064170837  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1510 learning rate: 0.001 Training Loss: 0.6289480328559875 Validation Loss: 0.6252023577690125  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1511 learning rate: 0.001 Training Loss: 0.6289224624633789 Validation Loss: 0.6251736283302307  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1512 learning rate: 0.001 Training Loss: 0.6288968324661255 Validation Loss: 0.6251450181007385  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1513 learning rate: 0.001 Training Loss: 0.6288713812828064 Validation Loss: 0.6251162886619568  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1514 learning rate: 0.001 Training Loss: 0.6288458108901978 Validation Loss: 0.6250874996185303  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1515 learning rate: 0.001 Training Loss: 0.6288201212882996 Validation Loss: 0.6250588893890381  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1516 learning rate: 0.001 Training Loss: 0.6287946105003357 Validation Loss: 0.6250301599502563  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1517 learning rate: 0.001 Training Loss: 0.628769040107727 Validation Loss: 0.6250014901161194  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1518 learning rate: 0.001 Training Loss: 0.6287435293197632 Validation Loss: 0.6249727606773376  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1519 learning rate: 0.001 Training Loss: 0.6287178993225098 Validation Loss: 0.6249440908432007  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1520 learning rate: 0.001 Training Loss: 0.6286922693252563 Validation Loss: 0.6249154210090637  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1521 learning rate: 0.001 Training Loss: 0.628666877746582 Validation Loss: 0.624886691570282  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1522 learning rate: 0.001 Training Loss: 0.6286413073539734 Validation Loss: 0.6248580813407898  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1523 learning rate: 0.001 Training Loss: 0.6286156177520752 Validation Loss: 0.6248292326927185  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1524 learning rate: 0.001 Training Loss: 0.6285900473594666 Validation Loss: 0.6248006820678711  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1525 learning rate: 0.001 Training Loss: 0.6285645961761475 Validation Loss: 0.6247718930244446  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1526 learning rate: 0.001 Training Loss: 0.6285390257835388 Validation Loss: 0.6247433423995972  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1527 learning rate: 0.001 Training Loss: 0.628513514995575 Validation Loss: 0.6247146725654602  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1528 learning rate: 0.001 Training Loss: 0.6284880042076111 Validation Loss: 0.6246860027313232  accuracy_train: 0.8342 accuracy_test: 0.8947 \n",
            "Epoch: 1529 learning rate: 0.001 Training Loss: 0.6284623146057129 Validation Loss: 0.6246573328971863  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1530 learning rate: 0.001 Training Loss: 0.6284368634223938 Validation Loss: 0.6246287226676941  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1531 learning rate: 0.001 Training Loss: 0.6284113526344299 Validation Loss: 0.6245999932289124  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1532 learning rate: 0.001 Training Loss: 0.6283858418464661 Validation Loss: 0.6245712637901306  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1533 learning rate: 0.001 Training Loss: 0.6283603310585022 Validation Loss: 0.6245426535606384  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1534 learning rate: 0.001 Training Loss: 0.6283347606658936 Validation Loss: 0.6245139837265015  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1535 learning rate: 0.001 Training Loss: 0.6283091902732849 Validation Loss: 0.624485433101654  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1536 learning rate: 0.001 Training Loss: 0.628283679485321 Validation Loss: 0.6244567632675171  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1537 learning rate: 0.001 Training Loss: 0.628258228302002 Validation Loss: 0.6244281530380249  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1538 learning rate: 0.001 Training Loss: 0.6282327175140381 Validation Loss: 0.6243995428085327  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1539 learning rate: 0.001 Training Loss: 0.6282070875167847 Validation Loss: 0.6243709325790405  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1540 learning rate: 0.001 Training Loss: 0.6281816363334656 Validation Loss: 0.6243422031402588  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1541 learning rate: 0.001 Training Loss: 0.6281561255455017 Validation Loss: 0.6243135929107666  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1542 learning rate: 0.001 Training Loss: 0.6281306743621826 Validation Loss: 0.6242850422859192  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1543 learning rate: 0.001 Training Loss: 0.628105103969574 Validation Loss: 0.6242563128471375  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1544 learning rate: 0.001 Training Loss: 0.6280795335769653 Validation Loss: 0.62422776222229  accuracy_train: 0.8367 accuracy_test: 0.8947 \n",
            "Epoch: 1545 learning rate: 0.001 Training Loss: 0.628054141998291 Validation Loss: 0.6241991519927979  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1546 learning rate: 0.001 Training Loss: 0.6280285716056824 Validation Loss: 0.6241705417633057  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1547 learning rate: 0.001 Training Loss: 0.6280031204223633 Validation Loss: 0.6241418719291687  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1548 learning rate: 0.001 Training Loss: 0.6279776692390442 Validation Loss: 0.6241133809089661  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1549 learning rate: 0.001 Training Loss: 0.6279520988464355 Validation Loss: 0.6240847706794739  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1550 learning rate: 0.001 Training Loss: 0.6279266476631165 Validation Loss: 0.6240561604499817  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1551 learning rate: 0.001 Training Loss: 0.6279012560844421 Validation Loss: 0.6240275502204895  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1552 learning rate: 0.001 Training Loss: 0.6278756856918335 Validation Loss: 0.6239988803863525  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1553 learning rate: 0.001 Training Loss: 0.6278501749038696 Validation Loss: 0.6239704489707947  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1554 learning rate: 0.001 Training Loss: 0.6278247237205505 Validation Loss: 0.6239418387413025  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1555 learning rate: 0.001 Training Loss: 0.6277992725372314 Validation Loss: 0.6239131093025208  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1556 learning rate: 0.001 Training Loss: 0.6277737617492676 Validation Loss: 0.6238845586776733  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1557 learning rate: 0.001 Training Loss: 0.6277482509613037 Validation Loss: 0.6238560080528259  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1558 learning rate: 0.001 Training Loss: 0.6277228593826294 Validation Loss: 0.6238275170326233  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1559 learning rate: 0.001 Training Loss: 0.6276974678039551 Validation Loss: 0.6237989068031311  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1560 learning rate: 0.001 Training Loss: 0.6276718974113464 Validation Loss: 0.6237704157829285  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1561 learning rate: 0.001 Training Loss: 0.6276463866233826 Validation Loss: 0.623741865158081  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1562 learning rate: 0.001 Training Loss: 0.6276209950447083 Validation Loss: 0.6237131357192993  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1563 learning rate: 0.001 Training Loss: 0.6275954842567444 Validation Loss: 0.6236845850944519  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1564 learning rate: 0.001 Training Loss: 0.6275699734687805 Validation Loss: 0.6236560940742493  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1565 learning rate: 0.001 Training Loss: 0.6275445222854614 Validation Loss: 0.6236276030540466  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1566 learning rate: 0.001 Training Loss: 0.6275192499160767 Validation Loss: 0.6235989332199097  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1567 learning rate: 0.001 Training Loss: 0.627493679523468 Validation Loss: 0.6235703825950623  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1568 learning rate: 0.001 Training Loss: 0.6274682283401489 Validation Loss: 0.6235418915748596  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1569 learning rate: 0.001 Training Loss: 0.6274428963661194 Validation Loss: 0.623513400554657  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1570 learning rate: 0.001 Training Loss: 0.6274173855781555 Validation Loss: 0.6234848499298096  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1571 learning rate: 0.001 Training Loss: 0.6273919343948364 Validation Loss: 0.6234562993049622  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1572 learning rate: 0.001 Training Loss: 0.6273664832115173 Validation Loss: 0.6234277486801147  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1573 learning rate: 0.001 Training Loss: 0.6273410320281982 Validation Loss: 0.6233991384506226  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1574 learning rate: 0.001 Training Loss: 0.6273156404495239 Validation Loss: 0.6233707070350647  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1575 learning rate: 0.001 Training Loss: 0.6272902488708496 Validation Loss: 0.6233422160148621  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1576 learning rate: 0.001 Training Loss: 0.6272649168968201 Validation Loss: 0.6233137845993042  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1577 learning rate: 0.001 Training Loss: 0.6272393465042114 Validation Loss: 0.6232852339744568  accuracy_train: 0.8392 accuracy_test: 0.8947 \n",
            "Epoch: 1578 learning rate: 0.001 Training Loss: 0.6272139549255371 Validation Loss: 0.6232565641403198  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1579 learning rate: 0.001 Training Loss: 0.6271886229515076 Validation Loss: 0.6232281923294067  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1580 learning rate: 0.001 Training Loss: 0.6271631717681885 Validation Loss: 0.6231996417045593  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1581 learning rate: 0.001 Training Loss: 0.6271378993988037 Validation Loss: 0.6231710910797119  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1582 learning rate: 0.001 Training Loss: 0.6271123290061951 Validation Loss: 0.6231426000595093  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1583 learning rate: 0.001 Training Loss: 0.6270869374275208 Validation Loss: 0.6231142282485962  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1584 learning rate: 0.001 Training Loss: 0.6270616054534912 Validation Loss: 0.6230857372283936  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1585 learning rate: 0.001 Training Loss: 0.6270360350608826 Validation Loss: 0.6230572462081909  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1586 learning rate: 0.001 Training Loss: 0.627010703086853 Validation Loss: 0.6230286955833435  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1587 learning rate: 0.001 Training Loss: 0.6269854307174683 Validation Loss: 0.6230002045631409  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1588 learning rate: 0.001 Training Loss: 0.6269599795341492 Validation Loss: 0.6229716539382935  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1589 learning rate: 0.001 Training Loss: 0.6269345879554749 Validation Loss: 0.6229432821273804  accuracy_train: 0.8417 accuracy_test: 0.8947 \n",
            "Epoch: 1590 learning rate: 0.001 Training Loss: 0.6269091367721558 Validation Loss: 0.622914731502533  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1591 learning rate: 0.001 Training Loss: 0.6268836855888367 Validation Loss: 0.6228862404823303  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1592 learning rate: 0.001 Training Loss: 0.6268583536148071 Validation Loss: 0.6228578090667725  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1593 learning rate: 0.001 Training Loss: 0.6268329620361328 Validation Loss: 0.6228294372558594  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1594 learning rate: 0.001 Training Loss: 0.6268076300621033 Validation Loss: 0.622800886631012  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1595 learning rate: 0.001 Training Loss: 0.626782238483429 Validation Loss: 0.6227724552154541  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1596 learning rate: 0.001 Training Loss: 0.6267568469047546 Validation Loss: 0.6227439045906067  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1597 learning rate: 0.001 Training Loss: 0.6267315149307251 Validation Loss: 0.6227155327796936  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1598 learning rate: 0.001 Training Loss: 0.6267061233520508 Validation Loss: 0.6226871609687805  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1599 learning rate: 0.001 Training Loss: 0.6266806721687317 Validation Loss: 0.6226586699485779  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1600 learning rate: 0.001 Training Loss: 0.6266553401947021 Validation Loss: 0.62263023853302  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1601 learning rate: 0.001 Training Loss: 0.6266299486160278 Validation Loss: 0.6226017475128174  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1602 learning rate: 0.001 Training Loss: 0.6266046166419983 Validation Loss: 0.6225733160972595  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1603 learning rate: 0.001 Training Loss: 0.626579225063324 Validation Loss: 0.6225448250770569  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1604 learning rate: 0.001 Training Loss: 0.6265539526939392 Validation Loss: 0.622516393661499  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1605 learning rate: 0.001 Training Loss: 0.6265286207199097 Validation Loss: 0.6224880218505859  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1606 learning rate: 0.001 Training Loss: 0.6265032291412354 Validation Loss: 0.6224595308303833  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1607 learning rate: 0.001 Training Loss: 0.6264778971672058 Validation Loss: 0.6224312782287598  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1608 learning rate: 0.001 Training Loss: 0.6264524459838867 Validation Loss: 0.6224027872085571  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1609 learning rate: 0.001 Training Loss: 0.626427173614502 Validation Loss: 0.6223743557929993  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1610 learning rate: 0.001 Training Loss: 0.6264018416404724 Validation Loss: 0.6223459243774414  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1611 learning rate: 0.001 Training Loss: 0.6263765692710876 Validation Loss: 0.6223175525665283  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1612 learning rate: 0.001 Training Loss: 0.6263512372970581 Validation Loss: 0.6222891807556152  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1613 learning rate: 0.001 Training Loss: 0.6263258457183838 Validation Loss: 0.6222606897354126  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1614 learning rate: 0.001 Training Loss: 0.6263005137443542 Validation Loss: 0.6222322583198547  accuracy_train: 0.8442 accuracy_test: 0.8947 \n",
            "Epoch: 1615 learning rate: 0.001 Training Loss: 0.6262751221656799 Validation Loss: 0.6222038865089417  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1616 learning rate: 0.001 Training Loss: 0.6262498497962952 Validation Loss: 0.6221754550933838  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1617 learning rate: 0.001 Training Loss: 0.6262245178222656 Validation Loss: 0.6221470236778259  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1618 learning rate: 0.001 Training Loss: 0.6261991858482361 Validation Loss: 0.6221187114715576  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1619 learning rate: 0.001 Training Loss: 0.6261738538742065 Validation Loss: 0.6220903396606445  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1620 learning rate: 0.001 Training Loss: 0.6261484622955322 Validation Loss: 0.6220619678497314  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1621 learning rate: 0.001 Training Loss: 0.6261231899261475 Validation Loss: 0.6220335364341736  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1622 learning rate: 0.001 Training Loss: 0.6260978579521179 Validation Loss: 0.6220051646232605  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1623 learning rate: 0.001 Training Loss: 0.6260725855827332 Validation Loss: 0.621976912021637  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1624 learning rate: 0.001 Training Loss: 0.6260473132133484 Validation Loss: 0.6219484806060791  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1625 learning rate: 0.001 Training Loss: 0.6260220408439636 Validation Loss: 0.621920108795166  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1626 learning rate: 0.001 Training Loss: 0.6259966492652893 Validation Loss: 0.6218917369842529  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1627 learning rate: 0.001 Training Loss: 0.6259713768959045 Validation Loss: 0.6218633651733398  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1628 learning rate: 0.001 Training Loss: 0.6259461045265198 Validation Loss: 0.6218350529670715  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1629 learning rate: 0.001 Training Loss: 0.6259207725524902 Validation Loss: 0.6218067407608032  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1630 learning rate: 0.001 Training Loss: 0.625895619392395 Validation Loss: 0.6217783093452454  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1631 learning rate: 0.001 Training Loss: 0.6258701682090759 Validation Loss: 0.6217498779296875  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1632 learning rate: 0.001 Training Loss: 0.6258448958396912 Validation Loss: 0.621721625328064  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1633 learning rate: 0.001 Training Loss: 0.6258196234703064 Validation Loss: 0.6216932535171509  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1634 learning rate: 0.001 Training Loss: 0.6257943511009216 Validation Loss: 0.6216649413108826  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1635 learning rate: 0.001 Training Loss: 0.6257691383361816 Validation Loss: 0.6216365694999695  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1636 learning rate: 0.001 Training Loss: 0.6257437467575073 Validation Loss: 0.6216081976890564  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1637 learning rate: 0.001 Training Loss: 0.6257185339927673 Validation Loss: 0.6215800046920776  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1638 learning rate: 0.001 Training Loss: 0.625693142414093 Validation Loss: 0.6215515732765198  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1639 learning rate: 0.001 Training Loss: 0.6256678700447083 Validation Loss: 0.621523380279541  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1640 learning rate: 0.001 Training Loss: 0.6256426572799683 Validation Loss: 0.6214949488639832  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1641 learning rate: 0.001 Training Loss: 0.6256174445152283 Validation Loss: 0.6214665770530701  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1642 learning rate: 0.001 Training Loss: 0.6255921125411987 Validation Loss: 0.6214383244514465  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1643 learning rate: 0.001 Training Loss: 0.6255669593811035 Validation Loss: 0.6214100122451782  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1644 learning rate: 0.001 Training Loss: 0.625541627407074 Validation Loss: 0.6213816404342651  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1645 learning rate: 0.001 Training Loss: 0.6255163550376892 Validation Loss: 0.6213533878326416  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1646 learning rate: 0.001 Training Loss: 0.6254910826683044 Validation Loss: 0.6213250160217285  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1647 learning rate: 0.001 Training Loss: 0.6254658699035645 Validation Loss: 0.6212968230247498  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1648 learning rate: 0.001 Training Loss: 0.6254406571388245 Validation Loss: 0.6212684512138367  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1649 learning rate: 0.001 Training Loss: 0.6254153251647949 Validation Loss: 0.6212401390075684  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1650 learning rate: 0.001 Training Loss: 0.6253900527954102 Validation Loss: 0.6212118864059448  accuracy_train: 0.8442 accuracy_test: 0.9006 \n",
            "Epoch: 1651 learning rate: 0.001 Training Loss: 0.6253648996353149 Validation Loss: 0.6211836338043213  accuracy_train: 0.8467 accuracy_test: 0.9006 \n",
            "Epoch: 1652 learning rate: 0.001 Training Loss: 0.6253396272659302 Validation Loss: 0.621155321598053  accuracy_train: 0.8467 accuracy_test: 0.9006 \n",
            "Epoch: 1653 learning rate: 0.001 Training Loss: 0.6253143548965454 Validation Loss: 0.6211270093917847  accuracy_train: 0.8467 accuracy_test: 0.9006 \n",
            "Epoch: 1654 learning rate: 0.001 Training Loss: 0.6252891421318054 Validation Loss: 0.6210987567901611  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1655 learning rate: 0.001 Training Loss: 0.6252639293670654 Validation Loss: 0.6210705041885376  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1656 learning rate: 0.001 Training Loss: 0.6252387166023254 Validation Loss: 0.6210422515869141  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1657 learning rate: 0.001 Training Loss: 0.6252135038375854 Validation Loss: 0.6210139989852905  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1658 learning rate: 0.001 Training Loss: 0.6251882314682007 Validation Loss: 0.6209856271743774  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1659 learning rate: 0.001 Training Loss: 0.6251630783081055 Validation Loss: 0.6209573149681091  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1660 learning rate: 0.001 Training Loss: 0.6251377463340759 Validation Loss: 0.6209291219711304  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1661 learning rate: 0.001 Training Loss: 0.6251126527786255 Validation Loss: 0.6209009885787964  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1662 learning rate: 0.001 Training Loss: 0.6250872611999512 Validation Loss: 0.6208726167678833  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1663 learning rate: 0.001 Training Loss: 0.6250621676445007 Validation Loss: 0.6208443641662598  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1664 learning rate: 0.001 Training Loss: 0.625036895275116 Validation Loss: 0.6208161115646362  accuracy_train: 0.8492 accuracy_test: 0.9006 \n",
            "Epoch: 1665 learning rate: 0.001 Training Loss: 0.6250117421150208 Validation Loss: 0.6207878589630127  accuracy_train: 0.8518 accuracy_test: 0.9006 \n",
            "Epoch: 1666 learning rate: 0.001 Training Loss: 0.624986469745636 Validation Loss: 0.6207596063613892  accuracy_train: 0.8518 accuracy_test: 0.9006 \n",
            "Epoch: 1667 learning rate: 0.001 Training Loss: 0.6249613165855408 Validation Loss: 0.6207313537597656  accuracy_train: 0.8518 accuracy_test: 0.9006 \n",
            "Epoch: 1668 learning rate: 0.001 Training Loss: 0.6249361038208008 Validation Loss: 0.6207031607627869  accuracy_train: 0.8518 accuracy_test: 0.9006 \n",
            "Epoch: 1669 learning rate: 0.001 Training Loss: 0.6249108910560608 Validation Loss: 0.6206749081611633  accuracy_train: 0.8518 accuracy_test: 0.9006 \n",
            "Epoch: 1670 learning rate: 0.001 Training Loss: 0.624885618686676 Validation Loss: 0.620646595954895  accuracy_train: 0.8518 accuracy_test: 0.9006 \n",
            "Epoch: 1671 learning rate: 0.001 Training Loss: 0.6248605251312256 Validation Loss: 0.620618462562561  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1672 learning rate: 0.001 Training Loss: 0.6248353123664856 Validation Loss: 0.6205902695655823  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1673 learning rate: 0.001 Training Loss: 0.6248101592063904 Validation Loss: 0.6205620765686035  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1674 learning rate: 0.001 Training Loss: 0.6247850060462952 Validation Loss: 0.62053382396698  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1675 learning rate: 0.001 Training Loss: 0.6247597932815552 Validation Loss: 0.6205055713653564  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1676 learning rate: 0.001 Training Loss: 0.6247345805168152 Validation Loss: 0.6204774379730225  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1677 learning rate: 0.001 Training Loss: 0.6247093677520752 Validation Loss: 0.6204491853713989  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1678 learning rate: 0.001 Training Loss: 0.62468421459198 Validation Loss: 0.6204209923744202  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1679 learning rate: 0.001 Training Loss: 0.62465900182724 Validation Loss: 0.6203927993774414  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1680 learning rate: 0.001 Training Loss: 0.6246338486671448 Validation Loss: 0.6203644871711731  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1681 learning rate: 0.001 Training Loss: 0.6246086955070496 Validation Loss: 0.6203363537788391  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1682 learning rate: 0.001 Training Loss: 0.6245835423469543 Validation Loss: 0.6203081607818604  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1683 learning rate: 0.001 Training Loss: 0.6245583891868591 Validation Loss: 0.6202799677848816  accuracy_train: 0.8543 accuracy_test: 0.9006 \n",
            "Epoch: 1684 learning rate: 0.001 Training Loss: 0.6245331168174744 Validation Loss: 0.6202517747879028  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1685 learning rate: 0.001 Training Loss: 0.6245081424713135 Validation Loss: 0.6202235817909241  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1686 learning rate: 0.001 Training Loss: 0.6244828701019287 Validation Loss: 0.6201953291893005  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1687 learning rate: 0.001 Training Loss: 0.6244577169418335 Validation Loss: 0.6201671957969666  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1688 learning rate: 0.001 Training Loss: 0.6244325637817383 Validation Loss: 0.6201390624046326  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1689 learning rate: 0.001 Training Loss: 0.6244074106216431 Validation Loss: 0.6201108694076538  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1690 learning rate: 0.001 Training Loss: 0.6243821978569031 Validation Loss: 0.6200825572013855  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1691 learning rate: 0.001 Training Loss: 0.6243570446968079 Validation Loss: 0.6200544834136963  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1692 learning rate: 0.001 Training Loss: 0.6243318319320679 Validation Loss: 0.6200263500213623  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1693 learning rate: 0.001 Training Loss: 0.6243069171905518 Validation Loss: 0.6199981570243835  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1694 learning rate: 0.001 Training Loss: 0.6242817044258118 Validation Loss: 0.6199700832366943  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1695 learning rate: 0.001 Training Loss: 0.6242564916610718 Validation Loss: 0.6199419498443604  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1696 learning rate: 0.001 Training Loss: 0.6242313385009766 Validation Loss: 0.6199137568473816  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1697 learning rate: 0.001 Training Loss: 0.6242063045501709 Validation Loss: 0.6198855638504028  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1698 learning rate: 0.001 Training Loss: 0.6241811513900757 Validation Loss: 0.6198574304580688  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1699 learning rate: 0.001 Training Loss: 0.6241560578346252 Validation Loss: 0.6198292970657349  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1700 learning rate: 0.001 Training Loss: 0.62413090467453 Validation Loss: 0.6198012232780457  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1701 learning rate: 0.001 Training Loss: 0.6241058111190796 Validation Loss: 0.6197729706764221  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1702 learning rate: 0.001 Training Loss: 0.6240806579589844 Validation Loss: 0.6197448372840881  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1703 learning rate: 0.001 Training Loss: 0.6240555047988892 Validation Loss: 0.6197167038917542  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1704 learning rate: 0.001 Training Loss: 0.6240304708480835 Validation Loss: 0.6196886301040649  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1705 learning rate: 0.001 Training Loss: 0.6240053772926331 Validation Loss: 0.619660496711731  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1706 learning rate: 0.001 Training Loss: 0.6239801049232483 Validation Loss: 0.619632363319397  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1707 learning rate: 0.001 Training Loss: 0.6239550709724426 Validation Loss: 0.6196043491363525  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1708 learning rate: 0.001 Training Loss: 0.6239300966262817 Validation Loss: 0.619576096534729  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1709 learning rate: 0.001 Training Loss: 0.6239048838615417 Validation Loss: 0.6195480227470398  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1710 learning rate: 0.001 Training Loss: 0.6238797307014465 Validation Loss: 0.6195198893547058  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1711 learning rate: 0.001 Training Loss: 0.6238545775413513 Validation Loss: 0.6194917559623718  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1712 learning rate: 0.001 Training Loss: 0.6238296627998352 Validation Loss: 0.6194637417793274  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1713 learning rate: 0.001 Training Loss: 0.6238046288490295 Validation Loss: 0.6194356083869934  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1714 learning rate: 0.001 Training Loss: 0.6237793564796448 Validation Loss: 0.619407594203949  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1715 learning rate: 0.001 Training Loss: 0.6237542629241943 Validation Loss: 0.6193795204162598  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1716 learning rate: 0.001 Training Loss: 0.6237291693687439 Validation Loss: 0.619351327419281  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1717 learning rate: 0.001 Training Loss: 0.6237041354179382 Validation Loss: 0.6193233132362366  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1718 learning rate: 0.001 Training Loss: 0.6236791014671326 Validation Loss: 0.6192951202392578  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1719 learning rate: 0.001 Training Loss: 0.6236540675163269 Validation Loss: 0.6192670464515686  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1720 learning rate: 0.001 Training Loss: 0.6236289143562317 Validation Loss: 0.6192390322685242  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1721 learning rate: 0.001 Training Loss: 0.6236038208007812 Validation Loss: 0.619210958480835  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1722 learning rate: 0.001 Training Loss: 0.6235786080360413 Validation Loss: 0.6191828846931458  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1723 learning rate: 0.001 Training Loss: 0.6235536932945251 Validation Loss: 0.6191548109054565  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1724 learning rate: 0.001 Training Loss: 0.6235286593437195 Validation Loss: 0.6191266775131226  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1725 learning rate: 0.001 Training Loss: 0.6235035061836243 Validation Loss: 0.6190986037254333  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1726 learning rate: 0.001 Training Loss: 0.6234784722328186 Validation Loss: 0.6190705895423889  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1727 learning rate: 0.001 Training Loss: 0.6234534382820129 Validation Loss: 0.6190425157546997  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1728 learning rate: 0.001 Training Loss: 0.6234283447265625 Validation Loss: 0.6190145015716553  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1729 learning rate: 0.001 Training Loss: 0.6234032511711121 Validation Loss: 0.6189863681793213  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1730 learning rate: 0.001 Training Loss: 0.6233782172203064 Validation Loss: 0.6189584136009216  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1731 learning rate: 0.001 Training Loss: 0.6233531832695007 Validation Loss: 0.6189302802085876  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1732 learning rate: 0.001 Training Loss: 0.6233281493186951 Validation Loss: 0.6189022660255432  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1733 learning rate: 0.001 Training Loss: 0.6233030557632446 Validation Loss: 0.618874192237854  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1734 learning rate: 0.001 Training Loss: 0.6232779622077942 Validation Loss: 0.6188462376594543  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1735 learning rate: 0.001 Training Loss: 0.6232529878616333 Validation Loss: 0.6188181638717651  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1736 learning rate: 0.001 Training Loss: 0.6232279539108276 Validation Loss: 0.6187901496887207  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1737 learning rate: 0.001 Training Loss: 0.6232028603553772 Validation Loss: 0.6187620759010315  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1738 learning rate: 0.001 Training Loss: 0.6231778264045715 Validation Loss: 0.6187340617179871  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1739 learning rate: 0.001 Training Loss: 0.6231528520584106 Validation Loss: 0.6187061071395874  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1740 learning rate: 0.001 Training Loss: 0.623127818107605 Validation Loss: 0.6186780333518982  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1741 learning rate: 0.001 Training Loss: 0.6231027841567993 Validation Loss: 0.6186500191688538  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1742 learning rate: 0.001 Training Loss: 0.6230777502059937 Validation Loss: 0.6186220049858093  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1743 learning rate: 0.001 Training Loss: 0.623052716255188 Validation Loss: 0.6185939908027649  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1744 learning rate: 0.001 Training Loss: 0.6230276823043823 Validation Loss: 0.6185660362243652  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1745 learning rate: 0.001 Training Loss: 0.6230026483535767 Validation Loss: 0.618537962436676  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1746 learning rate: 0.001 Training Loss: 0.6229776740074158 Validation Loss: 0.6185098886489868  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1747 learning rate: 0.001 Training Loss: 0.6229526996612549 Validation Loss: 0.6184819936752319  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1748 learning rate: 0.001 Training Loss: 0.622927725315094 Validation Loss: 0.6184539794921875  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1749 learning rate: 0.001 Training Loss: 0.6229025721549988 Validation Loss: 0.6184259057044983  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1750 learning rate: 0.001 Training Loss: 0.6228776574134827 Validation Loss: 0.6183980107307434  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1751 learning rate: 0.001 Training Loss: 0.622852623462677 Validation Loss: 0.618369996547699  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1752 learning rate: 0.001 Training Loss: 0.6228277087211609 Validation Loss: 0.6183419823646545  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1753 learning rate: 0.001 Training Loss: 0.6228026151657104 Validation Loss: 0.6183140277862549  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1754 learning rate: 0.001 Training Loss: 0.6227776408195496 Validation Loss: 0.6182860732078552  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1755 learning rate: 0.001 Training Loss: 0.6227526068687439 Validation Loss: 0.618257999420166  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1756 learning rate: 0.001 Training Loss: 0.6227276921272278 Validation Loss: 0.6182300448417664  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1757 learning rate: 0.001 Training Loss: 0.6227025389671326 Validation Loss: 0.6182020902633667  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1758 learning rate: 0.001 Training Loss: 0.6226776838302612 Validation Loss: 0.618174135684967  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1759 learning rate: 0.001 Training Loss: 0.6226526498794556 Validation Loss: 0.6181461215019226  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1760 learning rate: 0.001 Training Loss: 0.6226277351379395 Validation Loss: 0.6181183457374573  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1761 learning rate: 0.001 Training Loss: 0.6226027607917786 Validation Loss: 0.6180902719497681  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1762 learning rate: 0.001 Training Loss: 0.6225777864456177 Validation Loss: 0.6180623173713684  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1763 learning rate: 0.001 Training Loss: 0.622552752494812 Validation Loss: 0.618034303188324  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1764 learning rate: 0.001 Training Loss: 0.6225277781486511 Validation Loss: 0.6180064082145691  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1765 learning rate: 0.001 Training Loss: 0.6225028038024902 Validation Loss: 0.6179783940315247  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1766 learning rate: 0.001 Training Loss: 0.6224778890609741 Validation Loss: 0.617950439453125  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1767 learning rate: 0.001 Training Loss: 0.6224529147148132 Validation Loss: 0.6179226040840149  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1768 learning rate: 0.001 Training Loss: 0.6224279999732971 Validation Loss: 0.6178946495056152  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1769 learning rate: 0.001 Training Loss: 0.6224029660224915 Validation Loss: 0.6178666949272156  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1770 learning rate: 0.001 Training Loss: 0.6223779916763306 Validation Loss: 0.6178387403488159  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1771 learning rate: 0.001 Training Loss: 0.6223530173301697 Validation Loss: 0.617810845375061  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1772 learning rate: 0.001 Training Loss: 0.6223281025886536 Validation Loss: 0.6177828907966614  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1773 learning rate: 0.001 Training Loss: 0.6223031878471375 Validation Loss: 0.6177549958229065  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1774 learning rate: 0.001 Training Loss: 0.6222781538963318 Validation Loss: 0.6177271604537964  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1775 learning rate: 0.001 Training Loss: 0.6222532391548157 Validation Loss: 0.617699146270752  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1776 learning rate: 0.001 Training Loss: 0.6222283244132996 Validation Loss: 0.6176713109016418  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1777 learning rate: 0.001 Training Loss: 0.6222033500671387 Validation Loss: 0.617643415927887  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1778 learning rate: 0.001 Training Loss: 0.6221784353256226 Validation Loss: 0.6176153421401978  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1779 learning rate: 0.001 Training Loss: 0.6221534609794617 Validation Loss: 0.6175873875617981  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1780 learning rate: 0.001 Training Loss: 0.6221284866333008 Validation Loss: 0.6175596714019775  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1781 learning rate: 0.001 Training Loss: 0.6221034526824951 Validation Loss: 0.6175317168235779  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1782 learning rate: 0.001 Training Loss: 0.6220787167549133 Validation Loss: 0.617503821849823  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1783 learning rate: 0.001 Training Loss: 0.6220537424087524 Validation Loss: 0.6174761056900024  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1784 learning rate: 0.001 Training Loss: 0.6220287680625916 Validation Loss: 0.6174481511116028  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1785 learning rate: 0.001 Training Loss: 0.622003972530365 Validation Loss: 0.6174201369285583  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1786 learning rate: 0.001 Training Loss: 0.6219789385795593 Validation Loss: 0.6173923015594482  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1787 learning rate: 0.001 Training Loss: 0.6219540238380432 Validation Loss: 0.6173644065856934  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1788 learning rate: 0.001 Training Loss: 0.6219291687011719 Validation Loss: 0.6173364520072937  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1789 learning rate: 0.001 Training Loss: 0.6219042539596558 Validation Loss: 0.6173086166381836  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1790 learning rate: 0.001 Training Loss: 0.6218793988227844 Validation Loss: 0.6172808408737183  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1791 learning rate: 0.001 Training Loss: 0.6218543648719788 Validation Loss: 0.6172528862953186  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1792 learning rate: 0.001 Training Loss: 0.6218294501304626 Validation Loss: 0.6172250509262085  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1793 learning rate: 0.001 Training Loss: 0.6218045949935913 Validation Loss: 0.6171972155570984  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1794 learning rate: 0.001 Training Loss: 0.6217796802520752 Validation Loss: 0.6171693205833435  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1795 learning rate: 0.001 Training Loss: 0.6217548251152039 Validation Loss: 0.6171414852142334  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1796 learning rate: 0.001 Training Loss: 0.621729850769043 Validation Loss: 0.6171136498451233  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1797 learning rate: 0.001 Training Loss: 0.6217049956321716 Validation Loss: 0.6170857548713684  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1798 learning rate: 0.001 Training Loss: 0.6216801404953003 Validation Loss: 0.6170579791069031  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1799 learning rate: 0.001 Training Loss: 0.621655285358429 Validation Loss: 0.6170300841331482  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1800 learning rate: 0.001 Training Loss: 0.6216303110122681 Validation Loss: 0.6170022487640381  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1801 learning rate: 0.001 Training Loss: 0.6216055154800415 Validation Loss: 0.616974413394928  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1802 learning rate: 0.001 Training Loss: 0.6215804815292358 Validation Loss: 0.6169465184211731  accuracy_train: 0.8568 accuracy_test: 0.9006 \n",
            "Epoch: 1803 learning rate: 0.001 Training Loss: 0.6215556263923645 Validation Loss: 0.616918683052063  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1804 learning rate: 0.001 Training Loss: 0.6215307116508484 Validation Loss: 0.6168908476829529  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1805 learning rate: 0.001 Training Loss: 0.6215059161186218 Validation Loss: 0.6168630123138428  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1806 learning rate: 0.001 Training Loss: 0.6214811205863953 Validation Loss: 0.6168352365493774  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1807 learning rate: 0.001 Training Loss: 0.6214560866355896 Validation Loss: 0.6168073415756226  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1808 learning rate: 0.001 Training Loss: 0.6214313507080078 Validation Loss: 0.6167795658111572  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1809 learning rate: 0.001 Training Loss: 0.6214064955711365 Validation Loss: 0.6167517900466919  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1810 learning rate: 0.001 Training Loss: 0.6213815808296204 Validation Loss: 0.6167240738868713  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1811 learning rate: 0.001 Training Loss: 0.6213566660881042 Validation Loss: 0.6166962385177612  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1812 learning rate: 0.001 Training Loss: 0.6213318109512329 Validation Loss: 0.6166684031486511  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1813 learning rate: 0.001 Training Loss: 0.6213070154190063 Validation Loss: 0.616640567779541  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1814 learning rate: 0.001 Training Loss: 0.6212822794914246 Validation Loss: 0.6166127324104309  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1815 learning rate: 0.001 Training Loss: 0.6212573051452637 Validation Loss: 0.6165849566459656  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1816 learning rate: 0.001 Training Loss: 0.6212324500083923 Validation Loss: 0.616557240486145  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1817 learning rate: 0.001 Training Loss: 0.6212074756622314 Validation Loss: 0.6165293455123901  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1818 learning rate: 0.001 Training Loss: 0.6211827993392944 Validation Loss: 0.6165014505386353  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1819 learning rate: 0.001 Training Loss: 0.6211579442024231 Validation Loss: 0.6164738535881042  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1820 learning rate: 0.001 Training Loss: 0.6211330890655518 Validation Loss: 0.6164460182189941  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1821 learning rate: 0.001 Training Loss: 0.6211082339286804 Validation Loss: 0.6164182424545288  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1822 learning rate: 0.001 Training Loss: 0.6210833191871643 Validation Loss: 0.6163904666900635  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1823 learning rate: 0.001 Training Loss: 0.6210585832595825 Validation Loss: 0.6163626313209534  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1824 learning rate: 0.001 Training Loss: 0.6210337281227112 Validation Loss: 0.616334855556488  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1825 learning rate: 0.001 Training Loss: 0.6210089325904846 Validation Loss: 0.6163071990013123  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1826 learning rate: 0.001 Training Loss: 0.6209841370582581 Validation Loss: 0.6162793636322021  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1827 learning rate: 0.001 Training Loss: 0.6209591627120972 Validation Loss: 0.6162516474723816  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1828 learning rate: 0.001 Training Loss: 0.6209344267845154 Validation Loss: 0.6162238717079163  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1829 learning rate: 0.001 Training Loss: 0.6209095120429993 Validation Loss: 0.6161960959434509  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1830 learning rate: 0.001 Training Loss: 0.6208847761154175 Validation Loss: 0.6161684393882751  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1831 learning rate: 0.001 Training Loss: 0.6208599805831909 Validation Loss: 0.6161406636238098  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1832 learning rate: 0.001 Training Loss: 0.6208351254463196 Validation Loss: 0.6161128878593445  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1833 learning rate: 0.001 Training Loss: 0.620810329914093 Validation Loss: 0.6160852313041687  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1834 learning rate: 0.001 Training Loss: 0.6207855939865112 Validation Loss: 0.6160573959350586  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1835 learning rate: 0.001 Training Loss: 0.6207606792449951 Validation Loss: 0.6160296201705933  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1836 learning rate: 0.001 Training Loss: 0.6207359433174133 Validation Loss: 0.6160019040107727  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1837 learning rate: 0.001 Training Loss: 0.6207111477851868 Validation Loss: 0.6159743070602417  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1838 learning rate: 0.001 Training Loss: 0.6206862330436707 Validation Loss: 0.6159464120864868  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1839 learning rate: 0.001 Training Loss: 0.6206615567207336 Validation Loss: 0.6159186959266663  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1840 learning rate: 0.001 Training Loss: 0.6206367611885071 Validation Loss: 0.6158909797668457  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1841 learning rate: 0.001 Training Loss: 0.620611846446991 Validation Loss: 0.6158633232116699  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1842 learning rate: 0.001 Training Loss: 0.6205872297286987 Validation Loss: 0.6158356070518494  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1843 learning rate: 0.001 Training Loss: 0.6205623149871826 Validation Loss: 0.6158078908920288  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1844 learning rate: 0.001 Training Loss: 0.620537519454956 Validation Loss: 0.615780234336853  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1845 learning rate: 0.001 Training Loss: 0.620512843132019 Validation Loss: 0.6157524585723877  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1846 learning rate: 0.001 Training Loss: 0.6204880475997925 Validation Loss: 0.6157246828079224  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1847 learning rate: 0.001 Training Loss: 0.6204632520675659 Validation Loss: 0.6156970262527466  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1848 learning rate: 0.001 Training Loss: 0.6204384565353394 Validation Loss: 0.615669310092926  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1849 learning rate: 0.001 Training Loss: 0.6204137206077576 Validation Loss: 0.6156415343284607  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1850 learning rate: 0.001 Training Loss: 0.6203888654708862 Validation Loss: 0.6156138777732849  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1851 learning rate: 0.001 Training Loss: 0.6203640699386597 Validation Loss: 0.6155862808227539  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1852 learning rate: 0.001 Training Loss: 0.6203393340110779 Validation Loss: 0.6155585646629333  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1853 learning rate: 0.001 Training Loss: 0.6203147172927856 Validation Loss: 0.6155308485031128  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1854 learning rate: 0.001 Training Loss: 0.6202898025512695 Validation Loss: 0.6155032515525818  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1855 learning rate: 0.001 Training Loss: 0.6202650666236877 Validation Loss: 0.6154754161834717  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1856 learning rate: 0.001 Training Loss: 0.6202403903007507 Validation Loss: 0.6154478192329407  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1857 learning rate: 0.001 Training Loss: 0.6202155351638794 Validation Loss: 0.6154201030731201  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1858 learning rate: 0.001 Training Loss: 0.6201908588409424 Validation Loss: 0.6153924465179443  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1859 learning rate: 0.001 Training Loss: 0.620166003704071 Validation Loss: 0.6153647303581238  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1860 learning rate: 0.001 Training Loss: 0.6201412081718445 Validation Loss: 0.615337073802948  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1861 learning rate: 0.001 Training Loss: 0.6201165914535522 Validation Loss: 0.6153095364570618  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1862 learning rate: 0.001 Training Loss: 0.6200918555259705 Validation Loss: 0.6152817010879517  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1863 learning rate: 0.001 Training Loss: 0.6200670599937439 Validation Loss: 0.6152541637420654  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1864 learning rate: 0.001 Training Loss: 0.6200422644615173 Validation Loss: 0.6152265071868896  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1865 learning rate: 0.001 Training Loss: 0.6200176477432251 Validation Loss: 0.6151987910270691  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1866 learning rate: 0.001 Training Loss: 0.6199929118156433 Validation Loss: 0.6151711344718933  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1867 learning rate: 0.001 Training Loss: 0.6199681758880615 Validation Loss: 0.6151435971260071  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1868 learning rate: 0.001 Training Loss: 0.6199434995651245 Validation Loss: 0.6151159405708313  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1869 learning rate: 0.001 Training Loss: 0.6199187636375427 Validation Loss: 0.6150882244110107  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1870 learning rate: 0.001 Training Loss: 0.6198939681053162 Validation Loss: 0.6150606870651245  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1871 learning rate: 0.001 Training Loss: 0.6198692917823792 Validation Loss: 0.6150330305099487  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1872 learning rate: 0.001 Training Loss: 0.6198445558547974 Validation Loss: 0.6150054335594177  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1873 learning rate: 0.001 Training Loss: 0.6198198795318604 Validation Loss: 0.6149777173995972  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1874 learning rate: 0.001 Training Loss: 0.6197950839996338 Validation Loss: 0.6149501204490662  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1875 learning rate: 0.001 Training Loss: 0.6197704672813416 Validation Loss: 0.6149225234985352  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1876 learning rate: 0.001 Training Loss: 0.619745671749115 Validation Loss: 0.6148948669433594  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1877 learning rate: 0.001 Training Loss: 0.6197209358215332 Validation Loss: 0.6148672103881836  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1878 learning rate: 0.001 Training Loss: 0.6196962594985962 Validation Loss: 0.6148396134376526  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1879 learning rate: 0.001 Training Loss: 0.619671642780304 Validation Loss: 0.6148120164871216  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1880 learning rate: 0.001 Training Loss: 0.6196469068527222 Validation Loss: 0.6147843599319458  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1881 learning rate: 0.001 Training Loss: 0.6196221709251404 Validation Loss: 0.6147568225860596  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1882 learning rate: 0.001 Training Loss: 0.6195974946022034 Validation Loss: 0.6147291660308838  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1883 learning rate: 0.001 Training Loss: 0.6195728778839111 Validation Loss: 0.6147016882896423  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1884 learning rate: 0.001 Training Loss: 0.6195480823516846 Validation Loss: 0.6146741509437561  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1885 learning rate: 0.001 Training Loss: 0.6195234060287476 Validation Loss: 0.6146464943885803  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1886 learning rate: 0.001 Training Loss: 0.6194987893104553 Validation Loss: 0.6146189570426941  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1887 learning rate: 0.001 Training Loss: 0.6194739937782288 Validation Loss: 0.6145913004875183  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1888 learning rate: 0.001 Training Loss: 0.6194494366645813 Validation Loss: 0.6145636439323425  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1889 learning rate: 0.001 Training Loss: 0.6194246411323547 Validation Loss: 0.6145361065864563  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1890 learning rate: 0.001 Training Loss: 0.6193999648094177 Validation Loss: 0.6145085692405701  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1891 learning rate: 0.001 Training Loss: 0.6193753480911255 Validation Loss: 0.6144809126853943  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1892 learning rate: 0.001 Training Loss: 0.6193507313728333 Validation Loss: 0.6144534945487976  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1893 learning rate: 0.001 Training Loss: 0.6193259954452515 Validation Loss: 0.6144258379936218  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1894 learning rate: 0.001 Training Loss: 0.6193011999130249 Validation Loss: 0.6143983006477356  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1895 learning rate: 0.001 Training Loss: 0.6192767024040222 Validation Loss: 0.6143707633018494  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1896 learning rate: 0.001 Training Loss: 0.6192520260810852 Validation Loss: 0.6143431663513184  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1897 learning rate: 0.001 Training Loss: 0.6192273497581482 Validation Loss: 0.6143156290054321  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1898 learning rate: 0.001 Training Loss: 0.6192027926445007 Validation Loss: 0.6142880320549011  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1899 learning rate: 0.001 Training Loss: 0.6191779375076294 Validation Loss: 0.6142604351043701  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1900 learning rate: 0.001 Training Loss: 0.6191534399986267 Validation Loss: 0.6142328977584839  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1901 learning rate: 0.001 Training Loss: 0.6191287040710449 Validation Loss: 0.6142054796218872  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1902 learning rate: 0.001 Training Loss: 0.6191040277481079 Validation Loss: 0.6141777634620667  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1903 learning rate: 0.001 Training Loss: 0.6190793514251709 Validation Loss: 0.6141502857208252  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1904 learning rate: 0.001 Training Loss: 0.6190547943115234 Validation Loss: 0.614122748374939  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1905 learning rate: 0.001 Training Loss: 0.619030237197876 Validation Loss: 0.6140952110290527  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1906 learning rate: 0.001 Training Loss: 0.6190055012702942 Validation Loss: 0.6140677332878113  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1907 learning rate: 0.001 Training Loss: 0.6189808249473572 Validation Loss: 0.6140402555465698  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1908 learning rate: 0.001 Training Loss: 0.6189561486244202 Validation Loss: 0.6140126585960388  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1909 learning rate: 0.001 Training Loss: 0.6189316511154175 Validation Loss: 0.6139851808547974  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1910 learning rate: 0.001 Training Loss: 0.6189069747924805 Validation Loss: 0.6139577031135559  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1911 learning rate: 0.001 Training Loss: 0.6188823580741882 Validation Loss: 0.6139301657676697  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1912 learning rate: 0.001 Training Loss: 0.6188576221466064 Validation Loss: 0.6139026880264282  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1913 learning rate: 0.001 Training Loss: 0.6188331246376038 Validation Loss: 0.6138752102851868  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1914 learning rate: 0.001 Training Loss: 0.6188085079193115 Validation Loss: 0.6138476729393005  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1915 learning rate: 0.001 Training Loss: 0.6187838912010193 Validation Loss: 0.6138201355934143  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1916 learning rate: 0.001 Training Loss: 0.6187591552734375 Validation Loss: 0.6137926578521729  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1917 learning rate: 0.001 Training Loss: 0.6187346577644348 Validation Loss: 0.6137650609016418  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1918 learning rate: 0.001 Training Loss: 0.6187100410461426 Validation Loss: 0.6137375831604004  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1919 learning rate: 0.001 Training Loss: 0.6186853647232056 Validation Loss: 0.6137101054191589  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1920 learning rate: 0.001 Training Loss: 0.6186608076095581 Validation Loss: 0.613682746887207  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1921 learning rate: 0.001 Training Loss: 0.6186361908912659 Validation Loss: 0.613655149936676  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1922 learning rate: 0.001 Training Loss: 0.6186116337776184 Validation Loss: 0.6136276721954346  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1923 learning rate: 0.001 Training Loss: 0.618587076663971 Validation Loss: 0.6136001944541931  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1924 learning rate: 0.001 Training Loss: 0.6185624003410339 Validation Loss: 0.6135727167129517  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1925 learning rate: 0.001 Training Loss: 0.6185377836227417 Validation Loss: 0.6135451793670654  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1926 learning rate: 0.001 Training Loss: 0.6185131669044495 Validation Loss: 0.6135178208351135  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1927 learning rate: 0.001 Training Loss: 0.6184885501861572 Validation Loss: 0.6134903430938721  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1928 learning rate: 0.001 Training Loss: 0.6184641122817993 Validation Loss: 0.6134629845619202  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1929 learning rate: 0.001 Training Loss: 0.6184393763542175 Validation Loss: 0.6134353876113892  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1930 learning rate: 0.001 Training Loss: 0.6184148192405701 Validation Loss: 0.6134079694747925  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1931 learning rate: 0.001 Training Loss: 0.6183902621269226 Validation Loss: 0.613380491733551  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1932 learning rate: 0.001 Training Loss: 0.6183657050132751 Validation Loss: 0.6133530139923096  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1933 learning rate: 0.001 Training Loss: 0.6183410882949829 Validation Loss: 0.6133255362510681  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1934 learning rate: 0.001 Training Loss: 0.6183165311813354 Validation Loss: 0.6132981181144714  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1935 learning rate: 0.001 Training Loss: 0.6182920932769775 Validation Loss: 0.61327064037323  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1936 learning rate: 0.001 Training Loss: 0.6182671785354614 Validation Loss: 0.6132432222366333  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1937 learning rate: 0.001 Training Loss: 0.6182428002357483 Validation Loss: 0.6132157444953918  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1938 learning rate: 0.001 Training Loss: 0.6182182431221008 Validation Loss: 0.6131883859634399  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1939 learning rate: 0.001 Training Loss: 0.6181937456130981 Validation Loss: 0.6131609678268433  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1940 learning rate: 0.001 Training Loss: 0.6181690692901611 Validation Loss: 0.6131334900856018  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1941 learning rate: 0.001 Training Loss: 0.6181445717811584 Validation Loss: 0.6131060719490051  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1942 learning rate: 0.001 Training Loss: 0.6181200742721558 Validation Loss: 0.6130786538124084  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1943 learning rate: 0.001 Training Loss: 0.6180954575538635 Validation Loss: 0.6130512952804565  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1944 learning rate: 0.001 Training Loss: 0.6180709600448608 Validation Loss: 0.6130239367485046  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1945 learning rate: 0.001 Training Loss: 0.6180463433265686 Validation Loss: 0.6129964590072632  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1946 learning rate: 0.001 Training Loss: 0.6180218458175659 Validation Loss: 0.6129689812660217  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1947 learning rate: 0.001 Training Loss: 0.6179972290992737 Validation Loss: 0.612941563129425  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1948 learning rate: 0.001 Training Loss: 0.617972731590271 Validation Loss: 0.6129141449928284  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1949 learning rate: 0.001 Training Loss: 0.6179481744766235 Validation Loss: 0.6128866672515869  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1950 learning rate: 0.001 Training Loss: 0.6179236769676208 Validation Loss: 0.6128594279289246  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1951 learning rate: 0.001 Training Loss: 0.6178991198539734 Validation Loss: 0.6128320097923279  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1952 learning rate: 0.001 Training Loss: 0.6178746223449707 Validation Loss: 0.6128045320510864  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1953 learning rate: 0.001 Training Loss: 0.617850124835968 Validation Loss: 0.6127771139144897  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1954 learning rate: 0.001 Training Loss: 0.6178255677223206 Validation Loss: 0.6127497553825378  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1955 learning rate: 0.001 Training Loss: 0.6178010702133179 Validation Loss: 0.6127223372459412  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1956 learning rate: 0.001 Training Loss: 0.6177765130996704 Validation Loss: 0.6126949191093445  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1957 learning rate: 0.001 Training Loss: 0.6177518963813782 Validation Loss: 0.6126675605773926  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1958 learning rate: 0.001 Training Loss: 0.6177273392677307 Validation Loss: 0.6126402616500854  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1959 learning rate: 0.001 Training Loss: 0.6177029013633728 Validation Loss: 0.6126128435134888  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1960 learning rate: 0.001 Training Loss: 0.6176784634590149 Validation Loss: 0.6125854849815369  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1961 learning rate: 0.001 Training Loss: 0.6176539063453674 Validation Loss: 0.612558126449585  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1962 learning rate: 0.001 Training Loss: 0.6176294088363647 Validation Loss: 0.6125308275222778  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1963 learning rate: 0.001 Training Loss: 0.6176048517227173 Validation Loss: 0.6125032901763916  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1964 learning rate: 0.001 Training Loss: 0.6175804138183594 Validation Loss: 0.6124759316444397  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1965 learning rate: 0.001 Training Loss: 0.6175558567047119 Validation Loss: 0.6124486327171326  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1966 learning rate: 0.001 Training Loss: 0.617531418800354 Validation Loss: 0.6124212741851807  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1967 learning rate: 0.001 Training Loss: 0.6175069212913513 Validation Loss: 0.612393856048584  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1968 learning rate: 0.001 Training Loss: 0.6174824237823486 Validation Loss: 0.6123666167259216  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1969 learning rate: 0.001 Training Loss: 0.6174578666687012 Validation Loss: 0.612339198589325  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1970 learning rate: 0.001 Training Loss: 0.6174333691596985 Validation Loss: 0.6123118996620178  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1971 learning rate: 0.001 Training Loss: 0.6174089312553406 Validation Loss: 0.6122845411300659  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1972 learning rate: 0.001 Training Loss: 0.6173844933509827 Validation Loss: 0.6122572422027588  accuracy_train: 0.8593 accuracy_test: 0.9006 \n",
            "Epoch: 1973 learning rate: 0.001 Training Loss: 0.61735999584198 Validation Loss: 0.6122298836708069  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1974 learning rate: 0.001 Training Loss: 0.6173354983329773 Validation Loss: 0.6122026443481445  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1975 learning rate: 0.001 Training Loss: 0.6173109412193298 Validation Loss: 0.6121752262115479  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1976 learning rate: 0.001 Training Loss: 0.6172864437103271 Validation Loss: 0.6121478080749512  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1977 learning rate: 0.001 Training Loss: 0.617262065410614 Validation Loss: 0.6121205687522888  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1978 learning rate: 0.001 Training Loss: 0.6172376275062561 Validation Loss: 0.6120932102203369  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1979 learning rate: 0.001 Training Loss: 0.6172130107879639 Validation Loss: 0.6120660305023193  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1980 learning rate: 0.001 Training Loss: 0.6171886324882507 Validation Loss: 0.6120386123657227  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1981 learning rate: 0.001 Training Loss: 0.6171641945838928 Validation Loss: 0.6120113134384155  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1982 learning rate: 0.001 Training Loss: 0.6171397566795349 Validation Loss: 0.6119840145111084  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1983 learning rate: 0.001 Training Loss: 0.617115318775177 Validation Loss: 0.611956775188446  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1984 learning rate: 0.001 Training Loss: 0.6170907616615295 Validation Loss: 0.6119293570518494  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1985 learning rate: 0.001 Training Loss: 0.6170662641525269 Validation Loss: 0.6119021773338318  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1986 learning rate: 0.001 Training Loss: 0.617041826248169 Validation Loss: 0.6118746995925903  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1987 learning rate: 0.001 Training Loss: 0.6170174479484558 Validation Loss: 0.6118475198745728  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1988 learning rate: 0.001 Training Loss: 0.6169929504394531 Validation Loss: 0.6118202209472656  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1989 learning rate: 0.001 Training Loss: 0.6169685125350952 Validation Loss: 0.6117929220199585  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1990 learning rate: 0.001 Training Loss: 0.6169440746307373 Validation Loss: 0.6117655634880066  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1991 learning rate: 0.001 Training Loss: 0.6169196367263794 Validation Loss: 0.611738383769989  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1992 learning rate: 0.001 Training Loss: 0.6168952584266663 Validation Loss: 0.6117111444473267  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1993 learning rate: 0.001 Training Loss: 0.6168707609176636 Validation Loss: 0.6116837859153748  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1994 learning rate: 0.001 Training Loss: 0.6168463826179504 Validation Loss: 0.6116564869880676  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1995 learning rate: 0.001 Training Loss: 0.6168218851089478 Validation Loss: 0.6116293668746948  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1996 learning rate: 0.001 Training Loss: 0.6167974472045898 Validation Loss: 0.6116020083427429  accuracy_train: 0.8618 accuracy_test: 0.9006 \n",
            "Epoch: 1997 learning rate: 0.001 Training Loss: 0.6167730093002319 Validation Loss: 0.6115747690200806  accuracy_train: 0.8643 accuracy_test: 0.9006 \n",
            "Epoch: 1998 learning rate: 0.001 Training Loss: 0.6167486310005188 Validation Loss: 0.6115475296974182  accuracy_train: 0.8643 accuracy_test: 0.9006 \n",
            "Epoch: 1999 learning rate: 0.001 Training Loss: 0.6167241930961609 Validation Loss: 0.6115201711654663  accuracy_train: 0.8668 accuracy_test: 0.9006 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb6qHj5WUR4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "6c9681db-1a29-40c1-a6c4-2bdaacc3262c"
      },
      "source": [
        "#learning 0.01\n",
        "plt.figure()\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Performance with a learning rate of {}'.format(learningRate))\n",
        "plt.plot(epoch_arr,loss_arr,label='Train loss')\n",
        "plt.plot(epoch_arr,val_arr,label='Validation loss')\n",
        "plt.plot(epoch_arr,accuracy_train_arr,label='Test Acurracy')\n",
        "plt.plot(epoch_arr,accuracy_test_arr,label='Train Acurracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuray')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usv2H4APCZe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#learning 0.1\n",
        "display_data_plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNXtLQcMtaa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "ea3f6e51-d3b0-4b8c-9cb8-91cfd47c133b"
      },
      "source": [
        "#learning 0.01\n",
        "plt.figure()\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Performance with a learning rate of {}'.format(learningRate))\n",
        "plt.plot(epoch_arr,loss_arr,label='Train loss')\n",
        "plt.plot(epoch_arr,val_arr,label='Validation loss')\n",
        "plt.plot(epoch_arr,accuracy_train_arr,label='Test Acurracy')\n",
        "plt.plot(epoch_arr,accuracy_test_arr,label='Train Acurracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOngVLxDtN7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "f0289b86-34ee-473d-b5fe-b061db701ad5"
      },
      "source": [
        "#learning 0.001\n",
        "plt.figure()\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Performance with a learning rate of {}'.format(learningRate))\n",
        "plt.plot(epoch_arr,loss_arr,label='Train loss')\n",
        "plt.plot(epoch_arr,val_arr,label='Validation loss')\n",
        "plt.plot(epoch_arr,accuracy_train_arr,label='Test Acurracy')\n",
        "plt.plot(epoch_arr,accuracy_test_arr,label='Train Acurracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAHwCAYAAABtz0NOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU1f3/8dcne8JOArKTICogEJYgKqIgKiou4Iq1FepW/bVatVStWmtVrG2tVVtLixvV+gUXBLWCfCuK4BeVrYiCGyLIIkgCgYTMkGXO74+ZxABJmMDM3CTzfj4ePJx77jnnfu5MwE/OnHuOOecQEREREZHDl+B1ACIiIiIiTYWSaxERERGRCFFyLSIiIiISIUquRUREREQiRMm1iIiIiEiEKLkWEREREYkQJdciEhVmdoSZLTSzIjP7k9fxNCRmVmxmPeo4v97MTovStZ2Z9YxG3we57uVm9r+xvq4XzGycmW0Mfc4DvY5HRGJLybWIVAkldb5QUrDNzKaZWfND7O5aIB9o6Zz7RQTDbPScc82dc+sAQu/x/V7HFG3Oueedc2d4HQeAmU00s/eieImHgJ+FPuf/1nD9bDN7x8xKzOyzun6RMrNUM3vazHab2VYzu2W/86NCfZSE+uxe7dwlZrY4dG5BJG9QRGqn5FpE9neuc645MAjIA+6qT2MLSgC6A2vcIexUZWZJ9W0j3qn2mXuugfzsdAdW13F+OvBfIBO4E3jZzNrVUvce4KhQnyOBW83sTAAzywJeAX4NtAWWAS9Ua7sDeAR48FBvRETqr0H8YygiDY9zbjMwF+gLYGbHh0bBCs3sIzMbUVnXzBaY2WQz+z+gBHgWmEAwESg2s9NCI3CPmNmW0J9HzCw11H6EmW0ys9vMbCvwjJndY2Yvmdm/QlNLPjazo83sV2b2Xehr9zOqxfBjM/s0VHedmf2k2rnK/n8Ravutmf242vl0M/uTmW0ws11m9p6ZpR/svqsLXf/1asdfmtlL1Y43mtmA0GtnZj3N7Frg8mrv0+vVuhxgZqtC8bxgZmm1XPdIM3vbzArMLN/Mnjez1nV/ulVtU83sITP7JvRNxd+r3XcbM/u3mW03s52h112qtd3/M+8Ruq/rQvdeaGaPm5mF6u8zWnyQuomhzyPfzL42s5+F6teYOFvwG5fbzGwVsMfMkszsdjP7KvTzsMbMxoXq9gb+DpwQes8LD/Ze1HC9BDO7K/Tz8p2ZPWtmrUJ9FAOJwEdm9lUNbY8m+Ivrb5xzPufcTOBj4MJaPqYJwH3OuZ3OuU+BJ4CJoXMXAKudcy855/wEE/FcM+sF4Jx7yzn3IrCllr5FJAqUXItIjcysK3A28F8z6wy8AdxPcIRsEjDT9h1t+xHBqSAtgB8DzwN/CH01/hbBEbrjgQFALnAc+46Kdwj13T3UD8C5wHNAG4IjffMI/rvVGbgX+Ee19t8B5wAtQ9f/s5kN2q//VqG2VwGPm1mb0LmHgMHAiaEYbgUCYd53pXeB4aHEqxOQApwQei97AM2BVdUbOOem7vc+nVvt9CXAmUAO0J/vE6r9GfA7oBPQG+hKMMkKx4PA0QQ/k54E35u7Q+cSgGcIfh7dAB/w1/3aV//MN4TKzgGGhGK+BBhdx/Vrq3sNcFYorkHA2DDu5TJgDNDaOVcOfAUMJ/iZ/xb4l5l1DCWo1wHvh97zyl9E6nov9jcx9GckUPnZ/tU5tzf0rQ9ArnPuyBraHgusc84VVSv7KFS+j9DPZ8fQ+ZrqHlv9nHNuT+i+D+hLRGJHybWI7G92aDTvPYIJ4wPAD4E5zrk5zrmAc+4/BL+CPrtau2nOudXOuXLnXFkN/V4O3Ouc+845t51gwvOjaucDBEfz9jrnfKGyRc65eaFk6SWgHfBgqP8ZQHblKK1z7g3n3Fcu6F3gfwkmV5XKQtcvc87NAYqBYyw4neFK4OfOuc3OuQrn3GLn3N4w75vQ9dcBRQSTs5MJ/iKwJTSKeEroXgIHee+re8w5t8U5twN4PdTvAZxza51z/wm9b9uBh0PXq1NolPha4Gbn3I5QsvcAMD7Ub4FzbqZzriR0bnIN/db0mT/onCt0zn0DvFNb3AepewnwqHNuk3NuJ+FNa3jMObex8mcnNJq7JfS5vQB8SfAXunq/FzW4HHjYObfOOVcM/AoYX9vI+n6aA7v2K9tF8BeUmupWnq+pbn36EpEYaQhz00SkYRkbGmmuYsGHpC42s+ojq8kEE6JKGw/Sbye+H90k9LpTtePtoa+2q9tW7bUPyHfOVVQ7hmCCUWhmZwG/ITj6mABkEPy6vVJBKEmvVBJqmwWkERzx2184913du8AIgiOf7wKFBBPSE0LH9bF1v1g71VTJzI4AHiX4i0QLgve+M4z+2xF8j5aHZmNAcBQ8MdRvBvBngqPnlSP8LcwssdpnUNNnvn/cdT0QW1vdTvv1fbCfrQPqmNkVwC1Adqio8rOuSZ3vRQ1q+llOAo4ANh8kzmKC365U15LgL2Y11a0876+hbn36EpEY0ci1iIRjI/Ccc651tT/NnHPVRxQP9uDiFoLJaqVu7DsXtN4PPlay4NztmQSndxwR+qp/DsEE6WDyCSYuNX2FH859V1eZXA8PvX6XYHJ9CrUn14d83yEPhPro55xrSXC0Pdz79gHHVru3VtWmNfwCOAYYGur35FB59b4PN/bafAt0qXbcNYw2VbGEfhl8AvgZkBn6efiE72PfP+6DvRf7q+lnuZx9fxmszWqC89Orjy7nUsMDkKFR+29D52uqu7r6OTNrRvDnuK6HKUUkypRci0g4/gWca2ajQw+bpVnwIcEuB235venAXWbWzoKrHNwd6jcSUoBUYDtQHhrFDmvZt9BUjaeBh82sU+j+Tggl7PW973cJzsNNd85tAhYRHPnNJDhnvCbbCM7bPVQtCI5g7grNEf9lOI1C9/0Ewbnp7QHMrLOZVc57bkEw4Sw0s7YEvxWIlReBn4fiaQ3cVs/2zQgm0Nsh+LApoQdzQ7YBXcwsBcJ6L/Y3HbjZzHIsuFTlA8AL+30zUiPn3BfASuA3oZ+ncQTnnM+spcmzBP/etAlNMboGmBY6Nwvoa2YXWvCB17uBVc65z0L3kBgqTwISQtdLPliMInJ4lFyLyEE55zYC5wN3EExYNhJM4urzb8j9BOcrryI4XWNFqCwS8RUBNxJMynYCPwBeq0cXk0IxLSW4fNnvgYT63ncocSommFTjnNsNrAP+r9pUiv09BfQJrZgxux4xV/otwYf+dhF8+PKVerS9DVgLfGBmu4G3CI5WQ3AJt3SCo7ofAG8eQmyH6gmCc+ZXEfylZA7BkeHa3sN9OOfWAH8C3ieYSPcD/q9albcJju5uNbP8UFld78X+nib4oO1C4GuC33zcEOa9QXAudx7Bn9UHgYtC8+UrN9upPvL8G4JTljYQ/OXtj865N0P3uZ3gKiOTQ30NZd954j8i+AvSFILfpvgIvrciEkXm6r8ErYiISMyEvon4u3Ou+0Eri4h4TCPXIiLSoFhw3fGzQ+tVdyY4ejvL67hERMKhkWsREWlQQiuVvAv0IjiV4Q2CSyXu9jQwEZEwKLkWEREREYkQTQsREREREYkQJdciIiIiIhHSZHZozMrKctnZ2V6HISIiIiJN3PLly/Odc+1qOtdkkuvs7GyWLVvmdRgiIiIi0sSZ2YbazmlaiIiIiIhIhCi5FhERERGJECXXIiIiIiIR0mTmXNekrKyMTZs24ff7vQ5FwpCWlkaXLl1ITk72OhQRERGRQ9Kkk+tNmzbRokULsrOzMTOvw5E6OOcoKChg06ZN5OTkeB2OiIiIyCFp0tNC/H4/mZmZSqwbATMjMzNT3zKIiIhIo9akk2tAiXUjos9KREREGrsmn1x7qaCggAEDBjBgwAA6dOhA586dq45LS0vrbLts2TJuvPHGel0vOzub/Pz8wwlZRERERA5Dk55z7bXMzExWrlwJwD333EPz5s2ZNGlS1fny8nKSkmr+CPLy8sjLy4tJnCIiIiISGRq5jrGJEydy3XXXMXToUG699VaWLFnCCSecwMCBAznxxBP5/PPPAViwYAHnnHMOEEzMr7zySkaMGEGPHj147LHHDnqdhx9+mL59+9K3b18eeeQRAPbs2cOYMWPIzc2lb9++vPDCCwDcfvvt9OnTh/79+++T/IuIiIhI/cTNyPVvX1/Nmi27I9pnn04t+c25x9a73aZNm1i8eDGJiYns3r2bRYsWkZSUxFtvvcUdd9zBzJkzD2jz2Wef8c4771BUVMQxxxzD9ddfX+uSdcuXL+eZZ57hww8/xDnH0KFDOeWUU1i3bh2dOnXijTfeAGDXrl0UFBQwa9YsPvvsM8yMwsLCet+PiIiIiARp5NoDF198MYmJiUAwwb344ovp27cvN998M6tXr66xzZgxY0hNTSUrK4v27duzbdu2Wvt/7733GDduHM2aNaN58+ZccMEFLFq0iH79+vGf//yH2267jUWLFtGqVStatWpFWloaV111Fa+88goZGRlRuWcRERGReBA3I9eHMsIcLc2aNat6/etf/5qRI0cya9Ys1q9fz4gRI2psk5qaWvU6MTGR8vLyel/36KOPZsWKFcyZM4e77rqLUaNGcffdd7NkyRLmz5/Pyy+/zF//+lfefvvtevctIiIiIhq59tyuXbvo3LkzANOmTYtIn8OHD2f27NmUlJSwZ88eZs2axfDhw9myZQsZGRn88Ic/5Je//CUrVqyguLiYXbt2cfbZZ/PnP/+Zjz76KCIxiIiIiMSjuBm5bqhuvfVWJkyYwP3338+YMWMi0uegQYOYOHEixx13HABXX301AwcOZN68efzyl78kISGB5ORkpkyZQlFREeeffz5+vx/nHA8//HBEYhARERGJR+ac8zqGiMjLy3PLli3bp+zTTz+ld+/eHkUkh0KfmYiIiDR0ZrbcOVfjmskauRYRERGRBiGwZw+uoiLs+glpaVhKShQjqj8l1yIiIiLiuaIFC9h03fX1atPp9w/S6vzzoxTRoVFyLSIiIiKeK9uwAYB2t9xCQmp4o9FpfftGM6RDouRaRERERDwX8PkByJw4ocFN9agPLcUnIiIiIp4L+H2QmAi17EDdWCi5FhERERHPOZ8/+ICimdehHJaoJtdmdqaZfW5ma83s9hrOdzez+Wa2yswWmFmXaucmmNmXoT8TohlntIwcOZJ58+btU/bII49w/fW1T9YfMWIElUsKnn322RQWFh5Q55577uGhhx6q89qzZ89mzZo1Vcd33303b731Vn3Cr9GCBQs455xzDrsfERERkeoCfj+Wnu51GIctasm1mSUCjwNnAX2Ay8ysz37VHgKedc71B+4Ffhdq2xb4DTAUOA74jZm1iVas0XLZZZcxY8aMfcpmzJjBZZddFlb7OXPm0Lp160O69v7J9b333stpp512SH2JiIiIRFvAV0JCWprXYRy2aD7QeByw1jm3DsDMZgDnA2uq1ekD3BJ6/Q4wO/R6NPAf59yOUNv/AGcC06MYb8RddNFF3HXXXZSWlpKSksL69evZsmULw4cP5/rrr2fp0qX4fD4uuugifvvb3x7QPjs7m2XLlpGVlcXkyZP55z//Sfv27enatSuDBw8G4IknnmDq1KmUlpbSs2dPnnvuOVauXMlrr73Gu+++y/3338/MmTO57777OOecc7jooouYP38+kyZNory8nCFDhjBlyhRSU1PJzs5mwoQJvP7665SVlfHSSy/Rq1evWu9vx44dXHnllaxbt46MjAymTp1K//79effdd/n5z38OgJmxcOFCiouLufTSS9m9ezfl5eVMmTKF4cOHR+eNFxERkZio2LWLkmXLIAKbEpZ9s5GEdCXXdekMbKx2vIngSHR1HwEXAI8C44AWZpZZS9vOhxXN3Nth68eH1cUBOvSDsx6s9XTbtm057rjjmDt3Lueffz4zZszgkksuwcyYPHkybdu2paKiglGjRrFq1Sr69+9fYz/Lly9nxowZrFy5kvLycgYNGlSVXF9wwQVcc801ANx111089dRT3HDDDZx33nlVyXR1fr+fiRMnMn/+fI4++miuuOIKpkyZwk033QRAVlYWK1as4G9/+xsPPfQQTz75ZK3395vf/IaBAwcye/Zs3n77ba644gpWrlzJQw89xOOPP86wYcMoLi4mLS2NqVOnMnr0aO68804qKiooKSmp11stIiIiDU/+3/7Gjn8+G7H+Mk44PmJ9ecXrpfgmAX81s4nAQmAzEPa2PGZ2LXAtQLdu3aIR32GrnBpSmVw/9dRTALz44otMnTqV8vJyvv32W9asWVNrcr1o0SLGjRtHRkYGAOedd17VuU8++YS77rqLwsJCiouLGT16dJ3xfP755+Tk5HD00UcDMGHCBB5//PGq5PqCCy4AYPDgwbzyyit19vXee+8xc+ZMAE499VQKCgrYvXs3w4YN45ZbbuHyyy/nggsuoEuXLgwZMoQrr7ySsrIyxo4dy4ABAw721omIiEgDV1FYSNIRR9D171Mi0l9y164R6cdL0UyuNwPV36EuobIqzrktBEeuMbPmwIXOuUIz2wyM2K/tgv0v4JybCkwFyMvLq/v7iDpGmKPp/PPP5+abb2bFihWUlJQwePBgvv76ax566CGWLl1KmzZtmDhxIn6//5D6nzhxIrNnzyY3N5dp06axYMGCw4o3NTUVgMTERMrLyw+pj9tvv50xY8YwZ84chg0bxrx58zj55JNZuHAhb7zxBhMnTuSWW27hiiuuOKxYRURExFsBn5/Eli1I693b61AajGiuFrIUOMrMcswsBRgPvFa9gpllmVllDL8Cng69ngecYWZtQg8ynhEqa3SaN2/OyJEjufLKK6seZNy9ezfNmjWjVatWbNu2jblz59bZx8knn8zs2bPx+XwUFRXx+uuvV50rKiqiY8eOlJWV8fzzz1eVt2jRgqKiogP6OuaYY1i/fj1r164F4LnnnuOUU045pHsbPnx41TUXLFhAVlYWLVu25KuvvqJfv37cdtttDBkyhM8++4wNGzZwxBFHcM0113D11VezYsWKQ7qmiIiINBwBvw9La/wrfERS1EaunXPlZvYzgklxIvC0c261md0LLHPOvUZwdPp3ZuYITgv5aajtDjO7j2CCDnBv5cONjdFll13GuHHjqlYOyc3NZeDAgfTq1YuuXbsybNiwOtsPGjSISy+9lNzcXNq3b8+QIUOqzt13330MHTqUdu3aMXTo0KqEevz48VxzzTU89thjvPzyy1X109LSeOaZZ7j44ourHmi87rrrDum+7rnnHq688kr69+9PRkYG//znP4HgcoPvvPMOCQkJHHvssZx11lnMmDGDP/7xjyQnJ9O8eXOefTZy87NERETEG5VrU8v3zEXg6c6GIC8vz1WuD13p008/pbe+pmhU9JmJiIg0Hl9ffAmJbVrTbepUr0OJKTNb7pzLq+mcdmgUERERkUPi/D4SNC1kH16vFiIiIiIiHnJlZeT//R8Eig98VutgyrZuI63P/nsExjcl1yIiIiJxzL9mDfmPP46lp2OJifVrbEZabm50AmuklFyLiIiIxLGAzwdAt6n/IKPaoglyaDTnWkRERCSOVSbXWlIvMpRci4iIiMQxF9rILiFdS+pFgqaFRFFBQQGjRo0CYOvWrSQmJtKuXTsAlixZQkpKSp3tFyxYQEpKCieeeGKtdcaOHcvWrVv54IMPIhe4iIiIxI2AL5hca+Q6MpRcR1FmZiYrV64EghuuNG/enEmTJoXdfsGCBTRv3rzW5LqwsJDly5fTvHlz1q1bR48ePQ475oqKChKrPcyw/7GIiIg0LQF/cFqIRq4jQ9NCYmz58uWccsopDB48mNGjR/Ptt98C8Nhjj9GnTx/69+/P+PHjWb9+PX//+9/585//zIABA1i0aNEBfb3yyiuce+65jB8/vmr3R4C1a9dy2mmnkZuby6BBg/jqq69YsGAB55xzTlWdn/3sZ0ybNg2A7OxsbrvtNgYNGsRLL710wPETTzzBkCFDyM3N5cILL6SkpASAbdu2MW7cOHJzc8nNzWXx4sXcfffdPPLII1XXufPOO3n00Uej8VaKiIhIBDhfZXKtketIiJuR698v+T2f7fgson32atuL2467Lez6zjluuOEGXn31Vdq1a8cLL7zAnXfeydNPP82DDz7I119/TWpqKoWFhbRu3ZrrrruuztHu6dOnc/fdd3PEEUdw4YUXcscddwBw+eWXc/vttzNu3Dj8fj+BQICNGzfWGVtmZiYrVqwA4Pbbb9/nuKCggGuuuQaAu+66i6eeeoobbriBG2+8kVNOOYVZs2ZRUVFBcXExnTp14oILLuCmm24iEAgwY8YMlixZEvZ7JCIiIkE7Z8xg5wsvRv065fnbATBtYx4RcZNcNwR79+7lk08+4fTTTweCUy46duwIQP/+/bn88ssZO3YsY8eOPWhf27Zt48svv+Skk07CzEhOTuaTTz6he/fubN68mXHjxgGQFuZflEsvvbTW408++YS77rqLwsJCiouLGT16NABvv/02zz77LACJiYm0atWKVq1akZmZyX//+1+2bdvGwIEDyczMDCsGERER+V7RW/Mp27KFjMGDo3qd5I4dST3ySCxBExoiIW6S6/qMMEeLc45jjz2W999//4Bzb7zxBgsXLuT1119n8uTJfPzxx3X29eKLL7Jz505ycnIA2L17N9OnT+f222+vsX5SUhKBQKDq2B96MrhSs2bNaj2eOHEis2fPJjc3l2nTprFgwYI6Y7v66quZNm0aW7du5corr6yzroiIiNQs4POR1rs3Xf/2uNehSD3oV5QYSk1NZfv27VXJdVlZGatXr66atjFy5Eh+//vfs2vXLoqLi2nRogVFRTVvRTp9+nTefPNN1q9fz/r161m+fDkzZsygRYsWdOnShdmzZwPB0fKSkhK6d+/OmjVr2Lt3L4WFhcyfPz/suIuKiujYsSNlZWU8//zzVeWjRo1iypQpQHAUfteuXQCMGzeON998k6VLl1aNcouIiEj9OJ+PBE3VaHSUXMdQQkICL7/8Mrfddhu5ubkMGDCAxYsXU1FRwQ9/+EP69evHwIEDufHGG2ndujXnnnsus2bNOuCBxvXr17NhwwaOP/74qrKcnBxatWrFhx9+yHPPPcdjjz1G//79OfHEE9m6dStdu3blkksuoW/fvlxyySUMHDgw7Ljvu+8+hg4dyrBhw+jVq1dV+aOPPso777xDv379GDx4MGvWrAEgJSWFkSNHcskll2ilERERkUMU8PsxreDR6JhzzusYIiIvL88tW7Zsn7JPP/2U3r17exRR/AoEAlUrjRx11FH1aqvPTEREJOjLU0+l2dDj6fS7B7wORfZjZsudc3k1ndPItUTUmjVr6NmzJ6NGjap3Yi0iIiLfcz6/1p5uhOLmgUaJjT59+rBu3TqvwxAREWk0AiUluGqLDlSV+3zaNbERUnItIiIi4pHihQvZ+JProJZpugnNMmIckRwuJdciIiIiHildvwGco91NP8dS950CYokJtDz7bI8ik0Ol5FpERETEI4HQvhNtf/xjElJTPY5GIkEPNIqIiIh4xPl9YIalpHgdikSIkusoKigoYMCAAQwYMIAOHTrQuXPnquPS0tI62y5btowbb7yx3tdcuXIlZsabb755qGGLiIhIjAR8fiw9HTPzOhSJEE0LiaLMzExWrlwJwD333EPz5s2ZNGlS1fny8nKSkmr+CPLy8sjLq3H5xDpNnz6dk046ienTp3PmmWceWuDV7B9jXTGLiIhI/QT82oWxqdHIdYxNnDiR6667jqFDh3LrrbeyZMkSTjjhBAYOHMiJJ57I559/DsCCBQs455xzgGBifuWVVzJixAh69OjBY489VmPfzjleeuklpk2bxn/+8x/8oXlcAL///e/p168fubm53H777QCMGDGCyo138vPzyc7OBmDatGmcd955nHrqqYwaNeqA4+LiYkaNGsWgQYPo168fr776atV1nn32Wfr3709ubi4/+tGPKCoqIicnh7KyMgB27969z7GIiEg8cz6/kusmJm6GILc+8AB7P/0son2m9u5FhzvuqHe7TZs2sXjxYhITE9m9ezeLFi0iKSmJt956izvuuIOZM2ce0Oazzz7jnXfeoaioiGOOOYbrr7+e5OTkfeosXryYnJwcjjzySEaMGMEbb7zBhRdeyNy5c3n11Vf58MMPycjIYMeOHQeNccWKFaxatYq2bdsybdq0fY7Ly8uZNWsWLVu2JD8/n+OPP57zzjuPNWvWcP/997N48WKysrLYsWMHLVq0qIpl7NixzJgxgwsuuOCA2EVERLxStnUr/jVrPLl26TffYBlay7opiZvkuiG5+OKLSUxMBGDXrl1MmDCBL7/8EjOrdUR3zJgxpKamkpqaSvv27dm2bRtdunTZp8706dMZP348AOPHj+fZZ5/lwgsv5K233uLHP/4xGRnBtTLbtm170BhPP/30fepVP3bOcccdd7Bw4UISEhLYvHkz27Zt4+233+biiy8mKytrn+tcffXV/OEPf2Ds2LE888wzPPHEE/V5u0RERKLq2zvuYM/i9z27fsbQoZ5dWyIvbpLrQxlhjpZmzZpVvf71r3/NyJEjmTVrFuvXr2fEiBE1tkmttjxPYmIi5eXl+5yvqKhg5syZvPrqq0yePBnnHAUFBRQVFdUaR1JSEoHQjlDVp5DsH+P+x88//zzbt29n+fLlJCcnk52dfUD76oYNG8b69etZsGABFRUV9O3bt9a6IiIisVZeWEhGXh7tf3W7J9dP6dbNk+tKdMRNct1Q7dq1i86dOwPBuc6Hav78+fTv35958+ZVlU2YMIFZs2Zx+umnc++993L55ZdXTQtp27Yt2dnZLF++nOOOO46XX365XjG3b9+e5ORk3nnnHTZs2ADAqaeeyrhx47jlllvIzMysug7AFVdcwQ9+8AN+/etfH/I9ioiIRIMr8ZGUnU36scd6HYo0AXqg0WO33norv/rVrxg4cOABo9H1MX36dMaNG7dP2YUXXli1ash5551HXl4eAwYM4KGHHgJg0qRJTJkyhYEDB5Kfnx/2tS6//HKWLVtGv379ePbZZ1zDbAQAACAASURBVOnVqxcAxx57LHfeeSennHIKubm53HLLLfu02blzJ5dddtkh36OIiEg0BPx+LE3zniUyzNWyl31jk5eX5ypXvqj06aef0rt3b48ikupefvllXn31VZ577rk66+kzExGRWPti6PG0HDOGDnfr21UJj5ktd87VuGaypoVI1N1www3MnTuXOXPmeB2KiIjIAQJ+P5au5fAkMpRcS9T95S9/8ToEERGRGrlAALd3LwmaFiIRouRaREREoq5s61Z2/utfuPIKr0PZh6sIxpOgkWuJkCafXDvnMDOvw5AwNJX5/yIicqDdc9+k4MmnsIwMGtr/lRNatSK1l573kcho0sl1WloaBQUFZGZmKsFu4CrX5U7TFrAiIk1SwFcCwDFLPsSSmnT6IXGuSf90d+nShU2bNrF9+3avQ5EwpKWlHbDrpIiINA3O58eSk5VYS5PXpH/Ck5OTycnJ8ToMERGRuBdckUMPDUrTp01kREREJOqc30eCpv5JHFByLSIiIlEX8GktaYkPSq5FREQk6gJ+HwnpGV6HIRJ1TXrOtYiIiHyvoqiITTfcSGD37phfu3TDBlJ79oz5dUViTcm1iIhInChdt46SDz4grX9/ktq2jem1k9q3p8Xo0TG9pogXlFyLiIjEiYDPD0D7Sb+g2XHHeRyNSNOkOdciIiJxonIjlwQtiScSNUquRURE4oTzB0eutSSeSPQouRYREYkTldNCtJmLSPQouRYREYkTAb8P0Mi1SDTpgUYREYlLrrwct3ev12HEVOUSfJamkWuRaFFyLSIicccFAqw94wzKt3zrdSixl5hIQlqq11GINFlKrkVEJO44v5/yLd/SfMQIMoYM8TqcmErJ7o4l6X//ItGiv10iIhJ3AqFVM5oNP4m2l1/ucTQi0pTogUYREYk7zlf5YJ/mHotIZCm5FhGRuFM5cp2QrlUzRCSylFyLiEjcqVrvWSPXIhJhSq5FRCTuuMr1njVyLSIRpgcaRUSkyfJ//jllW7YcWP7ppwCYNlMRkQhTci0iIk2SKy9n/SWX1rlRTFJmZgwjEpF4oORaRESapIDfj9u7l7YTrqDlOececD6xZQtSunXzIDIRacqimlyb2ZnAo0Ai8KRz7sH9zncD/gm0DtW53Tk3x8yygU+Bz0NVP3DOXRfNWEVEpGmpXG4vJSeH9H59PY5GROJF1JJrM0sEHgdOBzYBS83sNefcmmrV7gJedM5NMbM+wBwgO3TuK+fcgGjFJyIiTVsglFxrXrWIxFI0Vws5DljrnFvnnCsFZgDn71fHAS1Dr1sBBz51IiIicggql9vTRjEiEkvRnBbSGdhY7XgTMHS/OvcA/2tmNwDNgNOqncsxs/8Cu4G7nHOL9r+AmV0LXAvQTfPmRESkGi23J9K4lVWU8dH2j6hwFbXWObL1kWSlZ8UwqoPz+oHGy4Bpzrk/mdkJwHNm1hf4FujmnCsws8HAbDM71jm3u3pj59xUYCpAXl6ei3XwIiLScGmjGJHGbeaXM5n84eQ66zxw0gOce+SBDyx7KZrJ9Waga7XjLqGy6q4CzgRwzr1vZmlAlnPuO2BvqHy5mX0FHA0si2K8IiLSBOz41/OUbdlC2aZNgEauRRqrzcWbSU1M5e+n/b3WOtmtsmMXUJiimVwvBY4ysxyCSfV44Af71fkGGAVMM7PeQBqw3czaATuccxVm1gM4ClgXxVhFRKQJqCgsZNv990NyMpaURNIRR5DcpYvXYYnIISjwFZCVnkVehzyvQ6mXqCXXzrlyM/sZMI/gMntPO+dWm9m9wDLn3GvAL4AnzOxmgg83TnTOOTM7GbjXzMqAAHCdc25HtGIVEZGmoXKFkA53/5o2F1/scTQi8ef6t67n4/yPI9LXnrI99GnbJyJ9xVJU51w75+YQXF6vetnd1V6vAYbV0G4mMDOasYmISNOjFUJEvFMRqGDxlsX0zezLsVnHRqTPU7qcEpF+YsnrBxpFREQiRiuEiHhn596dBFyAc488l/G9xnsdjmeUXIuISJMR8GuFEIk/0z+bzleFXzGhzwS6tux68AYR5pxj6qqpfFn4JQCZ6Zkxj6EhUXItIiJNRuWca41cS7wIuAAPfPgAAJlpmVw/4PqYx7Ddt52/rvwrzZOb07VFV3q37R3zGBoSJdciItJkuL17AW15LvGjcG9h1esCf4EnMeT78gG4f9j9jOo+ypMYGhIl1yIi0ugEfD423fhzKnbu3Ke8YtcuABLSNS1Emp6yijJWbl9JeaC8qmzrnq1Vr9cWruX9Le/HPK7VBasBTQeppORaREQandKNG9mzaBFpffqQ2O77rY8TM9uSMXgwKV1jP+9UJNpmrZ3FfR/cV+O5duntWL5tOdf+59oYRxVkGJ2ad/Lk2g2NkmsREWl0XOjBxawbb6DFiBHeBiMSI5uLN5OUkMRTZzy1T3lGcgYdm3Xkq8KvPIoMWqe2pn1Ge8+u35AouRYRkUanaj3r9AyPIxGJnXxfPlnpWQw6YlCN52srl9hSci0iIo2O1rOWpsJf7ufSf1/K9pLtB63rK/fRq22vGEQlh0PJtYiINDqVS+5pVRBp7LYUb2HdrnUM7zyc7i27H7T+SZ1PikFUcjiUXIuISKPz/bQQrQoijVvlMnYTjp3A0I5DPY5GIkHJtYiINDoBXwkACRq5Fg+98807vLvp3cPqY3PxZiC4AYw0DUquRUSk0dn5P/8DgOmBRvHQ1FVT+WLnF7RObX1Y/fRu25suLbpEKCrxmpJrERFpdBJS00ho3pzE5s28DkXiWL4/nzNzzmTySZO9DkUaECXXIiLS6AT2+ml24olehyGNRKG/kDUFayLeb4GvgKz0rINXlLii5FpERBod5/NrGT4J2wMfPsDc9XOj0remc8j+lFyLiEijE/D7sTStFCLh2bxnM/2z+vPLIb+MaL+JlkjvzN4R7VMaPyXXIiLS6DifTyuFSNgKfAUMbD+QAe0HeB2KxAEl1yIi0qg45wjs3YtpWkhcu2reVawuWB1W3T1lezi9++lRjkgkSMm1iIg0OOU7d+JftarGc66iAioqSNC0kLhVVlHGkq1LGNh+IH2z+h60fgIJXHT0RTGITETJtYiINEDbHvgdu19/vc46SVnadCNeFfgLADinxzlccswlHkcjsi8l1yIi0uBUFBaSelRPOk6uef1gS0oi9ZhjYhyVeGFT0Sae+uQpKgIVVWW7S3cDaBk8aZCUXIuISIPjfD4S27QlvX9/r0MRj725/k1e/uJl2me0x7Cq8pxWOfTJ7ONhZCI1U3ItIiINTsDnIylLo5ISXOkjIymD+RfP9zoUkbAouRYRkQYn4Pdj6XpgsTEpD5SzYtsKSgOlEe33i51fkJmu+fXSeCi5FhGRBkfrWDc+87+Zz6R3J0Wl7xM6nhCVfkWiQcm1iIg0OMGRayXXjcmW4i0APHXGU6QmpUa07+yW2RHtTySalFyLiDQSzjl2PP00FTt3eh1K1FUUFWkd60amwFdAamIqQzoMwcwO3kCkiVJyLSLSSJSuX893f3wIkpOxhASvw4kqS0oirU9vr8MQYMm3S7hpwU2UB8rrrFdaUUqHZh2UWEvcU3ItItJIBEpKAOjy6CO0OPVUj6OReLEqfxVFpUX8qM+PSKDuX+oGHTEoRlGJNFxKrkVEGgnn9wPoQT+JqQJfAc2Tm3PrkFu9DkWkUVByLSLSSAR8weTaNBdZ6rB251qe+/S5fXY0PBwrvluhpfBE6kHJtYhII+H8PgAStIqG1OG1r15j1pez6NCsQ8T6HJ09OmJ9iTR1Sq5FRBqJ70eulVxL7fJ9+XRs1pF5F83zOhSRuKTkWkSkkQhUjVxrWogE7fDv4JP8T/YpW7drnaZxiHhIybWISAOz/S9/pXjRogPKK/LzAbDUyG7QIY3Xgx8+yNz1cw8oPyvnLA+iERFQci0i0uDseu013N69pB5zzD7lia1a0Wz4cBJbt/YoMmloNu/ZTP+s/vxq6K/2Ke/RqodHEYmIkmsRkQYm4PfRYuSpdLz3t16HIg1cga+AAe0H0Derr9ehiEiIkmsRkQbG+fxaESSOPP/p8zy64lGcc/Vu66/wc1q306IQlYgcKiXXIiINiHOOgM+ntazjyPJty0lLTGNsz7H1bmtmXHjUhVGISkQOlZJrEZGGpKwMKio0ch1HCnwF9GzTk1vybvE6FBGJACXXIiINSMCvtaybko27N/LEx09Q4WrfLfHLwi8Z1mlYDKMSkWhSci0iEgWutPSQ5tBW7N4NQIKmhTQJ8zbMY9baWXRq1gkzq7FOy5SWDO8yPMaRiUi0KLkWEYmwPR98yDdXXQUVtY9WHkxCs2YRjEi8UuAroFlyM+2WKBJHlFyLiERY6fqvoaKCzJ/85JCS5ITUFJqPHBmFyCSWygPlvP3N22SmabdEkXii5FpEJMICvuC86cyrryKxRQuPoxGvvLPxHbbs2cKAdgO8DkVEYijB6wBERJoa5/cBkKCHEuPaluItAPzh5D94HImIxJKSaxGRCAv4/JCUhCUnex2KeKjAX0ByQjIdmnXwOhQRiSEl1yIiERbw+zRqHec27N7AM588Q5vUNrWuEiIiTZOSaxGRCHM+P6ZNYOLa5zs+B+CSYy7xOBIRiTUl1yIiEVT6zTeUbtyodarjXL4vH4ALj9bW5CLxRquFiIhE0DdXX0PZN9+QPkArRMQTX7mPPy37E3vK9gDw5c4vSbAE2qS28TgyEYk1JdciIhFUsXMnLc46kw533+11KBJDH2//mBc+f4H26e1JSUwB4IzuZ5CYkOhxZCISa0quRUQiKOD3k9KlK0ltNGIZTyqngTxxxhP0aN3D42hExEtKrkVEIsSVlUFZmR5mbGLKAmV8+O2HlFaU1lpnydYlAGSmazdGkXin5FpEJEICe/cCkJCe4XEkEknvbnyXmxfcfNB6rVJb0TKlZQwiEpGGTMm1iEiEOF9oZ0aNXDcpO/fuBOAfp/2DNmm1T/dpl9FOa1qLSHSTazM7E3gUSASedM49uN/5bsA/gdahOrc75+aEzv0KuAqoAG50zs2LZqwiIocr4PcDYNpApkkpKSsBoH+7/jRPae5xNCLS0EUtuTazROBx4HRgE7DUzF5zzq2pVu0u4EXn3BQz6wPMAbJDr8cDxwKdgLfM7GjnXEW04hURqYv/00/ZPWdunXUqCoMjnFrjumkpKQ8m1+lJ+lxF5OCiOXJ9HLDWObcOwMxmAOcD1ZNrB1ROUGsFbAm9Ph+Y4ZzbC3xtZmtD/b0fxXhFRGpV8NTT7P73v7Hk5DrrJbRsSUpOToyikljwlflITUzVsnoiEpZoJtedgY3VjjcBQ/ercw/wv2Z2A9AMOK1a2w/2a9s5OmGKiBxcoKSE1N696THrFa9DkRgrKS8hI0kPqYpIeLx+oPEyYJpz7k9mdgLwnJn1DbexmV0LXAvQrVu3KIUoIgLO7yNBc6njxubizUxZOYWyQBmrtq8iI1nJtYiEJyGKfW8GulY77hIqq+4q4EUA59z7QBqQFWZbnHNTnXN5zrm8du3aRTB0EZF9BXx+rQISR97+5m1e/epVVm1fRYIlMLLrSK9DEpFGIpoj10uBo8wsh2BiPB74wX51vgFGAdPMrDfB5Ho78BrwP2b2MMEHGo8ClkQxVhGROgX8fhK162LcKPAVkJSQxJwL5mh5PRGpl6gl1865cjP7GTCP4DJ7TzvnVpvZvcAy59xrwC+AJ8zsZoIPN050zjlgtZm9SPDhx3Lgp1opRES85HyaFtJUFJcWs2TrEoL/uzlQ5xadWbZtGW3T2iqxFpF6i+qc69Ca1XP2K7u72us1wLBa2k4GJkczPhGRcAX8fm1r3kQ8/cnTPPHxE7WeT0lIoTRQSufmeo5eROrP6wcaRUQatIDPx+abbqY8P5+EVCXXTcHWPVtpn9Gev4362wHn5nw9h6c/eRqA8ceMj3VoItIEKLkWEalD6YYNFL/7Lml9+tBi9Givw5EIyPfl0yGjA8e0PeaAc+t2rat63a2lVqESkfpTci0iUoeAzwdAu5tvptnQ4zyOpnErD5Qz7tVxbCzaePDKUVThKmpd/SMrPavG1yIi4VJyLSJSB+f3A2gZvgjY4d/B+t3rObnLyRzT5sBR41g6rftpNZYPaD+AmwbdRKIlcmzmsTGOSkSaAiXXIiJ1CPiCybWlpXscSeNX4CsA4IKeFzCq+yiPo6lZckIyV/W7yuswRKQRU3ItIlKHgK8E0Mh1ffnKffxh6R8oLi2uKtvh3wFAZnqmV2GJiESdkmsRkTpUTQvRGtf18kn+J7z8xct0bNaR1MTUqvLcdrkc2fpIDyMTEYkuJdciInUI7NkDgKVrWkh9VE4B+duov9GzTU+PoxERiR0l1yIitdj2+z+w45lnAEiI8+R6dcFqthRvCbv+B99+AGgKiIjEHyXXIiK12PvllyR16ED7SZPiOrkuD5RzxZwrKA2U1qtdy5SWtEptFaWoREQaJiXXIiK1cH4/Kd260eqcMV6H4qmd/p2UBkr5Sf+fcEb2GWG3y0zLJMESohiZiEjDo+RaRKQWAb+fxMy2XofhuXxfPgC92vbi6DZHexyNiEjDpuRaRKQWAb+P5DhZ3/qzHZ9xxdwr8Jf7DzjncIB2LBQRCYeSaxGRWjifP26W4Pu04FN85T5+2PuHNEtudsD5Fikt6JvV14PIREQaFyXXIiK1CPj9WJxsHlPgDy6dd8PAG8hIzvA4GhGRxkvJtYjEvcDevfj++19cecW+5Xv2kNCEp4Vs27ONR1Y8QmlFKV/s/IKMpAwl1iIih0nJtYjEvcIXXmDbA7+r8VxSVtNdp/m9ze/x73X/pnvL7iRaImN6xPeqKCIikaDkWkTiXvnOnWBG9+f/BVhVuSUYaX36eBdYlFVOBXnlvFdISUzxOBoRkaZBybWIxD3n82Pp6WQMGuR1KFHz9a6v+WLnF/uUrfxuJS1SWiixFhGJICXXIhL3An5fk18VZNK7kw5IrgH6ZmoFEBGRSFJyLSJxz/n8TX5782/3fMuYHmO4uu/V+5R3aNbBo4hERJomJdciEvcCPl+TXnKvtKKUotIiclrm0LNNT6/DERFp0pRci0jcC04Lafwj1ze9cxPzv5lf6/l2Ge1iGI2ISHxSci0iTVpgzx52PPssAd+B23pX2rt2LSmdOscwquhY+d1K+mb2ZXiX4QecS0lM4bTup3kQlYhIfFFyLSJN2p4PPmD7o49BYiIkJNRar+UZo2MYVeRVBCrYuXcnFx19Ef9vwP/zOhwRkbil5FpEmrRAiQ+AHv9+ndScHI+jiZ6de3cScAEy05vupjciIo1B7cM4IiJNQMAfTK6b+mogBb7ghjCZaUquRUS8pORaRJo0F5pr3dTXsa5MrrPSszyOREQkvmlaiIg0aQF/MLm2JjZy/dH2j/i2+Nuq4/9+918ATQsREfGYkmsRadKc3wdmWErT2eK7tKKUiW9OpDxQvk95elI67dK13J6IiJeUXItIkxbw+bH0dMzM61AipsBXQHmgnJ8O+ClndD+jqrxVaisykjM8jExERA6aXJvZucAbzrlADOIRETlsu+fMYcdz/wKgdNPGRjffuiJQUef57b7tAPRq24serXvEIiQREQlTOCPXlwKPmNlM4Gnn3GdRjklE5LDsfnMe/s8/J2NALmlHHUX64MFehxS2tza8xS/e/QWBMMYzNAVERKThOWhy7Zz7oZm1BC4DppmZA54BpjvniqIdoIhIfQX8PlKPPJJuTz/tdSj1trpgNQkkcP2A6+us1yKlBb0ze8coKhERCVdYc66dc7vN7GUgHbgJGAf80swec879JZoBiojUl/P5G91UkEr5vnzaprflutzrvA5FREQOQThzrs8Dfgz0BJ4FjnPOfWdmGcAaQMm1iDQoAb+fxDatvQ5jH/5yP5M/nExRad1f+K3avkprVYuINGLhjFxfCPzZObeweqFzrsTMropOWCIihy7gKyG5Y0evw9jH5zs/Z/ba2XRu3rnOFT1ap7XmrJyzYhiZiIhEUjjJ9T1A1U4FZpYOHOGcW++cmx+twEREDpXz+UlIb1jTQkrKSgC4f9j95HXI8zgaERGJlnC2P38JqP7YekWoTESkwXEVFQT8fiytYe3I6Cv3AWgdahGRJi6c5DrJOVdaeRB63XS2OhORJqO8oIAvhh5PRUEBCRkNK4ktKQ+OXGckNay4REQkssJJrreHHmoEwMzOB/KjF5KIyKEp27KFQHExrcaOpc3ll3sdzj4qp4Vo5FpEpGkLZ871dcDzZvZXwICNwBVRjUpE5BAEfMGpF63Gnk9Kl84eR/O9gAuwp2wPAOlJDWu6ioiIRFY4m8h8BRxvZs1Dx8VRj0pE5BA4vx+gQa1xXR4oZ8wrY9iyZwsJlqDkWkSkiQtrExkzGwMcC6SZGQDOuXujGJeISL0FfMHk2tIbTgK707+TLXu2cGrXUzmrx1kkJYT1z66IiDRS4Wwi83cgAxgJPAlcBCyJclwiIvXm/MFpIQ1p5DrfF3xE5dwjz+W07qd5HI2IiERbOEMoJzrn+pvZKufcb83sT8DcaAcmIlJfVSPXHi7Dt8O/gweXPIi/PBhL4d5CADLTMz2LSUREYiec5Nof+m+JmXUCCoCGtfWZiAhQtmkjgKcbyCzdupS5X88lp1UOKQnBVUuHdBjCUa2P8iwmERGJnXCS69fNrDXwR2AF4IAnohqViMghKHoruGlsgodzrgt8BQA8M/oZjVaLiMShOpNrM0sA5jvnCoGZZvZvIM05tysm0YmI1IMlJ5HWty+WnBzza5eUlbBw80KWbl1KoiXSOrV1zGMQERHv1ZlcO+cCZvY4MDB0vBfYG4vARETqK+DfS3qv3p5c+/WvXuf+D+8HILtlNokJiZ7EISIi3gpnWsh8M7sQeMU556IdkIjIoQr4fZ5NCdlaspUkS2LW+bNol9HOkxhERMR74STXPwFuAcrNzE9wl0bnnGsZ1chEROrJ+fwxf5ixrKIMh+O7ku9om9aW7FbZMb2+iIg0LOHs0NgiFoGIiBwO5xwBny+my/C9+fWb3LrwVhzBL/X6ZPaJ2bVFRKRhCmcTmZNrKnfOLYx8OCIih6isDCoqYjpyvaZgDUkJSfy/Af8PgLwj8mJ2bRERaZjCmRbyy2qv04DjgOXAqVGJSETkIAJ797Ljn88SKNlTVeZKywCwGO7OWOAvICs9i6v7XR2za4qISMMWzrSQc6sfm1lX4JGoRSQichAly5ax/eGHISEBzKrKLTWV1J7R36zlyY+f5KPvPuLj/I/p1LxT1K8nIiKNRzgj1/vbBHiz1pWICBAoKQEg55WZpPXqFfPrP/nxk6QmpnJExhGcnXN2zK8vIiINVzhzrv8CVC7BlwAMILhT40GZ2ZnAo0Ai8KRz7sH9zv8ZGBk6zADaO+dah85VAB+Hzn3jnDsvnGuKSNPn/H4AEmI4BaSSr9zHnrI9XNX3Kq7pf03Mry8iIg1bOCPXy6q9LgemO+f+72CNzCwReBw4neBo91Ize805t6ayjnPu5mr1byC0WU2Izzk3IIz4RCTOBHw+ACzGa1ov3bqUz3Z8BkBWelZMry0iIo1DOMn1y4DfOVcBwaTZzDKccyUHaXccsNY5ty7UbgZwPrCmlvqXAb8JL2wRiWdVI9epqTG7ZklZCdf87zVUBP8p1HrWIiJSo4Qw6swHqg8PpQNvhdGuM7Cx2vGmUNkBzKw7kAO8Xa04zcyWmdkHZjY2jOuJSJwI+ILJdSxHrvN9+VS4Cn4x+Be8ffHbDGw/8OCNREQk7oQzcp3mnCuuPHDOFZtZRoTjGA+8XDk6HtLdObfZzHoAb5vZx865r6o3MrNrgWsBunXrFuGQRKShCvh9YIalpET9WuWBcsoD5WzdsxWAnm16antzERGpVTjJ9R4zG+ScWwFgZoMBXxjtNgNdqx13CZXVZDzw0+oFzrnNof+uM7MFBOdjf7VfnanAVIC8vDyHiDQq5du3s+VXd1TNoQ5X2aZNWHo6Vm0Zvmjwlfs4c+aZ7PDvqCprl67EWkREahdOcn0T8JKZbQEM6ABcGka7pcBRZpZDMKkeD/xg/0pm1gtoA7xfrawNUOKc22tmWcAw4A9hXFNEGhHf6tXsee890vr1I6FZs7DbpeTkkN6vXxQjC9q6Zys7/Ds4O+dsjm5zNK1SW3F0m6Ojfl0REWm8wtlEZmkoAT4mVPS5c64sjHblZvYzYB7Bpfieds6tNrN7gWXOuddCVccDM5xz1UeeewP/MLMAwXnhD1ZfZUREmobKBxM7PTCZ1KOiv/lLfRX4CgAY23MsJ3Q6weNoRESkMQhnneufAs875z4JHbcxs8ucc387WFvn3Bxgzn5ld+93fE8N7RYD0R+WEhFPefFgonOOB5c8yKbiTQetW5lca9k9EREJVzjTQq5xzj1eeeCc22lm1wAHTa5FROri/MG51rHcDGaHfwf/89n/0LFZR9qktTlo/ZM6n0S3lnpgWkREwhNOcp1oZlY5bSO0OUz0H9EXkSavauQ6LXYj1wX+4Gj0L/J+wejs0TG7roiIxIdwkus3gRfM7B+h458Ac6MXkojEi4AvuBdVQlp0NoNZuGnhPit9AHy962sAMtMyo3JNERGJb+Ek17cRXEv6utDxKoIrhoiI1JtzDgKB4GufD0tOxpLC+aeofjYVbeKn839a47kkS6Jri641nhMRETkc4awWEjCzD4EjgUuALGBmtAMTkaZpw/jL8P1/9u48PLKrPvP499QiVZWWUmnfl95st3e7vdsEh82YEAgBBpghJGEmIQmEYRIIzJAZHmYmYTwwkJkhMJDAkLCFgWBsVtvYYIcl7ja0l267d6mlbu0q7VVSqerMH/dWqUoqdbfW0vJ+nuc+qrr31K2j61Lr9dHvnvP005nn3nB4Xd6nf7ofgL+48y+4oe6GnGMlvhIqAhXr8r4iPWJbBAAAIABJREFUIrKzLRmujTH7gDe72xDwDwDW2rs3pmsish3Fjx8neMMNlNx5BwCByy9f9TkTyQSJVO4Mob1TvQDsi+yjqbRp1e8hIiJyKS40cv0C8ATwa9bakwDGmPdsSK9EZFuy1mJjMUpuvZWaP/zDNTln90Q3r73/tcymZvMe1zR6IiKykS4Url+Hs8DLY8aY7wNfxVmhUURkRezMDAAmuHZT750ePc1sapZ/dcW/ojZUm3OsLlRHVVA3LoqIyMZZMlxba+8H7jfGlACvwVkGvdYY8yngm9bahzaojyKyTaRi6Xmt127qvfTUem/d/1YaSxvX7LwiIiIrcSk3NE4BXwa+bIyJAG/AmUFE4VpEliW93Lkna+T6E099gmPRYys+57nJcwAaoRYRkU1hWfNfWWujwGfcTURkWRYuGmOt5fNHPk91oHpRScelKvGV8No9r6XYuz5zZYuIiCzH2k8uKyIC2ESC2DPPYBPzs3jMdp0F5keuZ5IzpGyKt1zxFt5+9dsL0k8REZG1pHAtIuti7Dvfoff9H8h7zFtZCcD0nLNCY9C3ccufi4iIrCeFaxFZF8mRKAAtn/0MnsB8jbUJhQjs3w/AdMIJ1yF/aOM7KCIisg4UrkVkXaTizswgJbfeivH787bRyLWIiGw3nkJ3QES2JxuLg9+/ZLAGGJsZAyDk08i1iIhsDwrXIrIuUvF4TjnIQvefvJ/f/cHvAlBWVLZR3RIREVlXKgsRkXVh47ELhusXRl4g6Avy3pvey1XVV21gz0RERNaPwrWIrItULI4JLV1LPRQboi5Uxxv2vWEDeyUiIrK+FK5FZEWSk1NEv/Ql7Ew87/H40aOLljn/wpEv8Fe/+Cv2VOyhd6qXXeFdG9FVERGRDaNwLSIrMvVP/8Tgxz/uPDEmb5vwa16T8/yjhz4KwPMjz3NNzTW8ever17WPIiIiG03hWkRWJDXtTKO3+5FHKGpuumh7a23O8y/d+6V16ZeIiEghKVyLyIqk57FOL2Wez9jMGI+efZSUTTGTnNmoromIiBSMwrWIrIiNObXWF5oR5MsvfJm/PvzXi/a/ater1q1fIiIihaRwLSIrkh65NhcI1/1T/VQGKvmHX/sHAIq8RYSLwniMptgXEZHtSeFaRFbExuOYoiKM17v4mLVMJiYZmB6gJlhDfUl9AXooIiKy8RSuRWRFUrE4Jph/Huv/9cv/xWef/SwAdzbduZHdEhERKSiFaxHJSPQP0PvBD2JjsYu2nenqXLLe+lj0GPUl9bz1irdye+Pta91NERGRTUvhWkQy4s89y9QTTxC46io8odAF2xZ37CJ06y15jw3FhthdsZvfuvK31qObIiIim5bCtYhkpNwZQBrvu4/iXR0rOsfYzBhHh4/y67t/fS27JiIisiXoln0RybCXMHf1xTwz+AwAuyt2r0mfREREthKFaxHJSI9cX2h6vYsZjg8D8LLWl61Jn0RERLYSlYWISMb8qov5ZwFJS6aS/KDzB0zNTS069rPzPwOgKli19h0UERHZ5BSuRSQjveqiKS6+YLvDg4f5syf+bMnjjSWNhPwXviFSRERkO1K4FtlhrLVLHkvFYphgEGPMBc/RP9UPwOdf8Xlay1sXHS8vKl9dJ0VERLYohWuRHWTsW9/i/Ps/ABcI2N6qi5dzDEwPALA3spdwcXjN+iciIrLVKVyL7CDx48fB56P6938fcELy149/nd/c9zrqQs4S5YH9V1z0PH/73N8CGqEWERFZSOFaZAexsRjekhJq3vlHAHzt8Cf5ep2HyNU1/PENf3TJ50naJFdWXXnR8hEREZGdRlPxiewgqVgckzUTiGH54TiRTDAxO8GvtPzKWnZNRERkW9DItcgOcqb/BUiO8t9+8K8B6JnsAeDbp7+dWfwF4M6mO5mzc/z8/M8XnSORSgBQHazegB6LiIhsLQrXIjtI38hZSj2JTECuC9VxbvIcDSUNmX1d4130TPYwk5wBoLVs8WwgtzTcwi31t2xcx0VERLYIhWuRHcQ7O0egNMwXXvmFJdt89OBH+fILXyZpk7z9qrfzxzf88Qb2UEREZGtTuBbZAZKTk8SPHKV0Yg5bW3TBttXB6swotlZZFBERWR6Fa5EdYOC+/87o175GE3B+b8kF2+6u2J33sYiIiFycwrXIDjA3MoyvpZkP3nWel730pRdse1fzXfzTm/4JQAvEiIiILJOm4hPZAWwsjg2XcbTNQ3FF5UXbh4vDCtYiIiIroJFrkR1gfHyQ5ydOAF7KisoK3R0REZFtSyPXIjvAzNQEMz5474H38rK2lxW6OyIiItuWRq5FdgAbjzNbDr91xVvwefRjLyIisl70W1Zkm3mq/yk+dfhTpEhl9r19ahxqixWsRURE1pnKQkS2mUe6HuGp/qdI2RQNp8a47btnKY1ZWmv3FrprIiIi256GsUS2meHYME1lTfzfe/4vnW96M7HD5wC48fbXFbhnIiIi259GrkW2kYnZCb7X+T2qAs7Kiqnpacpe9lKueOF5Im96U4F7JyIisv0pXItsI986+S0A2srbAEjFYphAsJBdEhER2VEUrkW2kYHpAQA+dPuHAEjFY3gCgQL2SEREZGdRuBbZJiZnJ+md6qWhpAGPcX60bSyOCSpci4iIbBTd0CiyDZyInuD1D76elE1xbc21mf2peByPykJEREQ2jMK1yDZwauwUKZvi96/5/cwKjDaRgLk5PBq5FhER2TDrGq6NMfcAfwV4gb+x1n5kwfGPA3e7T0NArbW2wj32NuCD7rH/Yq39wnr2VWQrG44N89YfJrnn4Z/i9xykC7CpJIBuaBQREdlA6xaujTFe4JPAy4Ae4KAx5gFr7dF0G2vte7Lavwu43n1cCfwn4ABggafc10bXq78iW9GDpx7kGye+Qe9kL/c9ZbG1vdDUDIDBELrtVkpuu7XAvRQREdk51nPk+mbgpLX2NIAx5qvAa4CjS7R/M06gBngF8LC1dsR97cPAPcBX1rG/IlvOt05+i+PR41xRcRlFybNUvP711PzRHxW6WyIiIjvWes4W0gR0Zz3vcfctYoxpAzqAR5fzWmPM7xljDhljDg0ODq5Jp0W2kqHYELfU38JnX/S/AXTzooiISIFtlqn43gR83VqbXM6LrLWfsdYesNYeqKmpWaeuiWxew/FhqoJVpOJxAE27JyIiUmDrGa7PAS1Zz5vdffm8idySj+W8VmRHSqQSjM6MOuE65oRrjVyLiIgU1nqG64PAXmNMhzGmCCdAP7CwkTHmciAC/Cxr9w+AlxtjIsaYCPByd5+IuEZiIwBUBaqw8RiApt0TEREpsHW7odFaO2eMeSdOKPYCn7PWHjHGfBg4ZK1NB+03AV+11tqs144YY/4zTkAH+HD65kaRrWw0PsqcnbuktiFfiJA/lLNvfHac2eQsAKfHTgM4I9djblmIljoXEREpKJOVabe0AwcO2EOHDhW6GyJLevTso7z7sXdfcvv3fstw09HEst6j9QtfoOSWm5fbNREREVkGY8xT1toD+Y5phUaRDXJq9BQA//6Wf4/XeC/Y9sjwEZp7v4bZ007Vy+8F4OToSR7uepgD9QcI+ZwR7SJvEXsq9mAweEpKCF5/3fp+EyIiInJBCtciG2QoNkSZv4w3X/7mi7b96fmfYhNfI3FZOzV//C4AfnD0i/y/g4/yrn/xV0QCkfXuroiIiKyAwvVqxaIQqABjCt0TKZAjQ0f42FMfI5m68EySneOdVAWrLumcVYEqxufgn6OH+ej33gZA71QvXuMlXBxedZ9FRERkfShcr9bfvAwmeqFqN1Tthep9UL3HeVy1B4pCFz+HbGmP9zzOwb6D3FJ/ywXb7a3Yy4tbXnxJ59wV3sWxOQ++UAl+jx+A1rJW7mm/B4/ZLNPTi4iIyEIK16t1+zth4HkYOgE9T8Jz3wCybhINtzghu9oN3unH5U0a7d4mhmJDRIoj/M0r/mbNzumzBu9cilftfx2//Yo/XLPzioiIyPpSuF6tG38793kiBsOnYPgEDJ10vx6Hw1+B2Yn5dv7QfNCu2uuG7/Rod8mGfguyOulVEtdSKj4DaFEYERGRrUbheq35g1B/lbNlsxYm+50R7qHjMHzSHe0+BM/9Izmj3eVNbvDeNx+4q/dCeTN4VBKw2QzFhqgKrD5c29lZYs89B8kkyfFxQIvCiIiIbDUK1xvFGCird7aOu3KPJeIwcnp+lDs94v3M12BmbL6dL+gG7T0L6rv3QHHZxn4/kjEcG+aammtWfZ7oV79K/1/8Zc4+b6Ry1ecVERGRjaNwvUpff6oHv9fQVlVCa2WISMiPWW4ttT8AdfudLZu1MDXoBu4T7mj3cTh/GI5+C2xqvm1ZY1bo3jtfbhJu0Wj3KqRsCoPJ/DeNz8UZnx3PabNWZSFzwyPg9dL6t07ttikqInjttas+r4iIiGwchetV+u8/eIH+8ZnM89JiHy2VIVorg7RVlbiPna2pIkiRbxlB1xgorXW29jtzj83NwMgZt8Qkq777ua9DPHu0OwCVu3MDdzqEB8pX+d1vf9f+3bW8pPUlfOLuTwDwxm+/kTNjZxa1qwvVrfq9bDyGJxik5NZbV30uERERKQyF61X60Z/eTU90mq7hac6OOFv3yDSnBqf40bFBZubmR5c9BhrCwUzYbq0KZcJ3W2WIiuWMevuKofZyZ8tmLUwNuYE7q76771l4/kGwWXMxl9Zn1XRn1XdXtILnwisI7gTWOnXwPzz7QwASqQSdY53c3XI3dzXPl/b4jI+XtL1k1e+XisUxqrEWERHZ0hSuVylY5GVvXRl76xbXPKdSlsHJGSd0Z4XvsyPTPHpsgMGJmZz2ZZlRbyd4t2aNejde6qi3MVBa42xtt+cem5uF6Bm3xMQd7R46DkfvdxbDSfMWu/N2Z89m4tZ3B3bOAiYTiYmc59F4FIvlzqY7ecO+N6z5+6XiMc0OIiIissUpXK8jj8dQVx6grjzATe2Lb0ybnp2jJxrLjHp3u8H75OAkjx4bYHaJUe+2rBHv9HZJo96+Iqi5zNkWmhrOKjFx67sHjsKx70Jqbr5dSW3utIHpxXIibeD1r/RSbQrPDj6bs9LibGo2c+yt330r8WQcYE1mBsnHxuJ4Ahq5FhER2coUrgsoVORjX10Z+5YY9R6YmMkZ7T47PMXZkWkeeX6AockFo94BX07YzpSbVDmj3n7vRUa9S6qg5DZouy13fzIB0c6sEhN3xPv5B2F6eL6d8UKkPSt0754P3mX1W2LBnB/3/Jhf9P+CWxqclRYDBCjyFNFS1kLAFyDgC3B3y91cV3vdurx/Kh7HBDVyLSIispUpXG9SHo+hPhygPhzg5o78o97dIzG63MCdHvU+3j/BD19YPOrdWJFb650dxMPBC4x6e/3zI9Xcu6ATI+6COSdzt9M/hrnYfDt/iRO2M8F7z3zZySYqMxmODxMJRPjsyz+7Ie8XO3yYyZ/8JPN89vRp/E1NG/LeIiIisj4UrreoUJGPy+rLuKw+/6h3/0Q8U+edDt5dI9M88nw/Q5OzOe3LAj7aqnJHvLNrvZcc9Q5VOlvLTQs7ABPn5xfKSQfwc0/BkW/mTiFYUps1d/ee+VKTSLtTxrICR4ePcqjv0LJf98zgM2u+0uKFDPyPjzP95JM5+0p/9Vc37P1FRERk7Slcb0Mej6EhHKQhHOSWXYvD4tTMHN3RxTdZvtA3wSNHB5hNzodfr8fQWBHIKTdpqyyZH/UO5amz9ngg3Oxsu16ce2xuxikzyQTvk074PvZ9mBqYb2c8UNGWdVPl7vngXdZwwbm7/+s//1eeGXxmeRfN9epdr17R61YiNT1NyV130fJ/Pp3ZZzQnuYiIyJamcL0DlRT7uLy+nMvrF89znUpZ+sbjOdMKnh1xphp86Eg/w1O5o97lAR+tVU7gXjjq3VARWDzq7Ste+qbK2CiMnHLCdiZ4n4Sun0Jiar6dP+TM3b2o1GQPBCsYnB7kle2v5M9v+/PlXxt/ybJfs1KpeAx/qEmBWkREZBtRuJYcHo+hsSJIY0WQW/OMek/OzGUCd/bI9/O94zx0tI9E0mbaej2GJrfWe2Hwbq1yar1zBCug6UZny2YtTPTOh+2hkwwPvUCi/xk4/p3cMpNgJcPVQeoTXsqe/Jv50B3pcFbC3EQ0O4iIiMj2o3Aty1Ja7OOKhnKuaFg86p1Mj3oPz494p2u9f3Ckj5EFo97hoH/R7CYtlcHFtd7GQHmjs3W8iB93/5h3PvoglAPlDXn7WTvSCcc+lLXHOIvjpMN2dqlJeXNBloh3ZgdRuBYREdlOFK5lzaRHqpsqgty2e/Go90Q8QfdIzA3dU+7XGEfzjHqn5/VuqQzSEpkP4C2VQZ4eOgbAB2/5ID7P4o+wz+PjJa0vcUa80zXdmVHvE9D9JMxmLRCTXiI+Z+EcN4SHFs/UslZsTIvGiIiIbDcK17JhygJ+9jf62d+Yf9S7dyxG90iM7ug0Pema72iMHx8fZCBrNcvi2l/ij/j57HfrndAdCbrBO0RLxAngpUVuyUnj9c6WzVqYHHDm7M5MIXgKBp5fvGhOMDI/X3d2jXflLvCvPBhbazVyLSIisg0pXMum4PUY6sr9/PVz/4Xfv/b3eWN57g2P4/EY73nsTxiYHqI/dh6PrWR3TQlnR2IcPDPCxMxcTvtIyJ8VtkM5I+CNFUGKyuqgrA7a78ztSHIORrvyzN39I3j6y1kNjTMbSvbNlOnpBMMt4PFmWk4fPMjQpz6FTc2PzGMtpFIauRYREdlmFK5l0zg8eJgHTz9I33Qfn3vF53KO9cd6eHLgCS6vvJzry6/krqa7+Ff7DwDOKPBYLOHObuKMfKdnOlmq5KS+PJAz2t1aFcwE8ZrILjxVu4FX5HZwZhJGTrsj3lmlJs98DWbG5tt5i5yRbTd0T3yvk6mfHyR4zdXg9QHOgj2hm2+m5Pbb1+NSioiISIEoXMumkUgmAEimkouODcedpdbfd9P7uKk+d9EaYwwVoSIqQkVc01yx6LXJlKV/PJ65ybI7GsuUnTxxYpD+8dyl5It9HprdUpPWrFITJ4xfQXnDNblvYC1MDWWNdGeF7xMPkToexOsP0H7596G43CkvSdd426PQMwNVu5wSFBEREdnSFK6l4Hone/nJ+Z9wZuwMAKfGTvGFI1/IaXNsxLmJsTpYvezze7OmF8y3qE48kaQnuqDW2x0Bf6orykQ8t+QkPctJutRkfgT8apqabqbYN18SQiqJ/ZN34xn/Jdzz79x5vE9Cz0E48o+50wiGqrJurMwK4JW7obh02d+3iIiIbDyFaym4jzz5ER7tfjTzfGxmjI8e+uiidhXFFdSX1K/5+wf8XvbUlrKnNn+AHZt2S06i0zmj3y/0Ll7R0qRLTrJqvW8bnqU0UE7fFb9NbVkxHo9TFjK/WuWp+dA9fArOPA5PfyW3E6X1C0K3e4PlJpy/W0REZCdTuJaC657szjy+u+Vu/vKuv8zbrshThN+bZ7n1dRYO+bk6FObq5vCiY6mUpX8inplisDsrhP/k5BD9E3EiXYNUzMzxqr/8IUXpkpNIKGv0+3pa2u6g5fqshXVmp5367kzodh8f+x5MDWb1wDg3UFbtyp1OsHI3RNqgANdLRERkJ1O4lnUxm5xlODa85PFiXzGVgUoSyQRD00OZ/Q0lDRu6BPlqeTyGhnCQhnCQmzsWz4kdTyTpfNtXmYkX8Z9fe5UTvt0A/suzUcYXlJykl5OfH/m+jpba22i5PERzJOiUnMTH3BsrT83Xdo+cgue+7hxLM14nYOeEbvdGy3BzzowmIiIisjYUrmVdvOORd3Cw7+AF23zp3i/xmWc+Q3QmmtlXV1K33l3bUAG/l+LkLKHKct56a9ui42OxRE7gTo+AH+uf4IcvDDA7l8ppX1deTEsk5N5weTXNkZtpaXaCeH15Mf6ZUXe0Oyt0D5+Crp9CYmr+RN4ip6Skak/WqLdbalLW4NS3iIiIyLIpXMu6ODV6ipvrb+bXdv3aomPRmSgff+rjnBk7w6nRUwS8AT58x4dJpBLc3XJ3AXq7dqZ+9jO63/EH2ERifmcqRdnLX563fTjoJ9wU5qqm/CUnAxMzztSCw9PzN11GpznYGeWBp8+TPXW212OoLw+4wXs/LZEDNO8K0nIgREskQK0Zwxs9nRu6h0/ByUcgmTVjij/khu0FobtyN5RUK3iLiIhcgMK1rLlkKsnozCjX117Pb+z9jUXHpxJTfPypjzMcH2Y4Pszr972eV3a8sgA9XXszJ05iZ2ao/N3fxRQXZfaXvfSlyz6Xx2OoDweoDwe4qX1xyUkimaJvLJ4Z9e6Jxugecb7mm2LQ73WWp2+OXE5L5fU014VovjxISyRAqy9KVbwbkx26+4/AC9/JXbGyOJw/dGsqQREREUDhWtbA149/nX888Y+Z50mbJGVTS06bF/KFCPqCfPHoF4nNxVY0vd5mlYrHAah59x/jKS5e1/fyez2ZaQDziSeSnB+NOfN6R+enF+yJxnjoSD/DU7M57QN+D82RvTRHrnFKT5qDtFYUscs3QmPqHKWTnZj0TZY9T8Jz3wCyhs4zUwkuKDWp3KWpBEVEZMdQuJZV+/bpb9M90c2V1Vdm9t3dcjd3NN6Rt70xht+56nd4evBprjRX8uKWF29QT9efjcfAGExR0cUbr7OA38uumlJ21eQPttOzczmj3Zmv0Wl+0bX4ZsvS4t00R66iORKiZXeQ1rCPff4hWux5ahM9BMY7nRHvRUvF40wlWLnLDd3pbbeCt4iIbDsK17Jqw7Fhbq6/mY+9+GOX/Jo/uPYP1rFHhZOajmGCQcwWqEsOFfnYV1fGvrqyvMfHYgl6FpSb9LjTDP701BDTs+mVNEPAPipCVzr13nUhOvbCFcVDdHj6qE+coyLejW+0E048DJP9uW9UWpcVtjvcUhM3gBfn75uIiMhmpXAtqxKfi9M53sltjbcVuiubQioewxPYHou6hIN+wsEwVzYuvtnSWkt0OpEz2p0uPXFmOom5M51Uu9u1VJcW0xwJsrsBrgoMs8c7QLM9T/XsOUomu/CcfAQm+3LfqKQ2N2xnb4HyjbgMIiIiy6JwLavyxLknAKgN1Ra4J5uDjcW3Tbi+EGMMlSVFVJYUcW1LxaLjqZRlaHImq957PoQfPBfjW6M+5lINQANwI8ZAXVmAvbVwbUmUy4oGaTN91M2dJzx9luJTj2IOfyn3TUpq5ktLqhaUmih4i4hIgShcy6oMTA8A8Bt7Fs8KspPMDQ0x29VFoq8PEwwWujsF5/EYassD1JYHuLFt8SwiyZSlbzxOj7uUfHb4/mavoXcsSMq2Ztp7PYaOcrixbJQrA4Ps9g7QZHupjPdQcuoxvAtrvEtqcsN2dq13YPFIvIiIyFpRuJYVG5sZ4+z4WTzGQ0Xx4tHLnaT7HX9A/LnnAAgeuLHAvdn8vB5nWsCmiiC35Dk+O5eidyy26EbLEyNhHuurZWBiT077cu8MN5aPcU1omH0+d9R7+hzh4Ucpml4QvEPVbuBeUG5StVvBW0REVk3hWlZkODbMS7/+UuZSc9SF6vDu8KW050aGKbnjDqre/rsU7dlz8RfIBRX5PLRVldBWVZL3eDyRpCca49xoLHPTZU80xuPRab4yEmNgYn6O7wAz7PIOcH1JlP2BIXZ7+2ma6KVq6DFC8a/knjg9nWB24K7scPYFd/b/QIqIyKVRuJYV6ZnsYS41x9v2v23bLACzGjYWx9/aQsnttxe6KztCwO9lT20pe2rzT+OXnuM7HbrTAfwb0WnOjcYyC+wUM0ub6WeXp59rQkPsY5D2aB+1g49RPvPV3JMGK7NGuxeUm2gBHRERcSlcy4oMx4YBuHfXveyv2l/g3hReKh7HE1Ct9WZxsTm+44kkvWPxrFHvaY5FYzzqhvH+iThFdpZWM0CH6aXDM8AVs4PsHhigqf9HRBJfw2QtoGODlZhFpSbuqHdo8eqaIiKyfSlcy5K+ePSLPHj6wbzHxmbGAKgKVG1klzYlay02HscT3P6zhGwXAb+XjuoSOqrzl53MzCXpHY3njHr/KDrNl9zR8OjMOM0M0GH6nJHvZB97ZwZp73uMquTX8GQF72QggqnchScdvLMDuIK3iMi2o3AtS/p+5/fpnezl6pqrFx2rDlZzZ9Od1IRqCtCzzcXOzoK1GI1cbxvFPi/t1SW0LxG+s2+4TIfvQ+6o98DIKL7Jbtrpo8300THXR/t0P7vPP0Yd/y8neCeKwqQqOvBV78Jb7YbuSIfztbQWtsBiRCIikkvhWpY0PTfNDXU38Im7P1HormxqNhYD2BHzW4vjYjdczs6l6MsqO3lyNMY/RqfpGxmDkU5CU1204QTv1tgAbf3/RLO5Hy+pzDkS3iCzZW1QuYtA3W68mRHvDihvgh1+E7GIyGalcC1Lmk5ME/Rt79HY6YMHmT50aFXnSE5OAmBUFiKuIp+H1qoQrVWhPEd/hUTSCd/dbvh+Khqjd2ScmaFOvKOdlE2fpXVugLbZPtpHDtNy6iG8Zi5zhjnjZzrUxFy4A2/NbkL1e/BX73HCd7gFfEUb982KiEgOhWtZUmwuRsiXLxxsH/1/+RHiR4+u/kR+P8UdHas/j+wIfq+HlsoQLZULf74OAGTCd080xi+j03wnOsnEQDd25BRF411UxHtoHe+jbeI0bed+it/MTz2YwsN4cT2x0lZsZBdFtbspb9xHUc0eiLRD0fb+mRYRKTSFa1lSbC627UeuU1NTlN/7Shrvu291JzIG49Wf6WVt5Ibv9E3DV2SOzyVTzgqX0RjfH5lmZOAcs4Mn8UTPEJzsonL6HK2xPtqGniNycjLn3KPeKsZCLcyWt2MiHQTq91LRvI/S+n1aREdEZA0oXEteyVTSGbn2b+9RrlQ8jgmFMD79KMjW4fN6aI6EaI6EYFcV0ALcmjmeTFn6x+OciMYYGDjPdN8FaSTBAAAgAElEQVRJksOn8Y92UjrdTfX4OVrHf0TtufvhufnzjplyhoqamAq1kAi346veTUnDXiqbLyNS04jxeDb8exUR2WqUKCSvx3seByDg2951xJqfWrYjr8fQWBGksSIIHZXAVTnHrbUMTc7yzOAQ0XPHmek/gR05Q/F4F+FYN7Ujv6Rh5GE8nfMzm0zaIL3eBqLFTUyXtZGqaKeoZg/lTfuobeygtjyIx6PZTUREFK4lr+6JbgBe2b69V1+009Oan1p2HGMMNWXF1JQ1wa4m4O6c49ZaxiemGOg5zsT548wOnMQz2klosoum+ClqYz/FP5CE4077uPVziloGfI2MBVqIl7dhKjsort1DReNuWqrKqQ8H8Hs18i0i25/CteQ1FB/C7/FTX1Jf6K6sGzs3h00kMJpCTySHMYZweSnh/TfA/hsWN0jOMT3URbT7BSb7TpAcOoVvrIuOqbNUTT1D8dQM9AJHIGG9nLPV/IxaBn2NTIZamAu34a3qIFi3l/qaKpoqgjRHggT8um9BRLY+hWvJazg2TFWwCrONF7FIxZ0ZFlQWIrJMXh+hut2E6nYvPmYtTPQxO3iS8XPHiA2cxDN8mn3jZzkQ+wmhyUmYBM45zQdtmC5bx9O2liF/I1OhFpIV7fhrdhOpbqQpEqIpEqQpEqQ84N/Qb1NEZCUUriWv4fgw1YHqQndjRVIzM/R+4AMkR0cv2M7OJgDNTy2ypoyB8gaKyhuo3n3X4uPTIxA9Q2qkk8neEzBwirboGS6bOEHZ7D85wXsS6IFJG6Db1tJl63jc1jLgayBW6tR7h2raaKwso6nCCd5NFUEqS4q29YCAiGwNCteS13BsmLpQXaG7sSKznZ2Mf/d7FHV04K2ouGDb0M03U3LTTRvUMxEhVAmhSjxNN1J+9YJjiTiMdsHIGWz0DJ7+UzQOnaJ5tJOXTj2NLzWbCd+Jbqfc5Kyt5Wlbx4O2lj5PA/GyVmyknZqqShrD88G7sSKoum8R2RAK15LjlwO/5Kn+pzg3cY79VfsL3Z0VSS9HXveB91P6ohcVuDcicsn8Aai5DGouwwA5E4GmUjBxHkbOQPQMvpFOGodOUTd8mttGD+JPjDntpp1t6FwFnalaumwtP03V0WXr6KGW6dJWQhX1NKbLTSqCmdHvxoogpcX6tSgiq6N/RSTHX/zzX/DCyAsAXFl1ZYF7szKpeBxANyqKbCceD4Sbna3jLgyQs8h7LJoJ3oycoTraSWTkDNcNn8Y7+RMM7rSCsxAbDHJusI5TyRo6U7U8Yp3w3WVrmSpuoD5SSqN7k2VjRYCmipDzNRKkuqRYUw6KyAWta7g2xtwD/BXgBf7GWvuRPG3eCHwIsMDT1tq3uPuTwLNus7PW2l9fz76KY2B6gN/Y8xv8+a1/jt+7NW8eSodrT1A3KorsGMEINEWgaX52k8zcI4k4jJ7NBO9g9Ax7Rs6wO9oJ0Wcwyfnl45N4GZ6opXuijpOnazg5V8NTbvg+a2uZ84VoDDtBO1120lgRpNktPWmoCFDs06wnIjvZuoVrY4wX+CTwMqAHOGiMecBaezSrzV7gA8Ad1tqoMaY26xQxa+1169U/mZeyKc5NniOZSjI6M0ptqHbLBmsAmw7XGrkWEXDLTfY5WxYDbrlJbyZ4e6NnqB05Q230DDeOHIR47o3Rk/5K+pMNnB2q4+T5ap6fqeLxVB1nbR1DlAOG2rJiGrNutEzXfKfLT8oDPt14KbKNrefI9c3ASWvtaQBjzFeB1wBHs9r8G+CT1toogLV2YB37I0v4/HOf5xO/+ETmeV3J1ryRMS0Vc8tCNHItIhfj8UC4ydna71x8PBaFaGem5KR05Ayl0U52jxzn7vhj4J9fxTLhDTFa3ESfr56zsTqOjVfzzPOVfH+uhvO2ijn3V25psc8N3IHMyHdTpgwlSG1ZAK9KT0S2rPUM101Ad9bzHuCWBW32ARhjfoLzF7wPWWu/7x4LGGMOAXPAR6y1969jX3e0zvFOKooreN9N78Pv9fMrzb9S6C6tio07NzRq5FpEVi0YcbbG6xcfm5txyk3c4O0fOUNN9Aw1I2e4Ovokr0rOOL/ZvGCNl1iwgWhxI32eejptLceHqnj2bIQHY5WMUYI7lo7PY6gPB3JutsyMfrvlKMEilZ6IbFaFvqHRB+wFXgw0A48bY6621o4Cbdbac8aYXcCjxphnrbWnsl9sjPk94PcAWltbN7bn28hQbIjG0kZevfvVhe7Kqoz8/Rfpv+8+mJsDVHMtIuvMVwzVe51toexyk2gXJtpJKHqGULSTpujPuHFqcL5tAJJF5UyXNBMtaqTXU09XqpZj8SqePRXh2xOlzNrcX9dVJUWZEe+FJShNkSCRkF+lJyIFsp7h+hzQkvW8mcyaXBk9wD9baxPAGWPMcZywfdBaew7AWnvaGPMj4HogJ1xbaz8DfAbgwIEDFrmoRDLBux57F0PTQ5l9ZyfOcqDuQAF7tTbiR4/iCQSIvOUtFLU04ykpKXSXRGSnuli5ycykM6d3tBOinXijnZS5W+vQE9ySdZOlDXhIljUxFWohWtxAr6eeM8lajs9U8Ux/BT8+7iOWSOWcPuj30lgRyMx6kl333VgRpK48QJFPc36LrIf1DNcHgb3GmA6cUP0m4C0L2twPvBn4vDGmGqdM5LQxJgJMW2tn3P13APetY193jO6Jbn5y7idcVXUVNaEaABpLG3nd3tcVuGerl4rH8NXUUPuef1voroiIXFhxKdRd6WwLpVIw2Zep9TbRTnzRTsLRTsJDT9A+NcBtWc1tqJxkuJWpkhZGiho5b+rpStbwwkwVR6YsD/eOMzQ5m/MWxpC58bKxIkhjOJB53FQRpCEc0IqXIiu0buHaWjtnjHkn8AOcqrPPWWuPGGM+DByy1j7gHnu5MeYokATea60dNsbcDvwfY0wK8ODUXB9d4q1kGYbjwwC8+8Z3c2vDrQXuzdqysbjqrEVk6/N4oLzR2dpuX3x8dgqi86Pe8+H7NOHoo3QkZ7gj3dZ4oLyZZFMbU6FmRooa6fXUOSPfs6WcnPDy/PlxHjnaz8xc7uh3sc+TGelucMN35nlFQLXfIktY15pra+13ge8u2Pcfsx5b4N+5W3abnwILF8aVVUikEnzt2Nd4evBpAKoD1QXu0dpLxWKYkOqsRWSbKyqBuv3OtlD2qHfW5o12Ut79KOWT/bTD/Mh3cTlE2rAt7cRLWogWN3HeU0dXsobjMxF6JpKcH43x+IlBBiZmsAsKMCtLipzyk7A7Al4RyBoND1JTVqyZT2THKfQNjbJBDg8c5iNPOmv4VAYqaSxtLHCP1l4qHsNbVl7oboiIFM6ljHqPnl0Uvs3QCYInHiY4F6cROADuqHcTRNqhqY25cBtjxU30ehvoStXQOR3g3Fic3tEYXcPT/PTUMJMzczlvl575JLvcZOEIeHlg666rIJKPwvUOMTjt3Jn+jV//Bnsq9uAx2+9GFhuL46mtvXhDEZGdqqgEaq9wtoVSKZjsXxS8iXbCiUfwTfZRBVQBVwEUlTnBO9IGje0QaWeqtIU+Tz3dySp6JlKcH425W5yDnSP0jcWZS+UOf5cV+xaPemeNhteHA/i92+93lmxfCtfbWDKVpHuiG4vl5OhJAOpCdRcN1jMnT5Icn1i0v6ijHV8kMt/u9BmSo6OL2hVKcnwcE1BZiIjIing8UN7gbG23LT4+O5131Jvhk3DyEZiLUwLsBnZj5ke9I+1wRTtUdpAMtzHkb6BnJkTveDwTvM+5IfzpnjFGpi5882W+EXBNPSibicL1NvbJw5/ks89+NvM86AtSXnThsonZri5O/1r++a5DN91E29//HQBzg4OcftWrWFSAV2DeSEWhuyAisj0VhaD2cmdbyNqlR71P/dCZ8xtndoM6oK6o1AndFW3O18va3MdtxEqaOT9tOD8aozcreJ8fi3F0iZsvA35PTt13Q3g+eKdHxAN+3XwpG0PhehvrHO+kvqSe99zwHgBay1sv+n/2c8MjANS85z0ErpyfImr4059mbmRkvt1IFKyl+g//gOANN65D71fAQPDaawvdCxGRnccYKKt3ttY8M1ElYotHvUfOwMhpOP0YJKYzTYPA7pJadkfmAze72zNB3JY3MRJL5Yx4947Nj4D/6Nggg5PLu/myqSJITWkxHt18KWtA4XobG44N01LWwr277r3k16SXDg/deAOhA/MLy4x/+9skzp9f1C543XWU3nkHIiIiS/IHoeYyZ1vIWpgayllUx3ncBT0H4cg3wSYzzY3xUhVuoirSztXp8N3SDte0Q2QvlNQwm7T0j2eNeo/GOD/mlKF0Dk9d0s2X+UbAy3TzpVwChettYjoxzTsffSejM/M10F1jXfxq668u6zypeBxgUe2yCQYyxwBSsXQ7zSstIiKrYAyU1jhbc57VgpNzMH4uK3x3zYfvEw855SjZ/CGKKlppqWijJX3DZUMb7G+Dissh4JRHjscTmeB9bjTulqE4I+BPnhmhbzxOUjdfygooXG8Tp8dOc7DvINfVXEdVsAqA1rLWZa+8mIo5I9KeYG5o9gSCueE6nm6nGwhFRGQdeX1OQI60QceLFh9P32iZDtzZI99nfwYz47ntg5UQaaO8oo3ySBuXR9qhug32tkN4F/iKAEimLAMTcc6PxrNmPZkfAT/cPUp0OpFz6nwrXzaE50fBGyoCVJeo/GS7U7jeJoZjzsqL77vpfVxds/L1d6wboBeudOgJBrCxGNZajDFLthMREdlQF7vRMhbNDdzpEfC+Z+HYdyGZPTuJceYIj7TjrWijIdJGQ0UbN0baoaMNSjucWVVc07NznB+NuzXfWSPg7s2XDx/tZ3bBzZdFXg914WIndIcDNGSF8PTKlxWa/WRLU7jeJoZiQwBUB1e38mKm3GPBiLQJBMFa7Owsprh4yXYiIiKbhjEQqnS2phsWH0+lnJlMFoXvLjj9I3eWk6zSEG8xVLRkbq4MRdrYU9HGnkgbNLdDsDXn9NZaRqZm6R1Lh+4458ecWVB6x2Ic7IzSP967aO7voN9LQzhAgzvinQ7h6SkIG8Kq/97MFK63ieG4M3JdGaxc1XnSNyouGrl2nw99+tN4igPEnn3W2V9cvKr3ExERKRiPB8JNzkaem/PnZmC0G0Y7F9d7n3sK4gvWeigOQ6Q1E75NpJ2qijaqIm1cta8V/PWL3iKZsgxNzsyHb/dregaUJ5ZYer6s2DcfvtNlJ1nhW9MPFo7C9TYxHBumrKiMYu/qwu5SNyoW7doFXi/Dn/p0Zp+vthZPOLyq9xMREdm0fMVQvcfZ8omP5Qbu9Aj40InMwjo5Suud2vH0LCcVbXgj7dRF2qhrbuL61kjet0kkU/SPx3PDt1v/3TsW47lzYwwvWHwHIBLyL6r5bswK4XXlAYp8ugFzrSlcb2HTiWn6pvoAODtxlqpA1arPmYrHMMXFGE/uD1vpnXdw+eFf5i4a4/VivPq/YhER2aECYWi4xtkWyiyskxW+RzvdGy1/Ds99HWxWPbbHB+Hm+YV1MiG8HX9FG80V1TRHQkt2JZ5I0reg7OS8G8J7ojGePDPCeDx3+kFjoLq0eFHNd/aIeG1ZAK9uwFwWhest7F2Pvosn+57MPL+1Ic/E/ctkY/Elb1I0ftV3iYiIXJKchXVuWXw8mYCxnvw3W77wHZgeym3vD0GFW3JS0eqG79bMvkAwQnt1Ce3VJUt2aWpmLlNukv21dyzOiYEJHj8xyPRsMuc1Xo+hrqx4Uc139oh4VUmRZkDJonC9hXWOdXJL/S28ft/rAVY1S0haKh7HhJb+P2MRERFZA14/VHY4Wz4zk1lTDHa6j93nZ38OM2O57YvKFgXunBAeCFNS7GNPbRl7asvyvqW1lvHYnDP6nR2+R50R8WfPjfHQEjOg1IcDueF7wVSE4eDOmQFF4XqLStkUI/ERXr371dzTcc+andfGY5peT0REpNCKS6Fuv7PlExt1gnY6dEe75peYP/1jSEzltg+EswJ3++IQXlyKMYZwyE845OeKhvK8b2utZXhqNhO4ezOzoDglKEstwBP0e3NqvjPhO+trafH2iKXb47sooHc8/A76p+dXh9oV3sXHXvyxC75mKjHFHz7yh4zPjl+w3YWkbIo5O5dZMGatpGJxTFDhWkREZFMLVjhbw7WLj+XM7302N4QPnYCTP4S5WO5rQlV5Rr3bna/hFmc+ccAYQ3VpMdWlxVzdnH9Sg2TKMjgxk1v/nVUHfvz4IIOTeWZACfhya77DgcyS9OlSlGDR5r/XS+F6lZrLmgn5nQ9c13gXD3U9xHRiOrMvn5OjJ/nFwC+4ofaGVYXjyyov48UtL17x6/NJxWN4Apq7WkREZMu62Pze1sLUYO7KlunH/Ufg2PcWLK4DlNTmrfV2thZnZhWX12Ood4MxreQ1Ozc/A0q+OvBnesYYyTMDSkV6BhT3/G840MJ1LRWruVprTuF6lT546wczj+8/eT9//pM/Zzg+fMFwnV5N8c9u/jP2Vy3x5551Mvbgg4x98/68x+aGh5k5doyS22/f0D6JiIjIBjIGSmudrfnA4uOplDPTSWbUu2u+9OTcL+DotyCVO/MIZQ1L33AZbnFqzLMU+Ty0VIZoqbz4DCjpAJ7+2jfmLEv/i7NRbt9drXC9naWnwvvbZ/+WulDdku2eH3k+p/1GGvvmN4k9/QzFe/fm7E+OjzN7+jQAJXcoXIuIiOxYHg+UNzhbvplOUkln9crsWu90AO/+OTz3DbBZs44YD5Q1Ln3DZVkjeBdH0oDfe9EZUOzC2pJNQOF6De2p2EOJv4RvnPjGRds2lTateb30pUjF4gSvvYbWz30uZ//Uz3/O2d/+HQAib3nLhvdLREREtgiP15mTO9wMbXkG5JJzMH4uN3SnQ/iZJ5xj2cvKG6+zSmZF9gI7WSG8rN55zzw24wwkCtdrqKG0gZ+9+WeX3L4QH4hUPI43sngFqOwZQoyWNBcREZGV8vqcgBxpA+5afHxuFsZ7ska9s0L4yUdgsi+3vcfv1HUvqvVuhdrLnZlQNhGF6zW2Gf8PKpuN5Z9qzwTnb2JcuDqjiIiIyJrxFUHlLmfLJxF3FtgZ7VxQenLWudlyanC+7Wv+Gq7/lxvS7UulcL3DpOL5p9rT3NYiIiKyKfgDUL3H2fKZnZ4f7a67amP7dgkUrncYZ+R68VR7RtPviYiIyFZQFHLKQWovL3RP8tLf/3eYVDyOJ9/ItRaOEREREVk1jVxvExOPPsa5P/kTmJu7YDubSGBCi+eUVFmIiIiIyOopXG8TM8dewMZiVP3rtzvzSS7F66Hita9dtNsUFdHwX/8L/oaGdeyliIiIyPamcL1NpGJx8Pmo/dM/XfE5Kn7zN9ewRyIiIiI7j2qut4lUPP8UeyIiIiKycRSutwkbyz/FnoiIiIhsHIXrbSIVi+EJLr5RUUREREQ2jsL1NqGyEBEREZHC0w2Nm8xsdzdzQ0PLft3c4KDKQkREREQKTOF6E0lNTXHq3ldBIrGi15f8yovWuEciIiIishwK15tIcnwcEgkq3/ZblNx517JfH7hicy4DKiIiIrJTKFxvIqlYHIDAVVdTetedBe6NiIiIiCyXbmjcRGw8BoBHtdMiIiIiW5LC9SaSijsj1yYQLHBPRERERGQlFK43kVRMI9ciIiIiW5nC9SZiMyPXCtciIiIiW5FuaNwAc9EoY9+8Hzs3t+iYNxym4o1vINHdzfj3vg+AJ6iyEBEREZGtSOF6A4x/57sM3HffksdDN97AyN9/kfFvfxtPOIyvpmYDeyciIiIia0XhegOkpqYA2HfwSUxRUWb/1BNP0PPOd5GamiI1NYW/uZnd3/8exqf/LCIiIiJbkVLcBkjFY+Dx4CktxRiT2e8pK3eOx+Kk4jE8oZCCtYiIiMgWphsaN4CNxfEEAjnBGuZnBUnFY9hYHKNZQkRERES2NIXrDZCKxzB5blJMzwpi43FS8TgezW8tIiIisqUpXG8AG4vlnQHEEwoBTlnIUm1EREREZOtQuN4AqVg878IwnszIdYxUXGUhIiIiIlud7p5bpfMf+PfMDQ5esE38yBH8zc2L9qeXOR/5u78ncf48wWuvXZc+ioiIiMjGULhepdTkJMmJ8Qu28be2UH7PKxft95SEKH/1q5k920Wg/HJKf/Xu9eqmiIiIiGwAY60tdB/WxIEDB+yhQ4cK3Q0RERER2eaMMU9Zaw/kO6aaaxERERGRNaJwLSIiIiKyRhSuRURERETWiMK1iIiIiMgaUbgWEREREVkj6xqujTH3GGOOGWNOGmPev0SbNxpjjhpjjhhjvpy1/23GmBPu9rb17KeIiIiIyFpYt3mujTFe4JPAy4Ae4KAx5gFr7dGsNnuBDwB3WGujxphad38l8J+AA4AFnnJfG12v/oqIiIiIrNZ6jlzfDJy01p621s4CXwVes6DNvwE+mQ7N1toBd/8rgIettSPusYeBe9axryIiIiIiq7ae4boJ6M563uPuy7YP2GeM+Ykx5ufGmHuW8VoRERERkU2l0Muf+4C9wIuBZuBxY8zVl/piY8zvAb8H0Nrauh79ExERERG5ZOs5cn0OaMl63uzuy9YDPGCtTVhrzwDHccL2pbwWa+1nrLUHrLUHampq1rTzIiIiIiLLtZ7h+iCw1xjTYYwpAt4EPLCgzf04o9YYY6pxykROAz8AXm6MiRhjIsDL3X0iIiIiIpvWupWFWGvnjDHvxAnFXuBz1tojxpgPA4estQ8wH6KPAkngvdbaYQBjzH/GCegAH7bWjqxXX0VERERE1oKx1ha6D2viwIED9tChQ4XuhoiIiIhsc8aYp6y1B/Id0wqNIiIiIiJrROFaRERERGSNKFyLiIiIiKwRhWsRERERkTWybW5oNMYMAl0FevtqYKhA770V6Xotj67X8uh6LY+u1/Loei2Prtfy6HotX6GuWZu1Nu8iK9smXBeSMebQUneMymK6Xsuj67U8ul7Lo+u1PLpey6PrtTy6Xsu3Ga+ZykJERERERNaIwrWIiIiIyBpRuF4bnyl0B7YYXa/l0fVaHl2v5dH1Wh5dr+XR9VoeXa/l23TXTDXXIiIiIiJrRCPXIiIiIiJrROF6FYwx9xhjjhljThpj3l/o/mwGxpgWY8xjxpijxpgjxph3u/s/ZIw5Z4w57G73Zr3mA+41PGaMeUXhel8YxphOY8yz7nU55O6rNMY8bIw54X6NuPuNMeZ/utfrGWPMDYXt/cYyxlyW9Rk6bIwZN8b8W32+chljPmeMGTDGPJe1b9mfKWPM29z2J4wxbyvE97IRlrhe/90Y84J7Tb5pjKlw97cbY2JZn7VPZ73mRvdn+aR7TU0hvp/1tsT1WvbP4E75HbrE9fqHrGvVaYw57O7X52vpHLF1/g2z1mpbwQZ4gVPALqAIeBrYX+h+FXoDGoAb3MdlwHFgP/Ah4E/ztN/vXrtioMO9pt5Cfx8bfM06geoF++4D3u8+fj/w39zH9wLfAwxwK/DPhe5/Aa+bF+gD2vT5WvR9vwi4AXhupZ8poBI47X6NuI8jhf7eNvB6vRzwuY//W9b1as9ut+A8T7rX0LjX9JWF/t428Hot62dwJ/0OzXe9Fhz/GPAf9fnKfJ9L5Ygt82+YRq5X7mbgpLX2tLV2Fvgq8JoC96ngrLW91tpfuI8ngOeBpgu85DXAV621M9baM8BJnGu7070G+IL7+AvAa7P2/511/ByoMMY0FKKDm8BLgFPW2gstHrUjP1/W2seBkQW7l/uZegXwsLV2xFobBR4G7ln/3m+8fNfLWvuQtXbOffpzoPlC53CvWbm19ufW+c3+d8xf421lic/XUpb6Gdwxv0MvdL3c0ec3Al+50Dl22OdrqRyxZf4NU7heuSagO+t5DxcOkTuOMaYduB74Z3fXO90/2Xwu/eccdB0BLPCQMeYpY8zvufvqrLW97uM+oM59rOs1703k/kLS5+vClvuZ0rWb97s4I2NpHcaYXxpjfmyMucvd14RzjdJ24vVazs+gPl+Ou4B+a+2JrH36fLkW5Igt82+YwrWsC2NMKfAN4N9aa8eBTwG7geuAXpw/g4njTmvtDcArgT8yxrwo+6A7SqFpfbIYY4qAXwf+n7tLn69l0Gfq0hlj/gMwB3zJ3dULtFprrwf+HfBlY0x5ofq3iehncGXeTO4ggT5frjw5ImOz/xumcL1y54CWrOfN7r4dzxjjx/mB+JK19h8BrLX91tqktTYFfJb5P83v+OtorT3nfh0AvolzbfrT5R7u1wG3+Y6/Xq5XAr+w1vaDPl+XaLmfqR1/7Ywxvw38GvAv3V/muOUNw+7jp3DqhvfhXJvs0pEddb1W8DOoz5cxPuB1wD+k9+nz5ciXI9hC/4YpXK/cQWCvMabDHUV7E/BAgftUcG792N8Cz1tr/0fW/uy64N8A0ndNPwC8yRhTbIzpAPbi3LSxIxhjSowxZenHODdRPYdzXdJ3Nr8N+Jb7+AHgt9y7o28FxrL+TLaT5Iz26PN1SZb7mfoB8HJjTMT9E//L3X07gjHmHuB9wK9ba6ez9tcYY7zu4104n6nT7jUbN8bc6v47+FvMX+NtbwU/g/odCi8FXrDWZso99PlaOkewlf4N24i7JrfrhnOH6nGc/7P8D4Xuz2bYgDtx/lTzDHDY3e4F/h541t3/ANCQ9Zr/4F7DY2zTu58vcL124dwl/zRwJP05AqqAHwIngEeASne/AT7pXq9ngQOF/h4KcM1KgGEgnLVPn6/ca/QVnD8vJ3DqDN++ks8UTq3xSXf7nUJ/Xxt8vU7i1Gum/x37tNv2N92f1cPAL4BXZ53nAE6oPAX8b9yF2rbbtsT1WvbP4E75HZrvern7/y/wjgVt9flaOkdsmX/DtEKjiIiIiMgaUVmIiIiIiMgaUbgWEREREVkjCtciIiIiImtE4VpEREREZI0oXIuIiIiIrBGFaxGRbYNIYwoAAAHjSURBVMAYkzTGHM7a3r+G5243xjx38ZYiIuIrdAdERGRNxKy11xW6EyIiO51GrkVEtjFjTKcx5j5jzLPGmCeNMXvc/e3GmEeNMc8YY35ojGl199cZY75pjHna3W53T+U1xnzWGHPEGPOQMSZYsG9KRGQTU7gWEdkeggvKQv5F1rExa+3VOKu6fcLd97+AL1hrrwG+BPxPd///BH5srb0WuAFntThwlmH+pLX2SmAUZyU5ERFZQCs0iohsA8aYSWttaZ79ncCvWmtPG2P8QJ+1tsoYM4SzRHXC3d9rra02/7+dO0SpIIrCAPwfxGASu8HiDtyLiklML4hJ3ICrsLgNQUyCVnEThucGXpBreCNM0CDcpzh+X5lzbxjubYefM1M1T7LdWluM3rGT5La1tjusL5Kst9YuV38zgL9Fcg0wfe2L+jsWo/otvtkB+JTmGmD69kfPx6F+SHIw1EdJ7of6LsksSapqrao2f+qQAFMgeQCYho2qehqtb1prH7/j26qq5yzT58Nh7zTJdVWdJ5knOR72z5JcVdVJlgn1LMnLyk8PMBFmrgEmbJi53mutvf72WQD+A2MhAADQieQaAAA6kVwDAEAnmmsAAOhEcw0AAJ1orgEAoBPNNQAAdKK5BgCATt4BTrrqFxsFDIsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIBf-XGjBWgt",
        "colab_type": "text"
      },
      "source": [
        "# Results\n",
        "\n",
        "Epoch: 1999 learning rate: 0.001 Training Loss: 0.6167241930961609 Validation Loss: 0.6115201711654663  accuracy_train: 0.8668 accuracy_test: 0.9006 \n",
        "\n",
        "Epoch: 1999 learning rate: 0.01 Training Loss: 0.39713969826698303 Validation Loss: 0.37617188692092896  accuracy_train: 0.9146 accuracy_test: 0.9415\n",
        "\n",
        "Epoch: 1999 learning rate: 0.1 Training Loss: 0.16359683871269226 Validation Loss: 0.1477421224117279  accuracy_train: 0.9573 accuracy_test: 0.9649 \n",
        "\n",
        "Iterations needed for covergence of accuracy  \n",
        "* 0.001 - Never converges\n",
        "* 0.01  - 1250 epochs\n",
        "* 0.1   - 300 epochs\n",
        "\n",
        "# Discussion \n",
        "\n",
        "According to the training information the best and lowest validation loss was given by the learning rate of 0.1. Learning rates of 0.1 and 0.01 did converged , while 0.001 failed to achieve\n",
        "convergence. In epoch trained , Train accuracy was higher than the test accuracy. model with learning rate of 0.1 has a steady increaments in accuracy and steady decrements which have the\n",
        "ability pedict smothly through out the training. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KxdTxq1BUio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}